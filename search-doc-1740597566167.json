{"searchDocs":[{"title":"Editor Integration","type":0,"sectionRef":"#","url":"/docs/editor-integration/","content":"Editor Integration","keywords":"","version":"Next"},{"title":"Pyre Configuration","type":0,"sectionRef":"#","url":"/docs/configuration/","content":"","keywords":"","version":"Next"},{"title":"The Pyre Configuration​","type":1,"pageTitle":"Pyre Configuration","url":"/docs/configuration/#the-pyre-configuration","content":"The Pyre configuration is a .pyre_configuration file sitting at the root of your project. Running Pyre anywhere inside your project directory will use the settings in this configuration. You can generate an initial configuration in your project directory with $ pyre init  The configuration is a JSON file. For example, { &quot;source_directories&quot;: [ &quot;.&quot; ], &quot;search_path&quot;: [ &quot;/external/library&quot;, {&quot;site-package&quot;: &quot;foo&quot;} ] }  specifies that the code Pyre checks is in the directory of the configuration and that Pyre should look in an additional directory as well as the foo package installed in your environment for library code. You specify additional information to configure Pyre. The following fields are supported: source_directories: List of paths to type check. Paths can be a glob, for example, &quot;./foo*&quot;. Note: Pyre assumes that all imports are relative to the given source directory. For example, if your source directory is root/directory, then an import statement import module will be looking to import root.directory.module. If you wish to set a different import root for your source directory, you can provide an object {&quot;import_root&quot;: &quot;root&quot;, &quot;source&quot;: &quot;directory&quot;} instead of &quot;root/directory&quot;. In this case, import module will be looking to import root.module. search_path: List of paths to Python modules to include in the typing environment. Relative paths are the best way to reference locations above the configuration directory. search_path elements take precendence over source_directories, and the order within the search path indicates precedence. Individual items in the list can take one of the following forms: A plain string, representing a path to the directories from which Pyre will search for modules. The paths can be globs, for example, &quot;./foo*&quot;.An object {&quot;import_root&quot;: &quot;root&quot;, &quot;source&quot;: &quot;directory&quot;}, which can be used to control import root of the search path. See explaination for source_directories.An object {&quot;site-package&quot;: &quot;package_name&quot;}. It is equivalent to {&quot;import_root&quot;: &quot;site_root&quot;, &quot;source&quot;: &quot;package_name&quot;}, where site_root is the first element in site_roots that has the site package named package_name installed. This can be useful when you want to manually specify which pip package you want the type checker to see as a dependency to your project (in which case it is recommended to set site_package_search_strategy to &quot;none&quot; to disable site package auto discovery).An object {&quot;site-package&quot;: &quot;package_name&quot;, &quot;is_toplevel_module&quot;: true}, to specify the name as a single-file module found in the site-root rather than as a package. binary: Location of Pyre's native binary. exclude: List of regular expressions such as &quot;.*\\/node_modules\\/.*&quot; which specify files and directories that should be completely ignored by Pyre. The regular expression will be matched against the full path of files as opposed to their relative path. extensions: Consider extensions in this list equivalent to .py for type checking. Empty string indicates extensionless files. ignore_all_errors: A list of paths to omit from type-checking. This may be useful for generated files, virtualenv directories, etc. These should be paths relative to the location of the configuration file and support globs. Note: Files matching these paths will still be processed (i.e. type and module names in those files are still visible to Pyre). Please refer to the excludeconfiguration item if you have files that are intended to be hidden from Pyre. logger: Pyre will invoke this exectuable on every run, passing it statistics in JSON format. site_package_search_strategy: Configure how Pyre looks for type checking dependencies installed (e.g. by pip) on the local Python environment. Dependent libraries will not be type-checked, but they are consulted to determine the existence of globals/functions/classes. The value of this option can take one of the following forms: &quot;none&quot;. This indicates that Pyre should not attempt to search for any additional dependencies. Use this option if you know exactly what packages you depend on, and want to manually specify them with the search_path option.&quot;all&quot;. Pyre will pull in the entire site package roots (as specified in the site_roots option) as dependencies. Any libraries installed as site packages, regardless of whether they are typed or not, will be examined. Use this option if you do not know exactly which packages your code depend on, but want to make sure that no dependencies are missing.&quot;pep561&quot;. Similar to &quot;all&quot; but instead of pull in everything, Pyre will only pull in typed packages as dependencies according to rules specified in PEP 561. This is usually the recommended option, as the behavior is closer to what other type checkers would do by default. Note: If incremental check is used, and the search strategy is set to &quot;pep561&quot;, then a pyre restart is needed when new dependencies are installed -- Pyre will not automatically discover the new package by default. This is a limitation of the current implementation of Pyre and it may be lifted in the future. site_roots: List of path to where packages are installed. If not specified, Pyre will consult the current Python interpreter using site.getusersitepackages() and site.getsitepackages(), which should work in most cases. But if your codebase uses a different Python interpreter, you may want to specify this option manually so Pyre knows the correct location to look for site packages. typeshed: Path to the Typeshed standard library, which provides typed stubs for library functions. workers: Number of workers to spawn for multiprocessing. strict: Setting this to true will make strict mode the default in your project. python_version: This is expected to be a string of the form &quot;X.Y.Z&quot; which specifies what version of Python the checked code is expected to be executed with. By default, the version is set to the same as the Python interpreter that runs pyre itself. system_platform: This is expected to be a string that specifies the platform the checked code is expected to be executed on, and should be a legal value for sys.platform. By default, the platform is &quot;linux&quot;. Note: Since Pyre does not run your code, the setting of Python version and platform tends to have relatively small impact on the type checker's behavior. Currently, Pyre only uses Python version and platform to syntactically resolve version conditions of certain form. ","version":"Next","tagName":"h2"},{"title":"Command Line Arguments​","type":1,"pageTitle":"Pyre Configuration","url":"/docs/configuration/#command-line-arguments","content":"You can get a full and current list of options to run Pyre by running pyre --help. The following is a list of commonly used commands and options. ","version":"Next","tagName":"h2"},{"title":"Commands​","type":1,"pageTitle":"Pyre Configuration","url":"/docs/configuration/#commands","content":"Pyre comes with a couple commands that can be invoked with pyre &lt;COMMAND&gt;. The first command you might come in contact with is initialize, init: Initial setup of a configuration for a project. If Watchman is installed, running Pyre with no positional arguments defaults to incremental, otherwise defaults to check. check: Run Pyre end-to-end, i.e. not incrementally.incremental: Run Pyre incrementally. When invoked for the first time, the command will automatically start a server listening to changes to the filesystem. Subsequent invocations will be faster. When Pyre is run incrementally, you can control the Pyre's server working in the background with the following commands. start: Start the Pyre server.stop: Stop the Pyre server.restart: Restart the Pyre server.servers: List all currently running Pyre servers.kill: In case somethign goes wrong and the server becomes unresponsivbe kill will attempt to terminate any processes.rage: Print server logs for debugging or for context when reporting server errors. ","version":"Next","tagName":"h3"},{"title":"Commonly Used Flags​","type":1,"pageTitle":"Pyre Configuration","url":"/docs/configuration/#commonly-used-flags","content":"These flags can be passed in before any of the positional arguments above. For example: $ pyre --source-directory &quot;.&quot; --noninteractive check $ pyre --source-directory &quot;.&quot; restart  --noninteractive: Disable interactive logging, which by default overwrites intermediate logging output and adds colors for a more streamlined user experience. Non-interactive mode ensures all terminal output remains visible. --output {text, json, sarif}: Formatting for error return values. Defaults to text. --search-path SEARCH_PATH: Provide additional stubs or modules external to the project being type-checked. Can also be set in .pyre_configuration. --source-directory SOURCE_DIRECTORY: Provide a path to the source root to check. This can also be specified in .pyre_configuration. --typeshed TYPESHED: Path to the Typeshed standard library, which provides typed stubs for library functions. This can also be set in .pyre_configuration. --version: Print the current version of Pyre. ","version":"Next","tagName":"h3"},{"title":"Helper Commands​","type":1,"pageTitle":"Pyre Configuration","url":"/docs/configuration/#helper-commands","content":"","version":"Next","tagName":"h3"},{"title":"Working with Multi-Project Repositories​","type":1,"pageTitle":"Pyre Configuration","url":"/docs/configuration/#working-with-multi-project-repositories","content":"If you have a single repository with multiple independent Python projects, we recommend you use a separate .pyre_configuration for each one. This allows each project to be type checked independently. If you use virtual environments to manage separate dependencies for each project, you can installpyre as a development dependency in each one; by default Pyre will detect system packages from the environment it is installed in, so this will cause each project to detect the correct dependencies (assuming you activate the virtual environment before running Pyre). ","version":"Next","tagName":"h2"},{"title":"Pyre-Exclusive Features","type":0,"sectionRef":"#","url":"/docs/features/","content":"","keywords":"","version":"Next"},{"title":"Registering attributes using PyTorch's register_buffer​","type":1,"pageTitle":"Pyre-Exclusive Features","url":"/docs/features/#registering-attributes-using-pytorchs-register_buffer","content":"PyTorch allows subclasses of nn.Module to register a buffer in an object using self.register_buffer(&quot;foo&quot;, initial_value). Pyre supports this pattern when used within the constructor. It simply treats the buffer as a Tensor attribute of the class: import torch import torch.nn as nn class Foo(nn.Module): def __init__(self) -&gt; None: super(Foo, self).__init__() self.register_buffer(&quot;foo&quot;, torch.zeros(10, 20)) self.register_buffer(&quot;foo_persistent&quot;, torch.zeros(10, 20), persistent=False) def bar(self) -&gt; None: reveal_type(self.foo) # =&gt; torch.Tensor reveal_type(self.foo_persistent) # =&gt; torch.Tensor def baz() -&gt; None: y = Foo().foo reveal_type(y) # =&gt; torch.Tensor  Note that Pyre will not recognize buffers registered in methods other than the constructor (just like it doesn't recognize attributes defined in methods other than the constructor). It will also not recognize buffers that are initialized with None since it cannot infer the exact type of the buffer. In such a case, you can tell Pyre about the attribute's type by explicitly defining it in the class: import torch import torch.nn as nn from typing import Optional class Foo(nn.Module): my_none_buffer: Optional[torch.Tensor] def __init__(self) -&gt; None: super(Foo, self).__init__() self.register_buffer(&quot;my_none_buffer&quot;, None) def bar(self) -&gt; None: reveal_type(self.my_none_buffer) # =&gt; Optional[torch.Tensor]  ","version":"Next","tagName":"h2"},{"title":"Getting Started with Pyre","type":0,"sectionRef":"#","url":"/docs/getting-started/","content":"","keywords":"","version":"Next"},{"title":"Requirements​","type":1,"pageTitle":"Getting Started with Pyre","url":"/docs/getting-started/#requirements","content":"To get started, you need Python 3.8 or later and watchman working on your system. On MacOS you can get everything with homebrew: $ brew install python3 watchman  On Ubuntu, Mint, or Debian; use apt-get and homebrew: $ sudo apt-get install python3 python3-pip python3-venv watchman  We tested Pyre on Ubuntu 18.04.5 LTS, CentOS 7, as well as OSX 10.11 and later. ","version":"Next","tagName":"h2"},{"title":"Setting up a Project​","type":1,"pageTitle":"Getting Started with Pyre","url":"/docs/getting-started/#setting-up-a-project","content":"We start by creating an empty project directory and setting up a virtual environment: $ mkdir my_project &amp;&amp; cd my_project $ python3 -m venv ~/.venvs/venv $ source ~/.venvs/venv/bin/activate (venv) $ pip install pyre-check  Next, we teach Pyre about our new project: (venv) $ pyre init  This command will set up a configuration for Pyre (.pyre_configuration) as well as watchman (.watchmanconfig) in your project's directory. Accept the defaults for now – you can change them later if necessary. ","version":"Next","tagName":"h2"},{"title":"Running Pyre​","type":1,"pageTitle":"Getting Started with Pyre","url":"/docs/getting-started/#running-pyre","content":"We are now ready to run Pyre: (venv) $ echo &quot;i: int = 'string'&quot; &gt; test.py (venv) $ pyre ƛ Found 1 type error! test.py:1:0 Incompatible variable type [9]: i is declared to have type `int` but is used as type `str`.  This first invocation will start a daemon listening for filesystem changes – type checking your project incrementally as you make edits to the code. You will notice that subsequent invocations of pyre will be faster than the first one. ","version":"Next","tagName":"h2"},{"title":"Introductory Video​","type":1,"pageTitle":"Getting Started with Pyre","url":"/docs/getting-started/#introductory-video","content":" ","version":"Next","tagName":"h2"},{"title":"Further Reading​","type":1,"pageTitle":"Getting Started with Pyre","url":"/docs/getting-started/#further-reading","content":"This page should contain all of the basic information you need to get started with type checking your own project. If you are new to the type system, the introduction to types in Python is recommended reading to familiarize with the type system, gradual typing, and common type errors. If you are looking for more options to configure your type checking experience, the configuration page explores command line and configuration file settings. ","version":"Next","tagName":"h2"},{"title":"Overview","type":0,"sectionRef":"#","url":"/docs/overview/","content":"Overview const Home = () =&gt; { return ; };","keywords":"","version":"Next"},{"title":"pysa_filtering","type":0,"sectionRef":"#","url":"/docs/pysa_filtering/","content":"pysa_filtering","keywords":"","version":"Next"},{"title":"FAQ & Troubleshooting","type":0,"sectionRef":"#","url":"/docs/pyre-faq/","content":"","keywords":"","version":"Next"},{"title":"Pyre Rage​","type":1,"pageTitle":"FAQ & Troubleshooting","url":"/docs/pyre-faq/#pyre-rage","content":"","version":"Next","tagName":"h2"},{"title":"Typeshed & Stubs​","type":1,"pageTitle":"FAQ & Troubleshooting","url":"/docs/pyre-faq/#typeshed--stubs","content":"","version":"Next","tagName":"h2"},{"title":"Additional Resources","type":0,"sectionRef":"#","url":"/docs/pysa-additional-resources/","content":"","keywords":"","version":"Next"},{"title":"Public Talks​","type":1,"pageTitle":"Additional Resources","url":"/docs/pysa-additional-resources/#public-talks","content":"Pysa has been discussed at a number of conferences. These talks provide additional details and motivation for the project: PyCon 2018 - Open sourceing of Pyre and the deeper static analysis (Pysa) that it enablesPyCon 2019 &amp; Security @Scale - Basics of how Pysa worksF8 (at 16:00) - How Pyre works on InstagramDEF CON 28 - Tutorial on how to get started with Pysa We've also shared a blog post on our engineering blog which covers how we developed Pysa, how we use it, how it works, and it's results.  ","version":"Next","tagName":"h2"},{"title":"Installation","type":0,"sectionRef":"#","url":"/docs/installation/","content":"","keywords":"","version":"Next"},{"title":"Binary Distribution​","type":1,"pageTitle":"Installation","url":"/docs/installation/#binary-distribution","content":"You can get Pyre through pypi by running: $ (venv) $ pip install pyre-check  See our Getting Started section for a more detailed example, including setup for a virtual environment. ","version":"Next","tagName":"h2"},{"title":"IDE Integration​","type":1,"pageTitle":"Installation","url":"/docs/installation/#ide-integration","content":"Pyre supports the Language Server Protocol. We provide an extension for VSCode that will automatically try to connect to a running server. You can also directly interact with the LSP by piping the appropriate JSON into pyre persistent. ","version":"Next","tagName":"h2"},{"title":"Building from Source​","type":1,"pageTitle":"Installation","url":"/docs/installation/#building-from-source","content":"These instructions are known to work on Mac OS X (tested on High Sierra through OSX 10.13 - even though binaries are compatible with versions as old as 10.11) and Linux (tested on Ubuntu 16.04 LTS and CentOS 7). ","version":"Next","tagName":"h2"},{"title":"Requirements​","type":1,"pageTitle":"Installation","url":"/docs/installation/#requirements","content":"In addition to Python and watchman, we need a working OCaml compiler. We useOpam to manage our compiler and libraries. You can get Opam via various package management systems. Please follow their instructions for your particular operating system. ","version":"Next","tagName":"h3"},{"title":"Building the OCaml binary​","type":1,"pageTitle":"Installation","url":"/docs/installation/#building-the-ocaml-binary","content":"First, clone the repository from GitHub using: $ git clone https://github.com/facebook/pyre-check  You can complete the setup of your development environment with: $ cd pyre-check $ ./scripts/setup.sh --local  This will compile Pyre and run all the unit tests. This is likely going to take some time on your system. You can now make changes to the code. Run the following commands to compile and test your changes: $ cd source $ make $ make test  ","version":"Next","tagName":"h3"},{"title":"Testing changes to the Python Client​","type":1,"pageTitle":"Installation","url":"/docs/installation/#testing-changes-to-the-python-client","content":"In a virtualenv, install dependencies with requirements.txt and run python tests to make sure everything is set up correctly $ cd /path/to/pyre-check $ pip install -r requirements.txt $ ./scripts/run-python-tests.sh  When installing and running pyre from PyPi, the entry point to the executable is actually client/pyre.py. To be able to run this file from anywhere, add the directory containing the pyre-check directory to the PYTHONPATH environment variable and subsequently assign pyre as an alias for pyre-check.client.pyre. For the pyre command to correctly point to the compiled binary, also set the environment variable PYRE_BINARY to source/build/default/main.exe. $ echo &quot;alias pyre='PYTHONPATH=\\&quot;/path/to/pyre-check/..:\\$PYTHONPATH\\&quot; python -m pyre-check.client.pyre'&quot; &gt;&gt; ~/.bashrc $ echo &quot;export PYRE_BINARY=/path/to/pyre-check/source/_build/default/main.exe&quot; &gt;&gt; ~/.bashrc $ source ~/.bashrc  You should be able to open a new shell and run pyre -h now, confirming pyre was set-up correctly. Any changes made to the Pyre Python client code should be immediately observable the next time you invoke pyre Testing changes for Plugin Development​ VSCode will not pick up your shell aliases, so the alias step in the previous section will not work if you're doing VSCode Plugin development. To get around this, instead of creating an alias, we can create an executable script called pyre and place it in a directory in our PATH: #!/bin/bash PYTHONPATH=&quot;/path/to/pyre-check/..:$PYTHONPATH&quot; python -m pyre-check.client.pyre &quot;$@&quot;  Add the pyre-check/scripts directory to PATH (assuming you placed the above script in that directory) and then use the command pyre to launch the client like before $ echo 'PATH=&quot;/path/to/pyre-check/scripts:$PATH&quot;' &gt;&gt; ~/.bashrc $ source ~/.bashrc  ","version":"Next","tagName":"h3"},{"title":"Building from Docker​","type":1,"pageTitle":"Installation","url":"/docs/installation/#building-from-docker","content":"If you're having issues setting up or your OS is not yet supported, you can also use a Docker image. It runs Debian GNU/Linux 10 (buster) and builds pyre-check from source. Before starting, ensure that Docker is installed on your computer. Clone the pyre-check repository and navigate to the root directory. git clone https://github.com/facebook/pyre-check.git cd pyre-check Build the Docker image with the tag pyre-check (or another tag if you wish) docker build -t pyre-docker . Run the new image in a new container pyre-container (or another name if you wish) docker run \\ --name pyre-container \\ -v /path/to/your/directory:/src \\ -t -i \\ pyre-check Note: Launching the container will build and run all tests. Inside the container, run any Pyre command now with pyre! Note: When initializing Pyre with pyre init, you may have to enter the following paths for the binary and typeshed: ƛ No `pyre.bin` found, enter the path manually: /home/opam/pyre-check/source/_build/default/main.exe ƛ Unable to locate typeshed, please enter its root: /home/opam/pyre-check/stubs/typeshed/typeshed-master  For contributors: Inside the Docker container, the added pyre-check directory is only editable by the root user. To contribute to Pyre, make edits in your local filesystem and rebuild the Docker by running Step 2, then running a new Docker container in Steps 3-4. ","version":"Next","tagName":"h2"},{"title":"Windows Subsystem for Linux (WSL) Install​","type":1,"pageTitle":"Installation","url":"/docs/installation/#windows-subsystem-for-linux-wsl-install","content":"On x86_64 Windows pyre can run via Linux using WSL. A brief summary to get this running on Ubuntu please follow: Install WSL (external Microsoft Documentation)Once you have a login to your Linux of choice: Optionally: Install build environment (some dependencies of pyre might need to be built)Use pip as described above or via a Python Virtual Environment Here is an example using Ubuntu with a venv: $ sudo apt install python3-venv build-essential python3-dev libpython3-dev $ python3 -m venv /tmp/tp $ /tmp/tp/bin/pip install --upgrade pip setuptools wheel $ /tmp/tp/bin/pip install pyre-check $ source /tmp/tp/bin/activate $ cd /mnt/c/path/to/repo $ pyre --source-directory . check $ (tp) cooper@TESTFAC-1FMHLI2:/mnt/c/path/to/repo$ pyre --source-directory . check ƛ Setting up a `.pyre_configuration` with `pyre init` may reduce overhead. ƛ No type errors found  ","version":"Next","tagName":"h2"},{"title":"Coverage Increasing Strategies","type":0,"sectionRef":"#","url":"/docs/pysa-coverage/","content":"","keywords":"","version":"Next"},{"title":"pyre infer​","type":1,"pageTitle":"Coverage Increasing Strategies","url":"/docs/pysa-coverage/#pyre-infer","content":"Pyre comes with a built-in type inference feature. From the root of your project, run pyre infer -r -i to make recursive in-place edits to add type information. Note: There is currently a bug with using the above arguments with the infer feature. The workaround is to break it into two commands: pyre infer pyre infer -i --annotate-from-existing-stubs  ","version":"Next","tagName":"h2"},{"title":"Preprocessors​","type":1,"pageTitle":"Coverage Increasing Strategies","url":"/docs/pysa-coverage/#preprocessors","content":"Pysa comes with a number of preprocessors intended to dynamically generate models for a project. Read this page to learn about the preprocessors that are currently available, and how to write your own. For best results, every entry point to your application (eg. view function for a Django web server) should have a hand written or preprocessor-generated model. ","version":"Next","tagName":"h2"},{"title":"Quick and Dirty Scripts​","type":1,"pageTitle":"Coverage Increasing Strategies","url":"/docs/pysa-coverage/#quick-and-dirty-scripts","content":"Sometimes, code has conventions that convey typing/model information that just needs to be translated to a form Pysa understands. Don't be afraid of quick and dirty scripts to encode that information in a meaningful way. For example, do all your Django view functions live in a file called views.py and have an untyped request argument as the first argument? Can you just do a quick grep + sed to add the HttpRequest type annotation to all of those parameters? Pysa has a ton of pre-written models for HttpRequest, so a small typing change like that can cover a ton of entry points. ","version":"Next","tagName":"h2"},{"title":"Hand Crafted Models​","type":1,"pageTitle":"Coverage Increasing Strategies","url":"/docs/pysa-coverage/#hand-crafted-models","content":"Consider all the ways that your application takes user input, and check to see if Pysa already has models written or not. For example, if you're using Flask as your web server rather than Django, you'll find Pysa doesn't currently have any pre-written models for Flask. You'll need to write some models following the instructions in the previous pages of our docs. If the models are generally useful to others, please consider putting up a pull request to contribute them back to Pysa. ","version":"Next","tagName":"h2"},{"title":"Exploring Taint Models Interactively","type":0,"sectionRef":"#","url":"/docs/pysa-explore/","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Exploring Taint Models Interactively","url":"/docs/pysa-explore/#overview","content":"After Pysa's analysis is complete, the tool will output a detailed JSON with its final view of the taint of callables in addition to the issues it finds. We provide a script to explore these taint models called explore_pysa_models.py, which can give you insight into why Pysa thinks there might or might not be taint for a given callable. ","version":"Next","tagName":"h2"},{"title":"Basic Usage​","type":1,"pageTitle":"Exploring Taint Models Interactively","url":"/docs/pysa-explore/#basic-usage","content":"Before using the explore script, you should already have run Pysa on your codebase. For the purposes of this page, we will assume you stored it in /tmp/output_dir, e.g. $ pyre analyze --save-results-to /tmp/output_dir  After the analysis succeeds, Pysa will write one or multiple taint output files /tmp/output_dir/taint-output.json, containing the taint of each callable in addition to the issues found. Let's load this JSON into our explore script: $ python3 -i ~/fbsource/fbcode/tools/pyre/scripts/explore_pysa_models.py # Pysa Model Explorer Available commands: index('/path/to/results-directory') Index all available models in the given taint output directory. callables_containing('foo.bar') Find all callables containing the given string. callables_matching(r'foo\\..*') Find all callables matching the given regular expression. get_model('foo.bar') Get the model for the given callable. print_model('foo.bar') Pretty print the model for the given callable. Optional parameters: kind='UserControlled' Filter by taint kind. caller_port='result' Filter by caller port. remove_sources=False remove_sinks=False remove_tito=False remove_tito_positions=True remove_features=True remove_leaf_names=True get_issues('foo.bar') Get all issues within the given callable. print_issues('foo.bar') Pretty print the issues within the given callable. print_json({'a': 'b'}) Pretty print json objects with syntax highlighting.  &gt;&gt;&gt; index('/tmp/output_dir') Indexing `/tmp/output_dir/taint-output.json` Indexed 307120 models  Once we've indexed our taint JSON, we're good to go! Let's investigate what models Pysa finds for HttpRequest. First, we'll need to get the full name of the relevant callables: &gt;&gt;&gt; callables_containing('HttpRequest') ['django.http.request.HttpRequest.__init__', 'django.http.request.HttpRequest.body', ...] &gt;&gt;&gt; get_model('django.http.request.HttpRequest.__init_') {'callable': 'django.http.request.HttpRequest.__init__', 'sources': [], 'sinks': [], 'tito': [{'port': 'formal(self)', 'taint': [{'decl': None, 'leaves': [{'kind': 'LocalReturn', 'name': ''}]}]}]}  This (hard-to-parse) JSON is all that Pysa knows about the HttpRequest.__init__ function. If you squint, you'll see that the model doesn't introduce any sources or sinks (as expected), but has taint-in-taint-out for the self parameter. Let's take a look at body, a slightly more interesting function. We'll also swap to using the print_model() function which will pretty print the output: &gt;&gt;&gt; print_model('django.http.request.HttpRequest.body') { &quot;callable&quot;: &quot;django.http.request.HttpRequest.body&quot;, &quot;sources&quot;: [ { &quot;port&quot;: &quot;result&quot;, &quot;taint&quot;: [ { &quot;decl&quot;: null, &quot;kinds&quot;: [ { &quot;kind&quot;: &quot;UserControlled&quot; } ] }, ] } ], &quot;sinks&quot;: [], ...  Much easier to read! This model shows that the body property of HttpRequests returns a UserControlled source. You can also use the get_issues, and corresponding pretty-printing print_issues functions to see all issues in a given callable. Note that the get_issues and get_models functions return Python objects that you can manipulate: &gt;&gt;&gt; print_json(get_issues('foo.bar.log_errors')[0]) # This is valid, will print first issue! ... &gt;&gt;&gt; print_json(get_model('django.http.request.HttpRequest.body')[&quot;sources&quot;]) # Pretty print only the sources. [ { &quot;port&quot;: &quot;result&quot;, &quot;taint&quot;: [ { &quot;decl&quot;: null, &quot;kinds&quot;: [ { &quot;kind&quot;: &quot;UserControlled&quot; } ] }, ] } ]  ","version":"Next","tagName":"h2"},{"title":"Pysa Overview","type":0,"sectionRef":"#","url":"/docs/pysa-basics/","content":"","keywords":"","version":"Next"},{"title":"Taint Analysis​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#taint-analysis","content":"Tainted data is data that must be treated carefully. Pysa works by tracking flows of data from where they originate (sources) to where they terminate in a dangerous location (sinks). For example, we might use it to track flows where user-controllable request data flows into an eval call, leading to a remote code execution vulnerability. This analysis is made possible by user-created models which provide annotations on source code, as well as rules that define which sources are dangerous for which sinks. Pysa comes with many pre-written models and rules for builtin and common python libraries. Pysa propagates taint as operations are performed on tainted data. For example, if we start with a tainted integer and perform a number of operations on it, the end results will still be tainted: x = some_function_that_returns_a_tainted_value() # 'x' is marked as tainted y = x + 10 s = str(x) f = f&quot;Value = {s}&quot; # 'f' is marked with the same taint 'x' had  Pysa will only analyze the code in the repo that it runs on, as well as code in directories listed in the search_path of your.pyre_configuration file. It does not see the source of your dependencies. Just because you can see code in your editor does not mean Pysa has access to that code during analysis. Because of this limitation, Pysa makes some simplifying assumptions. If taint flows into a function Pysa doesn't have the source for, it will assume that the return type of that function has the same taint. This helps prevents false negatives, but can also lead to false positives. When an object is tainted, that means that all attributes of that object are also tainted. Note that this is another source of potential false positives, such as taint flows that include some_obj.__class__. This means that Pysa will detect all of the following flows: x = some_source() # 'x' is marked as tainted some_sink(x) # This is detected some_sink(x.some_attribute) # This is also detected some_sink(x.__class__) # This is (unfortunately) also detected  ","version":"Next","tagName":"h2"},{"title":"Pysa Configuration​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#pysa-configuration","content":"Pysa uses two types of files for configuration: a single taint.config file, and an unlimited number of files with a .pysa extension. The taint.configfile is a JSON document which stores definitions for sources, sinks, features, and rules (discussed below). The .pysa files are model files (also discussed below) which annotate your code with the sources, sinks, and features defined in your taint.config file. Examples of these files can be found in the Pyre repository. These files live in the directory configured by taint_models_path in your.pyre_configuration file. Any .pysa file found in this folder will be parsed by Pysa and the models will be used during the analysis. ","version":"Next","tagName":"h2"},{"title":"Sources​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#sources","content":"Sources are where tainted data originates. They are declared in yourtaint.config file like this: &quot;sources&quot;: [ { &quot;name&quot;: &quot;Cookies&quot;, &quot;comment&quot;: &quot;used to annotate cookie sources&quot; } ]  Models that indicate what is a source are then defined in .pysafiles. Sources are declared with the same syntax as type annotations in Python 3. Function return types, class/model attributes, and even entire classes can be declared as sources by adding TaintSource[SOURCE_NAME] wherever you would add a python type: # Function return source def django.http.request.HttpRequest.get_signed_cookie( self, key, default=..., salt=..., max_age=... ) -&gt; TaintSource[Cookies]: ... # Class attribute source: django.http.request.HttpRequest.COOKIES: TaintSource[Cookies]  When tainting an entire class, any return from a method or access of an attribute of the class will count as a returning tainted data. The specifics of these model files are discussed further in the Models section. # Class source: class BaseException(TaintSource[Exception]): ...  When tainting indexable return types such as Dicts, Lists, and Tuples, theReturnPath syntax can be used to only mark a portion of the return type as tainted: def applies_to_index.only_applies_to_nested() -&gt; TaintSource[Test, ReturnPath[_[0][1]]]: ... def applies_to_index.only_applies_to_a_key() -&gt; TaintSource[Test, ReturnPath[_[&quot;a&quot;]]]: ...  Note that ReturnPath syntax can also be applied to fields of classes and globals, which can be particularly helpful when annotating dictionaries. # Source file: a.py class C: dictionary_field = {&quot;text&quot;: &quot;will_be_tainted&quot;} # Model file: models.pysa a.C.dictionary_field: TaintSource[Test, ReturnPath[_[&quot;text&quot;]]]  See Parameter and Return Path for additional information. ","version":"Next","tagName":"h2"},{"title":"Sinks​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#sinks","content":"Sinks are where tainted data terminates. They are declared in yourtaint.config file like this: &quot;sinks&quot;: [ { &quot;name&quot;: &quot;SQL&quot;, &quot;comment&quot;: &quot;use to annotate places of SQL injection risk&quot; } ]  Models that indicate what is a sink are then defined in .pysa files. Sinks can be added to the same files as sources. Like sources, sinks are declared with the same syntax as type annotations in Python 3. Function parameters, class attributes, and even whole classes can be declared as sinks by addingTaintSink[SINK_NAME] where you would add a python type: # Function parameter sink def sqlite3.dbapi2.Cursor.execute(self, sql: TaintSink[SQL], parameters): ... # Attribute sink file_name.ClassName.attribute_name: TaintSink[RemoteCodeExecution]  When tainting an entire class, any flow into a method or attribute of the class will count as a flow to a taint sink. The specifics of these model files are discussed further in the Models section. # Entire class sink class BaseException(TaintSink[Logging]): ...  ","version":"Next","tagName":"h2"},{"title":"Implicit Sinks​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#implicit-sinks","content":"Implicit sinks are program expressions that we want to act as sinks, but that cannot be specified via taint signatures in .pysa files. Currently, only conditional tests are supported as implicit sinks. This allows writing rules that track whether a particular source is used in a conditional test expression. &quot;implicit_sinks&quot;: { &quot;conditional_test&quot;: [ &lt;your kind&gt; ] }  ","version":"Next","tagName":"h3"},{"title":"Rules​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#rules","content":"Rules declare which flows from source to sink we are concerned about. They are declared in your taint.config file like this: &quot;rules&quot;: [ { &quot;name&quot;: &quot;SQL injection.&quot;, &quot;code&quot;: 1, &quot;sources&quot;: [ &quot;UserControlled&quot; ], &quot;sinks&quot;: [ &quot;SQL&quot; ], &quot;message_format&quot;: &quot;Data from [{$sources}] source(s) may reach [{$sinks}] sink(s)&quot; } ]  Each rule needs a brief name that explains its purpose and a unique code. The rule must define a list of one or more sources, which we are concerned about flowing into one or more sinks. message_format can further explain the issue. When a flow is detected the {$sources} and {$sinks} variables will be replaced with the name of the specific source(s) and sink(s) that were involved in the detected flow. ","version":"Next","tagName":"h2"},{"title":"Sanitizers​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#sanitizers","content":"Sanitizers break a taint flow by removing taint from data. Models that indicate sanitizing functions are defined in .pysa files. Sanitizers can be added to the same files as sources and sinks. Functions are declared as sanitizers by adding a special decorator: # This will remove any taint passing through a function, regardless of whether # it is a taint source returned by this function, taint reaching sinks within # the function via 'text', or taint propagateing through 'text' to the # return value. @Sanitize def django.utils.html.escape(text): ...  This annotation is useful in the case of explicit sanitizers such as escape, which helps prevent cross site scripting (XSS) by escaping HTML characters. The annotation is also useful, however, in cases where a function is not intended to sanitize inputs, but is known to always return safe data despite touching tainted data. One such example could be hmac.digest(key, msg, digest), which returns sufficiently unpredictable data that the output should no longer be considered attacker-controlled after passing through. Sanitizers can also be scoped to only remove taint returned by a function, passing through a specific argument, or passing through all arguments. # This will remove any taint returned by this function, but allow taint # to be passed in to the function via 'argument'. It also prevents taint # from propagating from any argument to the return value. def module.sanitize_return(argument) -&gt; Sanitize: ... # This prevents any taint which passes through 'argument' from reaching a sink within # the function, but allows taint which originates within the function to be returned. def module.sanitize_parameter(argument: Sanitize): ... # This prevents any taint which passes through any parameter from entering the function, # but allows taint which originates within the function to be returned. It also prevents # taint from propagating from any argument to the return value. @Sanitize(Parameters) def module.sanitize_all_parameters(): ... # This will remove any taint which propagates through any argument to the return # value, but allow taint sources to be returned from the function as well as # allow taint to reach sinks within the function via any argument. @Sanitize(TaintInTaintOut) def module.sanitize_tito(a, b, c): ... # Same as before, but only for parameter 'b' def module.sanitize_tito_b(a, b: Sanitize[TaintInTaintOut], c): ...  Pysa also supports only sanitizing specific sources or sinks to ensure that the sanitizers used for a rule don't have adverse effects on other rules. The syntax used is identical to how taint sources and sinks are specified normally: # Sanitizes only the `UserControlled` source kind. def module.return_not_user_controlled() -&gt; Sanitize[TaintSource[UserControlled]]: ... # Sanitizes both the `SQL` and `Logging` sinks. def module.sanitizes_sql_and_logging_sinks( flows_to_sql: Sanitize[TaintSink[SQL]], logged_parameter: Sanitize[TaintSink[Logging]], ): ...  For taint-in-taint-out (TITO) sanitizers, Pysa supports only sanitizing specific sources and sinks through TITO: # With this annotation, whenever `escape(data)` is called, the UserControlled taint of `data` # will be sanitized, whereas other taint that might be present on `data` will be preserved. @Sanitize(TaintInTaintOut[TaintSource[UserControlled]]) def django.utils.html.escape(text): ... @Sanitize(TaintInTaintOut[TaintSink[SQL, Logging]]) def module.sanitize_for_logging_and_sql(): ...  Note that you can use any combination of annotations, i.e sanitizing specific sources or specific sinks, on the return value, a specific parameter or all parameters: def sanitize.sanitize_return() -&gt; Sanitize: ... def sanitize.sanitize_return_no_user_controlled() -&gt; Sanitize[TaintSource[UserControlled]]: ... def sanitize.sanitize_return_no_sql() -&gt; Sanitize[TaintSink[SQL]]: ...  def sanitize.sanitize_parameter(x: Sanitize): ... def sanitize.sanitize_parameter_all_tito(x: Sanitize[TaintInTaintOut]): ... def sanitize.sanitize_parameter_no_user_controlled(x: Sanitize[TaintSource[UserControlled]]): ... def sanitize.sanitize_parameter_no_sql(x: Sanitize[TaintSink[SQL]]): ... def sanitize.sanitize_parameter_no_rce(x: Sanitize[TaintSink[RemoteCodeExecution]]): ... def sanitize.sanitize_parameter_no_user_controlled_tito(x: Sanitize[TaintInTaintOut[TaintSource[UserControlled]]]): ... def sanitize.sanitize_parameter_no_sql_tito(x: Sanitize[TaintInTaintOut[TaintSink[SQL]]]): ...  @Sanitize(Parameters) def sanitize.sanitize_all_parameters(): ... @Sanitize(Parameters[TaintInTaintOut]) def sanitize.sanitize_all_parameters_all_tito(): ... @Sanitize(Parameters[TaintSource[UserControlled]]) def sanitize.sanitize_all_parameters_no_user_controlled(): ... @Sanitize(Parameters[TaintSink[SQL]]) def sanitize.sanitize_all_parameters_no_sql(): ... @Sanitize(Parameters[TaintSink[RemoteCodeExecution]]) def sanitize.sanitize_all_parameters_no_rce(): ... @Sanitize(Parameters[TaintInTaintOut[TaintSource[UserControlled]]]) def sanitize.sanitize_all_parameters_no_user_controlled_tito(): ... @Sanitize(Parameters[TaintInTaintOut[TaintSink[SQL]]]) def sanitize.sanitize_all_parameters_no_sql_tito(): ... @Sanitize(Parameters[TaintInTaintOut[TaintSource[Cookies], TaintSink[SQL]]]) def sanitize.sanitize_all_parameters_no_cookies_sql_tito(): ...  Attributes can also be marked as sanitizers to remove all taint passing through them: django.http.request.HttpRequest.GET: Sanitize  Sanitizing specific sources and sinks can also be used with attributes: def module.Node.id: Sanitize[TaintSource[UserSecrets]] = ... def module.Node.id: Sanitize[TaintSink[Logging]] = ...  Note that sanitizers come with the risk of losing legitimate taint flows. They remove all taint and aren't restricted to a specific rule or individual source to sink flows. This means you need to ensure you aren't potentially affecting other flows when you add a sanitizer for a flow you care about. For this reason, some of the above sanitizer examples might not be a good idea to use. For example, if you are trying to track flows where SQL injection occurs, the escape sanitizer removing all taint kinds would prevent you from seeing any flows where data going into your SQL query happened to be HTML escaped. The best practice with sanitizers, then, is to make them as specific as possible. It's recommended to sanitize specific sources and sinks over using the general @Sanitize, -&gt; Sanitize or: Sanitize annotations. ","version":"Next","tagName":"h2"},{"title":"TITO Sanitizers vs Source/Sink Sanitizers​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#tito-sanitizers-vs-sourcesink-sanitizers","content":"Source/Sink sanitizers are used to sanitize functions belonging to the source/sink trace. Example def render_string_safe(string: str): safe_strings_list = [&quot;safe&quot;, &quot;string&quot;, &quot;list&quot;] if string in safe_strings_list: return render(string) def render_input_view(request: HttpRequest): user_input = request.GET[&quot;user_input&quot;] return render_string_safe(user_input)  Without any sanitizer this code would raise a pysa issue since the UserControlled input is flowing into the render function (imagining that the render function is an XSS sink). To avoid this we can create a model: def render_string_safe(string: Sanitize[TaintSink[XSS]]): ...  This will instruct pysa to remove the XSS taint on the string parameter in this way even if we have a XSS sink (render) inside the render_string_safe function we will not trigger an issue. TITO Sanitizers instead are used to remove the taint when tainted value is flowing into (TaintIn) a function as a parameter and then it is returned (TaintOut) by the same function. def sanitize_string(string: str): return re.sub('[^0-9a-z]+', '*', string) def render_input_view(request: HttpRequest): user_input = request.GET[&quot;user_input&quot;] safe_str = sanitize_string(user_input) return render(safe_str)  Like in the example before this code would generate a Pysa XSS issue. To avoid this we can create a model: def sanitize_string(string: Sanitize[TaintInTaintOut[TaintSink[XSS]]]): ...  This will instruct pysa to remove the XSS taint from the value returned by the sanitize_string when a tainted value is passed as string parameter to the sanitize_string function. ","version":"Next","tagName":"h3"},{"title":"Taint Propagation​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#taint-propagation","content":"Sometimes, Pysa is unable to infer that tainted data provided as an argument to a function will be returned by that function. In such cases, Pysa models can be annotated with TaintInTaintOut[LocalReturn] to encode this information for the analysis. This annotation can be applied to any parameter, including self, and is useful in scenarios such as when retrieving a value from a collection containting tainted data: # This tells Pysa that if a 'dict' contains tainted data, the result # of calling 'get' on that dict will also contain tainted data def dict.get(self: TaintInTaintOut[LocalReturn], key, default): ...  Note that TaintInTaintOut (ie. without square brackets) is also accepted and can be used as a short hand for TaintInTaintOut[LocalReturn]. LocalReturn is only ever required when using the Updates syntax below and wanting to preserve the LocalReturn behaviour. For performance reasons, Pysa does not keep track of when functions place taint into their parameters, such as when a function adds a tainted entry to a list it received (with some notable exceptions for taint assigned to self in a constructor or property). The TaintInTaintOut[Updates[PARAMETER]] annotation can be used to work around Pysa's limitations by telling Pysa that taint will flow the the annotated parameter into the parameter named PARAMETER: # This tells Pysa that if 'dict.update' is called with tainted data, # then the 'self' object (ie. the dictionary itself) should then be # considered tainted. def dict.update(self, __m: TaintInTaintOut[Updates[self]]): ...  Note that constructors and property setters are treated as if they were returning self. This means you should use LocalReturn instead of Updates[self] when writing models those. For instance: def MyClass.__init__(self, argument: TaintInTaintOut[LocalReturn]): ... @foo.setter def MyClass.foo(self, value: TaintInTaintOut[LocalReturn]): ...  Feature annotations may also be placed inside the [] blocks of TaintInTaintOut[...] annotations. ","version":"Next","tagName":"h2"},{"title":"Features​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#features","content":"Feature annotations are also placed in your taint.config and .pysa files. This is a larger topic and will be covered in detail on its own page. ","version":"Next","tagName":"h2"},{"title":"Model files​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#model-files","content":"","version":"Next","tagName":"h2"},{"title":"Usage​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#usage","content":"By default, Pysa computes an inferred model for each function and combines it with any declared models in .pysa files (of which there can be more than one). The union of these models and their annotations will be used. For example, cookies are both user controlled and potentially sensitive to log, and Pysa allows us apply two different annotations to them: django.http.request.HttpRequest.COOKIES: TaintSource[UserControlled] django.http.request.HttpRequest.COOKIES: TaintSource[Cookies]  ","version":"Next","tagName":"h3"},{"title":"Requirements and Features​","type":1,"pageTitle":"Pysa Overview","url":"/docs/pysa-basics/#requirements-and-features","content":"Fully qualified names​ Any declarations in .pysa files must use the fully qualified name for the function/attribute they are attempting to annotate. You can usually find the fully qualified name for a type by looking at how it is imported, however, it's important to note that fully qualified names correspond to where something is declared, not necessarily where it is imported from. For example, you can importHttpRequest directly from the django.http module, even though it is defined indjango.http.request. If you wanted to taint an attribute of HttpRequest, you would need to use the module in which it was defined: django.http.request.HttpRequest.GET: TaintSource[UserControlled]  Matching signatures​ The signature of any modeled function needs to match the signature of the function, as seen by Pyre. Note that Pyre doesn't always see the definition of the functions directly. If .pyi stub files are present, Pyre will use the signatures from those files, rather than the actual signature from the function definition in your or your dependencies' code. See the Gradual Typing page for more info about these .pyi stubs. This matching signature requirement means that all parameters being modelled must be named identically to the parameters in the corresponding code or .pyi file. Unmodelled parameters, *args, and **kwargs may be included, but are not required. When copying parameters to your model, all type information must be removed, and all default values must be elided (see below). If a function includes an * that indicates keyword only parameters, or a / that indicatespositional-only parameters, then that may be included in your model. Note that unlike when modeling named parameters, you need to include all positional only parameters the model so that Pysa knows what position is being tainted. For example, urllib.request.urlopen has the following signature: def urlopen(url, data=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT, *, cafile=None, capath=None, cadefault=False, context=None):  Given that signature, either of the following models are acceptable: def urllib.request.urlopen(url: TaintSink[HTTPClientRequest], data, timeout, *, cafile, capath, cadefault, context): ... def urllib.request.urlopen(url: TaintSink[HTTPClientRequest]): ...  Pysa will complain if the signature of your model doesn't match the implementation. When working with functions defined outside your project, where you don't directly see the source, you can use pyre querywith the signature argument to have Pysa dump it's internal model of a function, so you know exactly how to write your model. Eliding​ As you can see from the above examples, unmodelled parameters and function bodies can both be elided with .... Additionally, type annotations must be entirely omitted (not replaced with ...), even when present on the declaration of the function. This is done to make parsing taint annotations unambiguous. ","version":"Next","tagName":"h3"},{"title":"Feature Annotations","type":0,"sectionRef":"#","url":"/docs/pysa-features/","content":"","keywords":"","version":"Next"},{"title":"Manually Added Features​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#manually-added-features","content":"","version":"Next","tagName":"h2"},{"title":"via Feature Using Via[]​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#via-feature-using-via","content":"The via feature indicates that a flow passed through a point in the code, such as a function parameter, that was annotated with the specified feature name. For example, via:getattr might indicate that the flow passed through a call togetattr Feature names are declared in your taint.config file (the same file as sources/sinks/rules) like this: features: [ { name: &quot;getattr&quot;, comment: &quot;via getattr first parameter&quot; }, { name: &quot;request_files&quot;, comment: &quot;via django request.FILES&quot; } ]  The via feature can be appended to TaintSource and TaintSink annotations to add extra metadata to the specified source and sink flows. It can also be appended to TaintInTaintOut annotations, to add extra metadata to any flow that goes through that annotated function/parameter/attribute. This is done by adding Via[FEATURE_NAME] within square brackets after theTaintXXXX annotation in a model file: # Augmenting TaintSource django.http.request.HttpRequest.FILES: TaintSource[UserControlled, Via[request_files]] = ... # Augmenting TaintInTaintOut def getattr( o: TaintInTaintOut[Via[getattr]], name: TaintSink[GetAttr], default: TaintInTaintOut[LocalReturn], ): ...  Pysa also supports attaching features to inferred flows, which allows you to filter flows passing through a function without having to annotate the taint yourself explicitly, and having the feature attached to all taint flowing through the function. This is done by adding the AttachToSource,AttachToSink, and AttachToTito annotations in a model file: # Attaching taint to sources. def get_signed_cookie() -&gt; AttachToSource[Via[signed]]: ... # Attaching taint to sinks. def HttpResponseRedirect.__init__(self, redirect_to: AttachToSink[Via[redirect]], *args, **kwargs): ... # Attaching taint to taint-in-taint-out models. def attach_features.tito_and_sink(arg: AttachToTito[Via[some_feature_name]]): ...  Pysa additionally supports attaching features to flows irrespective of sources, sinks, and TITO, using the AddFeatureToArgument annotation: def add_feature_to_argument.add_feature_to_first( first: AddFeatureToArgument[Via[string_concat_lhs]], second ): ...  Note that Pysa automatically adds some via features with special meaning. See the Automatic Features section for details. ","version":"Next","tagName":"h3"},{"title":"via-value Feature Using ViaValueOf[]​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#via-value-feature-using-viavalueof","content":"The via-value feature is similar to the via feature, however, it capturesthe value of the specified argument, rather than a feature name. Note that this only works for string literals, boolean literals, numeric literals, and enums. For example, via-value:Access-Control-Allow-Origin might indicate that the string literal Access-Control-Allow-Origin was used to set a header in a Django response. The via-value feature can be added anywhere that the via feature can be added. It is added by specifying ViaValueOf[PARAMETER_NAME], wherePARAMETER_NAME is the name of the function parameter for which you would like to capture the argument value. To continue the above example, this is how you would capture the name of a header being set on a Django HttpResponse: def django.http.response.HttpResponse.__setitem__( self, header: TaintSink[ResponseHeaderName], value: TaintSink[ResponseHeaderValue, ViaValueOf[header]] ): ...  In cases where the argument is not a constant, the feature will appear asvia-value:&lt;unknown:ARGUMENT_TYPE&gt;, where ARGUMENT_TYPE indicates how the argument value is provided at the callsite. For a model such as this: def f (first, second, third) -&gt; TaintSource[Test, ViaValueOf[second]]:...  The following function invocations will produce the features shown in the comments: f(*args) # Generates via-value:&lt;unknown:args&gt; f(**kwargs) # Generates via-value:&lt;unknown:kwargs&gt; f(second=foo) # Generates via-value:&lt;unknown:named&gt; f(foo, bar) # Generates via-value:&lt;unknown:positional&gt; f(*args, **kwargs) # Generates via-value:&lt;unknown:args_or_kwargs&gt;  If the argument is not provided at the call site (e.g, using the default value), the feature will appear as via-value:&lt;missing&gt;. You can also associate a tag with a via-value feature to ensure that differentvia-value annotations don't interfere with each other. Here's how you can retain the information that the name of the header was being set: def django.http.response.HttpResponse.__setitem__( self, header: TaintSink[ResponseHeaderName], value: TaintSink[ResponseHeaderValue, ViaValueOf[header, WithTag[&quot;set-header&quot;]] ): ...  The feature would now appear as via-set-header-value:Access-Control-Allow-Origin. ","version":"Next","tagName":"h3"},{"title":"via-type Feature Using ViaTypeOf[]​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#via-type-feature-using-viatypeof","content":"The via-type feature is nearly identical to the via-value feature, however, it captures the type of the specified argument, rather than it's value. Pysa will retrieve the type information for the argument from Pyre, and add a feature such as &quot;via-type&quot;: &quot;str&quot;, &quot;via-type&quot;: &quot;typing.List[str]&quot;, or &quot;via-type&quot;: &quot;typing.Any&quot; (in the case Pyre doesn't have type information). ViaTypeOf is useful for sinks such as subprocess.run, which acceptsUnion[bytes, str, Sequence] for it's arg parameter. The via-type feature can help identify which type the argument to arg actually had. Knowing the type of the argument can help assess the severity of a given issue (user controlled input in a str passed to arg is much easier to exploit for RCE than user controlled input in one element of a Sequence passed to arg). The via-value feature can be added anywhere that the via feature can be added. It is added by specifying ViaTypeOf[PARAMETER_NAME], wherePARAMETER_NAME is the name of the function parameter for which you would like to capture the argument value: def subprocess.run( args: TaintSink[RemoteCodeExecution, ViaTypeOf[args]], ): ...  The via-type feature can also be used on attribute or global models. For example: my_module.MyClass.source: TaintSource[Test, ViaTypeOf] = ... my_module.MyClass.sink: TaintSource[Test, ViaTypeOf] = ...  A standalone ViaTypeOf is also supported in this case, and is shorthand for TaintInTaintOut[ViaTypeOf]: my_module.MyClass.my_attribute: ViaTypeOf = ...  The via-type feature also supports adding tags, using the same syntax as the via-valuefeature: def subprocess.run( args: TaintSink[RemoteCodeExecution, ViaTypeOf[args, WithTag[&quot;my_tag&quot;]]] ): ... my_module.MyClass.sink: TaintSource[Test, ViaTypeOf[WithTag[&quot;my_tag&quot;]]] = ... my_module.MyClass.other_attribute: ViaTypeOf[WithTag[&quot;my_tag&quot;]] = ...  Note that ViaTypeOf on Annotated types will not include the annotations after the first type specified. This is because Pyre does not store annotations as part of the type information. Consider the following code: from typing import Annotated class Foo: x: Annotated[int, &quot;foo&quot;]  If there is a ViaTypeOf on Foo.x here, the feature shown on traces will be via-type-of:typing.Annotated[int],not via-type-of:typing.Annotated[int, &quot;foo&quot;]. ","version":"Next","tagName":"h3"},{"title":"via-attribute Feature Using ViaAttributeName[]​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#via-attribute-feature-using-viaattributename","content":"The via-attribute feature is similar to the via-value feature, however, it can only be used to model attributes, and captures the name of the attribute being accessed. For instance: my_module.MyClass.my_attribute: ViaAttributeName = ...  Pysa will add the feature &quot;via-attribute:my_attribute when taint flows through the attribute. This also supports tags, using the same syntax as via-value: my_module.MyClass.my_attribute: ViaAttributeName[WithTag[&quot;example&quot;]] = ...  Note that via-attribute is most useful inmodel queries, when the attribute name is not known in advance. ","version":"Next","tagName":"h3"},{"title":"Supporting Features Dynamically Using ViaDynamicFeature[]​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#supporting-features-dynamically-using-viadynamicfeature","content":"In general, Pysa requires you to specify the list of features that are allowed. This encourages features to be documented, and help avoid typos when writing features so that the features propagating in the analysis are consistent with filters you might have on issues. However, there might be very specific cases where you want to dynamically generate features, depending on artifacts of the code. Most cases here can be handled by via-type and via-value features, however, you might be dealing with dynamic code or metadata that the system can't detect. In these cases, Pysa allows skipping validation on features by the use of ViaDynamicFeature. This syntax has identical behavior to Via[] except the lack of validation. Here's an example: def subprocess.run( args: TaintSink[RemoteCodeExecution, ViaDynamicFeature[subprocess_run_execution]] ): ...  ","version":"Next","tagName":"h3"},{"title":"Automatic Features​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#automatic-features","content":"","version":"Next","tagName":"h2"},{"title":"via Feature​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#via-feature","content":"In addition to the manually specified via features, Pysa automatically adds some via features with special meaning such as via:obscure:model, via:obscure:unknown-callee,via:format-string, and via:tito. via:obscure:model means that the flow passed through code that Pysa does not have access to analyze, and thus some taint flow assumptions were made. This can be a useful feature to filter out flows that may be more noisy. via:obscure:unknown-callee means that a call cannot be resolved as the callee is unknown (most likely because of missing type information). via:format-string means that a flow passed through a python f-string (f&quot;Variable: {variable_name}&quot;) or a str.format. Tito stands for taint-in-taint-out which refers to taint flows that enter a function via a parameter and then exit it in some form via the return value. The via:tito feature is attached automatically to all such flows. ","version":"Next","tagName":"h3"},{"title":"type Feature​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#type-feature","content":"The type feature is an automatically added feature which indicates that the flow passes through a conversion to the specified type. This feature currently only tracks conversion to numeric values (ie. type:scalar). This can be useful for filtering out flows when numeric values are highly unlikely to result in an exploitable flow, such as SQL injection or RCE. ","version":"Next","tagName":"h3"},{"title":"first-field Feature​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#first-field-feature","content":"The first-field feature is automatically added to flows for the first field access on the flow. E.g., if request is a source, and the flow starts withrequest.f, then first-field:f should be attached to the flow. ","version":"Next","tagName":"h3"},{"title":"first-index Feature​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#first-index-feature","content":"The first-index feature is an automatically added feature which indicates that a flow starts with a dictionary access using the specified constant as the key. This is useful in cases such as Django's GET/POST/META dictionaries on theHttpRequest object. A flow that started with as access of the HTTP_REFERERheader from the META object would result in the first-index:HTTP_REFERERfeature being added. ","version":"Next","tagName":"h3"},{"title":"has Feature​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#has-feature","content":"The has features is a summary feature for first-field and first-index. Thus, has:first-index simply indicates that there is at least onefirst-index:&lt;name&gt; feature present, and similarly for has:first-field. ","version":"Next","tagName":"h3"},{"title":"always- Modifier on Features​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#always--modifier-on-features","content":"The always- modifier will automatically be added to any of the above features, when every single flow within an issue has the feature. For example, if an issue captures flows from three different sources of user input into a SQL sink, thealways-type:scalar modifier would be added if all three of those flows pass through a conversion to int before reaching the sink. Note that thealways- version of a feature is exclusive with the non-always- version; if always-type:scalar is present, type:scalar will not be present. ","version":"Next","tagName":"h3"},{"title":"broadening Features​","type":1,"pageTitle":"Feature Annotations","url":"/docs/pysa-features/#broadening-features","content":"Pysa automatically adds broadening features whentaint broadening is applied during the analysis. Broadening features are: tito-broadeningmodel-broadeningmodel-source-broadeningmodel-sink-broadeningmodel-tito-broadeningmodel-shapingmodel-source-shapingmodel-sink-shapingmodel-tito-shapingwiden-broadeningissue-broadening See taint broadening for more infomation. ","version":"Next","tagName":"h3"},{"title":"Debugging False Positives and False Negatives","type":0,"sectionRef":"#","url":"/docs/pysa-false-positives-negatives/","content":"","keywords":"","version":"Next"},{"title":"Common Causes of False Positives​","type":1,"pageTitle":"Debugging False Positives and False Negatives","url":"/docs/pysa-false-positives-negatives/#common-causes-of-false-positives","content":"","version":"Next","tagName":"h2"},{"title":"Taint broadening​","type":1,"pageTitle":"Debugging False Positives and False Negatives","url":"/docs/pysa-false-positives-negatives/#taint-broadening","content":"Pysa uses a set of heuristics in order to make the analysis scale to millions of lines of code. The main heuristic is calledtaint broadening (also called taint collapsing), which happens when Pysa is tracking too many attributes of an object or keys of a dictionary. To avoid blowing up, Pysa will collapse taint, and assume the whole object is tainted. Pysa will use sane defaults, but heuristics can betuned using command line options or a taint configuration file. Taint collapsing also happens when taint flows through a function that Pysa does not have the code for. To be sound, it assumes functions without code automatically propagate taint on arguments to their return value. This can be avoided by providing a model for these functions using@SkipObscure. ","version":"Next","tagName":"h3"},{"title":"Common Causes of False Negatives​","type":1,"pageTitle":"Debugging False Positives and False Negatives","url":"/docs/pysa-false-positives-negatives/#common-causes-of-false-negatives","content":"","version":"Next","tagName":"h2"},{"title":"Missing Type Information​","type":1,"pageTitle":"Debugging False Positives and False Negatives","url":"/docs/pysa-false-positives-negatives/#missing-type-information","content":"Pysa relies on type information from Pyre to identify sources and sinks, and to build the call graph needed to follow the propagation of taint between the two. Just because type information is available somewhere in the code, does not mean Pyre will know the type of an object in the exact place where Pysa needs it. See the documentation onCoverage Increasing Strategies for tips on how to increase type coverage. The following examples demonstrate how lost type information leads to lost flows. Missing Sources/Sinks​ HttpRequest.GET is a common source of UserControlled data in Django. If therequest objects are not explicitly typed as HttpRequest, however, Pysa will fail to detect obvious issues: from django.http import HttpRequest def this_is_missed(request): # This flow WILL NOT be found, because Pysa does not know the type of # 'request' at this point and thus does not know 'request.GET' is a source # (even though the type is known in 'run') eval(request.GET[&quot;command&quot;]) def this_is_caught(request: HttpRequest): # This flow WILL be found. eval(request.GET[&quot;command&quot;]) def run(request: HttpRequest): this_is_missed(request) this_is_caught(request)  Incomplete Call Graph​ Pysa relies on type information in order to build a call graph that accurately tracks a method call of foo.bar(x) to the def bar(self, x) implementation. Without type information on bar, Pysa will be unable to figure out how to dispatch the call and the flow will be lost: from django.http import HttpRequest class Runner: def run(self, command: str) -&gt; None: eval(command) def this_is_missed(request: HttpRequest, runner): # This flow WILL NOT be found, because Pysa does not know the type of # 'runner', and thus does not know where the 'run' call dispatches to runner.run(request.GET[&quot;command&quot;]) def this_is_caught(request: HttpRequest, runner: Runner): # This flow WILL be found. runner.run(request.GET[&quot;command&quot;])  ","version":"Next","tagName":"h3"},{"title":"Globals​","type":1,"pageTitle":"Debugging False Positives and False Negatives","url":"/docs/pysa-false-positives-negatives/#globals","content":"To allow for parallel processing, Pysa is limited in it's ability to track taint flows through global variables. For example, Pysa will not detect an issue in the following code: user_controlled_data = &quot;&quot; def load_data(request: HttpRequest) -&gt; None: user_controlled_data = request.GET[&quot;data&quot;] def run_command(request: HttpRequest) -&gt; None: load_data(request) eval(user_controlled_data)  The best workaround is to avoid using globals in your code. If a refactor isn't possible, but you do know what globals should be considered tainted, you can explicitly declare the global tainted in your .pysa files. ","version":"Next","tagName":"h3"},{"title":"Methodology for Debugging False Positives and False Negatives​","type":1,"pageTitle":"Debugging False Positives and False Negatives","url":"/docs/pysa-false-positives-negatives/#methodology-for-debugging-false-positives-and-false-negatives","content":"There are three recommended ways to debug false positives and false negatives. If the analysis is reasonably fast on your code, or that you are able to reproduce the false positive or false negative on a smaller code, you can use the reveal_taint approach. If, instead, the analysis is slow on your code (say, more than 5 minutes) and that you are unable to reproduce on a small example, you can use themodel explorer orSAPP summaries approach. In all cases, you should first: Identify the flow you expect to see (or not see): SourceSinkEvery function call/return that propagates the tainted data from the source to the sinkEvery variable that the tainted data passes through, within the identified functions. This usually includes the parameter which initially received the taint, and then 0 or more local variables that hold the tainted data as it is transformed in some way. ","version":"Next","tagName":"h2"},{"title":"Reveal taint approach​","type":1,"pageTitle":"Debugging False Positives and False Negatives","url":"/docs/pysa-false-positives-negatives/#reveal-taint-approach","content":"This approach is based on the magic functionsreveal_taint andreveal_type. Add a reveal_taint and reveal_type statement to each of the variables that must be tainted (or not), as identified in step 1.Start following the flow from source to sink in your code, and find the corresponding output for each reveal_taint statement. Note that each time Pysa analyzes a function (could be many times), it will dump the latest taint information, so the last instance of reveal_taintoutput for a given line will be the most accurate and is the one you should look at.reveal_taint output exposes some of theimplementation details of Pysa, by giving you Revealed forward taint and Revealed backward taint messages. Without going into those details, you should expect to see either the source name (eg. UserControlled) you care about appearing in theRevealed forward taint output, or the sink name (eg.RemoteCodeExecution) you care about in the Revealed backward taintoutput.For each reveal_taint, following the flow of tainted data from source to sink, locate the output in the logs that reveals the taint (eg.integration_test.reveal_taint:20:4-20:16: Revealed forward taint for ``command``:).If you see your source or sink name in the output, then go back to 1) and carry on with the next reveal_taint statement. If you do not see the source or sink name, then that means the cause of the false negative is likely between your previous reveal_taint and the one you're currently looking at. Refer to the &quot;Commom Causes of False Negatives&quot; section above for ideas on the cause, and how to fix it. ","version":"Next","tagName":"h3"},{"title":"Model explorer approach​","type":1,"pageTitle":"Debugging False Positives and False Negatives","url":"/docs/pysa-false-positives-negatives/#model-explorer-approach","content":"This approach uses the Pysa Model Explorer to interactively explore the taint output results. Perform a full run using the --save-results-to parameters.Start the Pysa Model Explorer. For each function or method identified in step 1, retrieve the fully qualified name of the callable usingcallables_containing, then use print_model(&lt;fully-qualified-name&gt;). If the return variable should be tainted, you should see a source on theresult port.If an argument should be tainted, you should see a sink on a port namedformal(&lt;argument-name&gt;).This should allow you to figure out in which callable the taint is incorrectly lost (for a false negative) or where the taint is incorrectly kept (for a false positive).If you still don't know what is wrong, you can try to add apyre_dump call in a given callable, and run pysa again. This will produce very verbose logs, which might be hard to navigate. ","version":"Next","tagName":"h3"},{"title":"SAPP summaries approach​","type":1,"pageTitle":"Debugging False Positives and False Negatives","url":"/docs/pysa-false-positives-negatives/#sapp-summaries-approach","content":"This approach uses theSAPP Summaries Explorerto interactively explore the taint output results. The approach is the same as &quot;Model explorer approach&quot; but can be done in a graphical way. Upload SAPP Summary for the run which the issue belongs to: Click on the arrow on the top right of the SAPP UI Run page and click Upload Run. Open SAPP Summaries Web UI: After a while refresh the run page and you should see Available: Load in VS Code or View on Web. Click on the View on Web link which brings you to a UI where you'll insert the fully qualified domain name of the functions you want to review Identify the frame/function where the taint flow was interrupted reviewing the sink trace: Start from the sink (last frame) and use SAPP Summary check if the last frame function has the correct taint associated with the correct parameter (formal). For example in (this)[https://fburl.com/security/4dmlih2v] issue check in SAPP Summary if inweather.service.WeatherAPIService.async_current_weather_api_json sinkslist the parameter self[lng] is tainted with the sink kind we want to track in the issue (in our example HTTPClientRequestSchematized_URI). If this is the case repeat the same process for the next frame (weather.service.WeatherAPIService._async_get_current_weather_from_api ) until reaching a function which does not propagate the taint correctly (move to point 5) or the Trace Root Callable (move to point 4). Identify the frame/function where the taint flow was interrupted reviewing the source trace: Apply the same process starting from the source and checking the correct taint propagation in the result value of SAPP summary (value returned by the function). Example (issue)[https://fburl.com/security/dh4wowfm] we start fromusers.user_phone_fetcher.UserPhoneFetcher.async_get_phone_number_node(which is the first frame) and check if SAPP summary is correctly showing theNodeEdgeGetter source in the result port (which represent the return value of the function). If this is the case repeat the same process for the next frame until reaching a function which does not propagate the taint correctly. Identify the root cause: Check recent changes to the code which may have altered Pysa ability to track the taint or simply deleted the flowManually review the code and see if there are patterns described incommon causes of false negatives or in open pysa false negatives/false positive tasks (tags pysa-bug andfalse-negative/false-positive or child tasks of T145051608). ","version":"Next","tagName":"h3"},{"title":"Example using reveal_taint​","type":1,"pageTitle":"Debugging False Positives and False Negatives","url":"/docs/pysa-false-positives-negatives/#example-using-reveal_taint","content":"Pysa will not be able to detect a vulnerability in the following code: from django.http import HttpRequest, HttpResponse class Runner: def run(self, command: str) -&gt; None: eval(command) def get_command(request: HttpRequest) -&gt; str: command = request.GET[&quot;command&quot;] return command def execute_command(runner: Runner, command): runner.run(command) def start(request: HttpRequest): command = get_command(request) runner = Runner() execute_command(runner, command)  Folling the above debugging steps we identify the flow of data from beginning to end, and add debugging statements: from django.http import HttpRequest, HttpResponse class Runner: def run(self, command: str) -&gt; None: reveal_type(command) reveal_taint(command) eval(command) # 5. User controlled data reaches the sink in here def get_command(request: HttpRequest) -&gt; str: command = request.GET[&quot;command&quot;] # 1. User controlled data originates here reveal_type(command) reveal_taint(command) return command def execute_command(runner: Runner, command): reveal_type(command) reveal_taint(command) reveal_type(runner) reveal_taint(runner) runner.run(command) # 4. User controlled data is passed in here def start(request: HttpRequest): command = get_command(request) # 2. User controlled data is returned here reveal_type(command) reveal_taint(command) runner = Runner() execute_command(runner, command) # 3. User controlled data is passed in here  See the appendix for the full output of running pyre --noninteractive analyzeon this example. Starting at 1), we see this in the output: 2020-12-28 13:02:36,486 [PID 3382063] WARNING integration_test.reveal_taint:13:4-13:16: Revealed forward taint for `command`: @integration_test.reveal_taint:11:14-11:25 -&gt; UserControlled -&gt; SimpleFeature: [Features.Simple.LeafName {leaf = &quot;Obj{django.http.request.HttpRequest.GET}&quot;; 2020-12-28 13:02:36,486 [PID 3382063] WARNING port = None}], ComplexFeature: [], TraceLength: 0, FirstIndex: [&quot;command&quot;], FirstField: [] 2020-12-28 13:02:36,486 [PID 3382063] WARNING UserControlled_Payload -&gt; SimpleFeature: [Features.Simple.LeafName {leaf = &quot;Obj{django.http.request.HttpRequest.GET}&quot;; 2020-12-28 13:02:36,486 [PID 3382063] WARNING port = None}], ComplexFeature: [], TraceLength: 0, FirstIndex: [&quot;command&quot;], FirstField: [] 2020-12-28 13:02:36,486 [PID 3382063] WARNING 2020-12-28 13:02:36,486 [PID 3382063] WARNING integration_test.reveal_taint:13:4-13:25: Revealed backward taint for `command`: declaration -&gt; LocalReturn -&gt; SimpleFeature: [], ComplexFeature: [(Features.Complex.ReturnAccessPath [])], TraceLength: 4611686018427387903, FirstIndex: [], FirstField: []  Removing the timestamps and other noise gives us: integration_test.reveal_taint:13:4-13:16: Revealed forward taint for `command`: @integration_test.reveal_taint:11:14-11:25 -&gt; UserControlled -&gt; SimpleFeature: [ Features.Simple.LeafName { leaf = &quot;Obj{django.http.request.HttpRequest.GET}&quot;; port = None } ], ComplexFeature: [], TraceLength: 0, FirstIndex: [&quot;command&quot;], FirstField: [] UserControlled_Payload -&gt; SimpleFeature: [ Features.Simple.LeafName { leaf = &quot;Obj{django.http.request.HttpRequest.GET}&quot;; port = None } ], ComplexFeature: [], TraceLength: 0, FirstIndex: [&quot;command&quot;], FirstField: [] integration_test.reveal_taint:13:4-13:25: Revealed backward taint for `command`: declaration -&gt; LocalReturn -&gt; SimpleFeature: [], ComplexFeature: [(Features.Complex.ReturnAccessPath [])], TraceLength: 4611686018427387903, FirstIndex: [], FirstField: []  For debugging false negatives, the only portion we care about is:  Revealed forward taint for `command`: @integration_test.reveal_taint:11:14-11:25 -&gt; UserControlled  This confirms that on line 11 (characters 14-25), we did indeed detect thatcommand was tainted as UserControlled. Moving on to 2, the forward taint output again tells us that we haveUserControlled taint on command at line 26 (characters 4-16). Starting with 4, we notice that we no longer see UserControlled orRemoteCodeExecution in our revealed forward or backwards taint: 2020-12-28 13:02:35,472 [PID 3382063] WARNING integration_test.reveal_taint:18:4-18:16: Revealed forward taint for `command`: 2020-12-28 13:02:35,472 [PID 3382063] WARNING 2020-12-28 13:02:35,472 [PID 3382063] WARNING integration_test.reveal_taint:18:4-18:25: Revealed backward taint for `command`: 2020-12-28 13:02:35,472 [PID 3382063] WARNING  This has helped us narrow down the problem to the execute_command function. In the end, the problem was that we did not have type information on runner, so Pysa did not know where the definition of runner.run was. Without knowing where the definition was, Pysa couldn't know that run containted a sink and thus couldn't know that command eventually reached that sink. ","version":"Next","tagName":"h3"},{"title":"Appendix​","type":1,"pageTitle":"Debugging False Positives and False Negatives","url":"/docs/pysa-false-positives-negatives/#appendix","content":"Subset of the output from running pyre --noninteractive analyze on the example: 2020-12-28 13:02:31,719 [PID 3382063] PERFORMANCE Overrides recorded: 2.408138s 2020-12-28 13:02:31,719 [PID 3382063] INFO Building call graph... 2020-12-28 13:02:34,166 [PID 3382063] PERFORMANCE Call graph built: 2.447174s 2020-12-28 13:02:34,166 [PID 3382063] INFO Call graph edges: 100 2020-12-28 13:02:34,166 [PID 3382063] INFO Computing overrides... 2020-12-28 13:02:34,311 [PID 3382063] PERFORMANCE Computed overrides: 0.144886s 2020-12-28 13:02:34,311 [PID 3382063] PERFORMANCE Pre-fixpoint computation for static analysis: 7.664068s 2020-12-28 13:02:34,311 [PID 3382063] INFO Analysis fixpoint started for 3075 overrides 68 functions... 2020-12-28 13:02:34,311 [PID 3382063] INFO Iteration #0. 3143 Callables [...] 2020-12-28 13:02:35,471 [PID 3382063] WARNING integration_test.reveal_taint:6:8-6:19: Revealed type for command: str 2020-12-28 13:02:35,471 [PID 3382063] WARNING integration_test.reveal_taint:7:8-7:20: Revealed forward taint for `command`: 2020-12-28 13:02:35,471 [PID 3382063] WARNING 2020-12-28 13:02:35,471 [PID 3382063] WARNING integration_test.reveal_taint:7:8-7:29: Revealed backward taint for `command`: @integration_test.reveal_taint:8:13-8:20 -&gt; RemoteCodeExecution -&gt; SimpleFeature: [Features.Simple.LeafName {leaf = &quot;eval&quot;; port = None}], ComplexFeature: [], TraceLength: 0, FirstIndex: [], FirstField: [] 2020-12-28 13:02:35,472 [PID 3382063] WARNING 2020-12-28 13:02:35,472 [PID 3382063] WARNING integration_test.reveal_taint:17:4-17:15: Revealed type for command: typing.Any 2020-12-28 13:02:35,472 [PID 3382063] WARNING integration_test.reveal_taint:18:4-18:16: Revealed forward taint for `command`: 2020-12-28 13:02:35,472 [PID 3382063] WARNING 2020-12-28 13:02:35,472 [PID 3382063] WARNING integration_test.reveal_taint:19:4-19:15: Revealed type for command: typing.Any 2020-12-28 13:02:35,472 [PID 3382063] WARNING integration_test.reveal_taint:20:4-20:16: Revealed forward taint for `command`: 2020-12-28 13:02:35,472 [PID 3382063] WARNING 2020-12-28 13:02:35,472 [PID 3382063] WARNING integration_test.reveal_taint:20:4-20:25: Revealed backward taint for `command`: 2020-12-28 13:02:35,472 [PID 3382063] WARNING 2020-12-28 13:02:35,472 [PID 3382063] WARNING integration_test.reveal_taint:18:4-18:25: Revealed backward taint for `command`: 2020-12-28 13:02:35,472 [PID 3382063] WARNING 2020-12-28 13:02:35,473 [PID 3382063] WARNING integration_test.reveal_taint:12:4-12:15: Revealed type for command: str 2020-12-28 13:02:35,473 [PID 3382063] WARNING integration_test.reveal_taint:13:4-13:16: Revealed forward taint for `command`: @integration_test.reveal_taint:11:14-11:25 -&gt; UserControlled -&gt; SimpleFeature: [Features.Simple.LeafName {leaf = &quot;Obj{django.http.request.HttpRequest.GET}&quot;; 2020-12-28 13:02:35,473 [PID 3382063] WARNING port = None}], ComplexFeature: [], TraceLength: 0, FirstIndex: [&quot;command&quot;], FirstField: [] 2020-12-28 13:02:35,473 [PID 3382063] WARNING UserControlled_Payload -&gt; SimpleFeature: [Features.Simple.LeafName {leaf = &quot;Obj{django.http.request.HttpRequest.GET}&quot;; 2020-12-28 13:02:35,473 [PID 3382063] WARNING port = None}], ComplexFeature: [], TraceLength: 0, FirstIndex: [&quot;command&quot;], FirstField: [] 2020-12-28 13:02:35,473 [PID 3382063] WARNING 2020-12-28 13:02:35,473 [PID 3382063] WARNING integration_test.reveal_taint:13:4-13:25: Revealed backward taint for `command`: declaration -&gt; LocalReturn -&gt; SimpleFeature: [], ComplexFeature: [(Features.Complex.ReturnAccessPath [])], TraceLength: 4611686018427387903, FirstIndex: [], FirstField: [] 2020-12-28 13:02:35,473 [PID 3382063] WARNING 2020-12-28 13:02:35,480 [PID 3382063] WARNING integration_test.reveal_taint:25:4-25:15: Revealed type for command: str 2020-12-28 13:02:35,480 [PID 3382063] WARNING integration_test.reveal_taint:26:4-26:16: Revealed forward taint for `command`: via call@integration_test.reveal_taint:24:14-24:34[integration_test.reveal_taint.get_command][{ root = LocalResult; path = [] }] -&gt; UserControlled -&gt; SimpleFeature: [Features.Simple.LeafName {leaf = &quot;Obj{django.http.request.HttpRequest.GET}&quot;; 2020-12-28 13:02:35,480 [PID 3382063] WARNING port = None}], ComplexFeature: [], TraceLength: 1, FirstIndex: [&quot;command&quot;], FirstField: [] 2020-12-28 13:02:35,480 [PID 3382063] WARNING UserControlled_Payload -&gt; SimpleFeature: [Features.Simple.LeafName {leaf = &quot;Obj{django.http.request.HttpRequest.GET}&quot;; 2020-12-28 13:02:35,480 [PID 3382063] WARNING port = None}], ComplexFeature: [], TraceLength: 1, FirstIndex: [&quot;command&quot;], FirstField: [] 2020-12-28 13:02:35,480 [PID 3382063] WARNING 2020-12-28 13:02:35,481 [PID 3382063] WARNING integration_test.reveal_taint:26:4-26:25: Revealed backward taint for `command`: 2020-12-28 13:02:35,481 [PID 3382063] WARNING 2020-12-28 13:02:35,546 [PID 3382063] PERFORMANCE Expensive callables for iteration 0: 2020-12-28 13:02:35,577 [PID 3382063] INFO Iteration #0, 3143 callables, heap size 46105024 took 1.266790s 2020-12-28 13:02:35,578 [PID 3382063] INFO Iteration #1. 3038 Callables [...] 2020-12-28 13:02:36,482 [PID 3382063] WARNING integration_test.reveal_taint:6:8-6:19: Revealed type for command: str 2020-12-28 13:02:36,482 [PID 3382063] WARNING integration_test.reveal_taint:7:8-7:20: Revealed forward taint for `command`: 2020-12-28 13:02:36,483 [PID 3382063] WARNING 2020-12-28 13:02:36,483 [PID 3382063] WARNING integration_test.reveal_taint:7:8-7:29: Revealed backward taint for `command`: @integration_test.reveal_taint:8:13-8:20 -&gt; RemoteCodeExecution -&gt; SimpleFeature: [Features.Simple.LeafName {leaf = &quot;eval&quot;; port = None}], ComplexFeature: [], TraceLength: 0, FirstIndex: [], FirstField: [] 2020-12-28 13:02:36,483 [PID 3382063] WARNING 2020-12-28 13:02:36,486 [PID 3382063] WARNING integration_test.reveal_taint:12:4-12:15: Revealed type for command: str 2020-12-28 13:02:36,486 [PID 3382063] WARNING integration_test.reveal_taint:13:4-13:16: Revealed forward taint for `command`: @integration_test.reveal_taint:11:14-11:25 -&gt; UserControlled -&gt; SimpleFeature: [Features.Simple.LeafName {leaf = &quot;Obj{django.http.request.HttpRequest.GET}&quot;; 2020-12-28 13:02:36,486 [PID 3382063] WARNING port = None}], ComplexFeature: [], TraceLength: 0, FirstIndex: [&quot;command&quot;], FirstField: [] 2020-12-28 13:02:36,486 [PID 3382063] WARNING UserControlled_Payload -&gt; SimpleFeature: [Features.Simple.LeafName {leaf = &quot;Obj{django.http.request.HttpRequest.GET}&quot;; 2020-12-28 13:02:36,486 [PID 3382063] WARNING port = None}], ComplexFeature: [], TraceLength: 0, FirstIndex: [&quot;command&quot;], FirstField: [] 2020-12-28 13:02:36,486 [PID 3382063] WARNING 2020-12-28 13:02:36,486 [PID 3382063] WARNING integration_test.reveal_taint:13:4-13:25: Revealed backward taint for `command`: declaration -&gt; LocalReturn -&gt; SimpleFeature: [], ComplexFeature: [(Features.Complex.ReturnAccessPath [])], TraceLength: 4611686018427387903, FirstIndex: [], FirstField: [] 2020-12-28 13:02:36,486 [PID 3382063] WARNING 2020-12-28 13:02:36,486 [PID 3382063] WARNING integration_test.reveal_taint:25:4-25:15: Revealed type for command: str 2020-12-28 13:02:36,486 [PID 3382063] WARNING integration_test.reveal_taint:26:4-26:16: Revealed forward taint for `command`: via call@integration_test.reveal_taint:24:14-24:34[integration_test.reveal_taint.get_command][{ root = LocalResult; path = [] }] -&gt; UserControlled -&gt; SimpleFeature: [Features.Simple.LeafName {leaf = &quot;Obj{django.http.request.HttpRequest.GET}&quot;; 2020-12-28 13:02:36,486 [PID 3382063] WARNING port = None}], ComplexFeature: [], TraceLength: 1, FirstIndex: [&quot;command&quot;], FirstField: [] 2020-12-28 13:02:36,486 [PID 3382063] WARNING UserControlled_Payload -&gt; SimpleFeature: [Features.Simple.LeafName {leaf = &quot;Obj{django.http.request.HttpRequest.GET}&quot;; 2020-12-28 13:02:36,487 [PID 3382063] WARNING port = None}], ComplexFeature: [], TraceLength: 1, FirstIndex: [&quot;command&quot;], FirstField: [] 2020-12-28 13:02:36,487 [PID 3382063] WARNING 2020-12-28 13:02:36,492 [PID 3382063] WARNING integration_test.reveal_taint:26:4-26:25: Revealed backward taint for `command`: 2020-12-28 13:02:36,492 [PID 3382063] WARNING 2020-12-28 13:02:36,552 [PID 3382063] PERFORMANCE Expensive callables for iteration 1: 2020-12-28 13:02:36,585 [PID 3382063] INFO Iteration #1, 3038 callables, heap size 46521728 took 1.007461s 2020-12-28 13:02:36,585 [PID 3382063] INFO Iteration #2. 23 Callables [...] 2020-12-28 13:02:37,018 [PID 3382063] PERFORMANCE Expensive callables for iteration 2: 2020-12-28 13:02:37,018 [PID 3382063] INFO Iteration #2, 23 callables, heap size 46530432 took 0.432597s 2020-12-28 13:02:37,018 [PID 3382063] INFO Iteration #3. 2 Callables [integration_test.string_concatenation.bad_1 (fun), integration_test.string_concatenation.bad_2 (fun)] 2020-12-28 13:02:37,130 [PID 3382063] PERFORMANCE Expensive callables for iteration 3: 2020-12-28 13:02:37,131 [PID 3382063] INFO Iteration #3, 2 callables, heap size 46532352 took 0.113038s 2020-12-28 13:02:37,131 [PID 3382063] INFO Iteration #4. 0 Callables [] 2020-12-28 13:02:37,131 [PID 3382063] INFO Fixpoint iterations: 4 2020-12-28 13:02:37,348 [PID 3382063] PERFORMANCE Analysis fixpoint complete: 3.037628s 2020-12-28 13:02:37,369 [PID 3382063] PERFORMANCE Analyze: 18.289002s  ","version":"Next","tagName":"h2"},{"title":"Implementation Details","type":0,"sectionRef":"#","url":"/docs/pysa-implementation-details/","content":"","keywords":"","version":"Next"},{"title":"Summaries​","type":1,"pageTitle":"Implementation Details","url":"/docs/pysa-implementation-details/#summaries","content":"Pysa works by computing summaries of all functions. Summaries describe: Which function arguments hit sinksWhich sources the function returnsWhich arguments propagate their taint to the return value in some way These summaries cover the entire call graph of the function. Covering the entire call graph means that if foo calls bar, foo's summary will include information on sources and sinks that are reachable in bar. ","version":"Next","tagName":"h2"},{"title":"Iteration​","type":1,"pageTitle":"Implementation Details","url":"/docs/pysa-implementation-details/#iteration","content":"Pysa's summary inference process is iterative. Summaries must be continually recomputed until a global fixed point is reached. The fixed point occurs when an entire iteration is completed without any summary changing. Pysa uses a call dependency graph to determine which functions need to be re-analyzed after a given iteration (ie. if foo calls bar, and bar's summary changed last iteration, foo must be reanalyzed this iteration to see if it's summary will also change). ","version":"Next","tagName":"h3"},{"title":"Source Summaries​","type":1,"pageTitle":"Implementation Details","url":"/docs/pysa-implementation-details/#source-summaries","content":"The source portion of summaries track how data from a source is eventually returned by a function. To compute the source portion of a summary, Pysa must start with a model such as this one that states source returns tainted data of type UserControlled: def source() -&gt; TaintSource[UserControlled]: ...  Then Pysa can analyze the source code of a function such as returns_source and infer that it will also return taint of type UserControlled: def returns_source(): return source()  This inference results in a summary for returns_source, which we can conceptually think of as an inferred model like this: def returns_source() -&gt; TaintSource[UserControlled]: ...  Pysa's next iteration can start with that summary for returns_source, and use it when anlyzing the code for wraps_source: def wraps_source(): return returns_source()  From this code, Pysa can infer a model documenting that wraps_source will also end up (indirectly) returning taint of type UserControlled: def wraps_source() -&gt; TaintSource[UserControlled]  ","version":"Next","tagName":"h3"},{"title":"Sink Summaries​","type":1,"pageTitle":"Implementation Details","url":"/docs/pysa-implementation-details/#sink-summaries","content":"The sink portion of summaries track how arguments to a function eventually flow into a sink. To compute the sink portion of a summary, Pysa must start with a model such as this one that states sink's parameter arg is as anRemoteCodeExecution sink: def sink(arg: TaintSink[RemoteCodeExecution]): ...  Then Pysa can analyze the source code of a function such as calls_sink and infer that calls_sink's arg will also end up in a RemoteCodeExecutionsink: def calls_sink(arg): sink(arg)  This inference results in a summary for calls_sink, which we can conceptually think of as an inferred model like this: def calls_sink(arg: TaintSink[RemoteCodeExecution]): ...  Pysa's next iteration can start with that summary for calls_sink, and use it when anlyzing the code for wraps_sink: def wraps_sink(arg): calls_sink(arg)  From this code, Pysa can infer a model documenting that wraps_sink's argwill also end up (indirectly) reaching an RemoteCodeExecution sink: def wraps_sink(arg: TaintSink[RemoteCodeExecution]): ...  ","version":"Next","tagName":"h3"},{"title":"Taint In Taint Out (TITO) Summaries​","type":1,"pageTitle":"Implementation Details","url":"/docs/pysa-implementation-details/#taint-in-taint-out-tito-summaries","content":"Pysa summaries also track how tainted data propagates from function arguments into that function's return value. This is known as Taint In Taint Out (TITO). When computing the TITO portion of summaries, Pysa does not need to start from a model at all (however, an explicit TaintInTaintOutmodel can be written, if desired). Pysa can simply start by looking at the source code for a function like tito and inferring that it's arg parameter gets propagated to the return value of the function: def tito(arg): return arg  This inference results in a summary for tito, which we can conceptually think of as an inferred model like this: def tito(arg: TaintInTaintOut): ...  Pysa's next iteration can start with that summary for tito, and use it when anlyzing the code for wraps_tito: def wraps_tito(arg): return tito(arg)  From this code, Pysa can infer a model documenting that wraps_tito's argwill also end up (indirectly) propagated to the return value of the function: def wraps_tito(arg: TaintInTaintOut): ...  ","version":"Next","tagName":"h3"},{"title":"Emitting Issues​","type":1,"pageTitle":"Implementation Details","url":"/docs/pysa-implementation-details/#emitting-issues","content":"An issue indicates that Pysa has found a flow of data from a source to a sink (for any source-sink pair specified in a rule). Issues occur in the function where summaries indicate data from a source is returned from one function and is then passed into another function whose argument reaches a sink. This means issues often unintuitively occur in a function that is somewhere in the middle of the flow from source to sink. Continuing the previous examples, Pysa can use the summaries computed forwraps_source, wraps_sink, and wraps_tito to identify an issue infind_issue: def find_issue(): x = wraps_source() # x: TaintSource[UserControlled] y = wraps_tito(x) # y: TaintSource[UserControlled] wraps_sink(y) # Issue!  The summary for wraps_source tells Pysa the return value is tainted data of type UserControlled, and thus x is marked as UserControlled. The summary for wraps_tito tells Pysa that tainted data passed in through arg will be propagated to the return value, and thus y is marked with the same taint asx (UserControlled). Finally, the summary of wraps_sink tells Pysa that data passed into arg eventually reaches a sink of kind RemoteCodeExecution. Assuming we have a rule that says we want to find flows from UserControlledto RemoteCodeExecution, Pysa will then emit an issue on the line wherewraps_sink is called with the UserControlled data in y. ","version":"Next","tagName":"h2"},{"title":"Visualizing Issues​","type":1,"pageTitle":"Implementation Details","url":"/docs/pysa-implementation-details/#visualizing-issues","content":"Visualizing the flow of data in a given issue ends up looking something like this:  Overall, the traces form an inverted V, with sources and sinks connecting at the apex. There can be multiple sources for an issue, because two different sources can both end up combined into a single return value for a function. Similarly, there can be multiple sinks because a single argument to a function could be passed into two different sinks. The TITO process appears as a loop in this visualization, because data passed into a TITO function will always end up back in the original function via the return value of the TITO function. ","version":"Next","tagName":"h2"},{"title":"Dynamically Generating Models","type":0,"sectionRef":"#","url":"/docs/pysa-model-generators/","content":"","keywords":"","version":"Next"},{"title":"Running Model Generators​","type":1,"pageTitle":"Dynamically Generating Models","url":"/docs/pysa-model-generators/#running-model-generators","content":"The majority of model generators require access to a running environment. For example, the RESTApiSourceGenerator needs to be able to access urlpatternsconfigured for Django, meaning it has to import (and implicitly run) the file you use to configure routing. The recommended way to run model generators is to set up a small script within your repository that can run within the virtual environment for your project. This tutorial exerciseprovides an example of how to setup and use model generators. ","version":"Next","tagName":"h2"},{"title":"Example Model Generators​","type":1,"pageTitle":"Dynamically Generating Models","url":"/docs/pysa-model-generators/#example-model-generators","content":"The set of model generators is always changing, but below are some examples of model generators which are currently provided out of the box with Pysa. ","version":"Next","tagName":"h2"},{"title":"RESTApiSourceGenerator​","type":1,"pageTitle":"Dynamically Generating Models","url":"/docs/pysa-model-generators/#restapisourcegenerator","content":"This model generator is intended to taint all arguments to Django view functions asUserControlled. This is useful when you have views that receive user-controlled data as arguments separate from the HttpRequest parameter, such as when capturing values from the request path. ","version":"Next","tagName":"h3"},{"title":"ExitNodeGenerator​","type":1,"pageTitle":"Dynamically Generating Models","url":"/docs/pysa-model-generators/#exitnodegenerator","content":"This generator is intended to taint all data returned from Django view functions asReturnedToUser. This is useful when you have decorators which allow your view functions to return raw python types, rather than HttpResponse objects. Note that you do not need this generator if you always construct HttpResponseobjects, because they are already annotated as ReturnedToUser sinks. ","version":"Next","tagName":"h3"},{"title":"GraphQLSourceGenerator​","type":1,"pageTitle":"Dynamically Generating Models","url":"/docs/pysa-model-generators/#graphqlsourcegenerator","content":"This model generator is similar to the RESTApiSourceGenerator andExitNodeGenerator discussed above, but it is intended to generate models withUserControlled and ReturnedToUser annotations for graphene-style GraphQLresolver functions. ","version":"Next","tagName":"h3"},{"title":"AnnotatedFreeFunctionWithDecoratorGenerator​","type":1,"pageTitle":"Dynamically Generating Models","url":"/docs/pysa-model-generators/#annotatedfreefunctionwithdecoratorgenerator","content":"This model generator provides general purpose functionality to annotate all free functions which have a given decorator. The annotations can be used to mark any of the function's arguments or return types as sources, sinks, features, etc. This is useful whenever you have a function which modifies taint analysis expectations. For example, if you had a decorator which applies rate limiting to functions, you could use this model generator to add a feature to all flow passing through rate limited functions, to enable you to filter them out from a given rule. ","version":"Next","tagName":"h3"},{"title":"Writing Model Generators​","type":1,"pageTitle":"Dynamically Generating Models","url":"/docs/pysa-model-generators/#writing-model-generators","content":"All model generator code lives intools/generate_taint_modelswithin the pyre-check repository. ","version":"Next","tagName":"h2"},{"title":"Adding a new model generator​","type":1,"pageTitle":"Dynamically Generating Models","url":"/docs/pysa-model-generators/#adding-a-new-model-generator","content":"This commitprovides an example of how to add a new model generator. The basic workflow is: Create a new file under generate_taint_models of the form get_&lt;pattern of model&gt;.Write a class that inherits from ModelGenerator.Collect all the callables you're interested in modeling via gather_functions_to_model.Convert the callables you've collected into models. The CallableModel class is a convenience that pretty prints things in the right way - you just need to specify what kind of taint the parameters and return value should have, specify the callable to model, and call generate().Write unit tests (example).Import your new class in the __init__ file (example).  ","version":"Next","tagName":"h3"},{"title":"Advanced Topics","type":0,"sectionRef":"#","url":"/docs/pysa-advanced/","content":"","keywords":"","version":"Next"},{"title":"Conditional models based on Python version​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#conditional-models-based-on-python-version","content":"Pysa models support if conditions but only for version comparisons for the python version used to run pysa. This allows for conditional parsing of models and allows different models to be used for different versions of python. if sys.version == (3,9,0): def module.foo(): ... else: def module.bar(): ...  In this example, the first model will only be parsed and honored if the python version in the system or virtual environment from which Pysa is run is equal to 3.9.0. In all other conditions, the second model will be parsed and honored. sys.version is the only allowed left hand expression and the right hand expression has to be a tuple of integers of the form (major, minor, micro). Only the major version number is required and the other two are optional. The comparison operators supported include == (equal to), != (not equal to),&lt; (less than), &gt; greater than, &lt;= (less than or equal to), and&gt;= (greater than or equal to). If conditions can also be nested inside one another and follow the same behavior as python if conditions. ","version":"Next","tagName":"h2"},{"title":"Obscure models​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#obscure-models","content":"When Pysa does not have enough information about a function or method, it will make basic assumptions about its behavior. This is referred to as an obscure model. Most notably, it assumes that the function or method propagates the taint from its arguments to its return value. This usually happens when Pysa doesn't know about the callee of a function call: def foo(f: Any): x = input() y = f(x) # no information about `f`, y will be considered tainted. eval(y)  Functions and methods defined in type stubs or in a different language (for instance, in C or C++ bindings) will also be treated as obscure models. To prevent a function or method from being marked as obscure, one can use the@SkipObscure taint annotation in a .pysa file: @SkipObscure def module.foo(): ...  ","version":"Next","tagName":"h2"},{"title":"Parameter and return path​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#parameter-and-return-path","content":"When writing a model for a source, the ReturnPath annotation allows to specify which index or attribute of the returned value is tainted. For instance: def only_attribute_foo_tainted() -&gt; TaintSource[Test, ReturnPath[_.foo]]: ...  Similarly, the ParameterPath annotation allows to specify which index or attribute of an argument leads to a sink. For instance: def only_arg_dot_bar_is_sink(arg: TaintSink[Test, ParameterPath[_.bar]]): ...  ","version":"Next","tagName":"h2"},{"title":"Access path definition​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#access-path-definition","content":"The ParameterPath and ReturnPath annotation takes an access path as an argument. An access path starts with an underscore _ which represents the whole argument or return value (depending on the context). The underscore can be followed by attribute accesses (e.g, _.foo.bar) and index accesses (e.g, _[&quot;foo&quot;][0][&quot;bar&quot;]), or a combination of both (e.g, _.foo[0]). In addition to these, four special calls can be used: .all(), .keys(),.parameter_name() and .all_static_fields(). all()​ .all() is used to represent that any index might be tainted. This is usually when the index cannot be known statically. For instance: def foo(i: int): i = random.randint(0, 100) return {i: source()}  This can be represented by the model: def foo(): TaintSource[Test, ReturnPath[_.all()]]: ...  keys()​ .keys() is used to represent that any key of the dictionary might be tainted. For instance: def foo(): return {source(): 0}  This can be represented by the model: def foo(): TaintSource[Test, ReturnPath[_.keys()]]: ...  all_static_fields()​ .all_static_fields() is used to mark all statically-known attributes of the given parameter or return value as a source or sink. The set of attributes is determined using the type annotation of the parameter or return value. If it is not annotated or that we could not find any attributes, the whole parameter or return value will be marked as a source or sink instead. For instance: class A: x: str y: str def foo(a: A) -&gt; B: ...  Using the following model: def foo(a: TaintSink[Test, ParameterPath[_.all_static_fields()]]): ...  This will add a sink on a.x and a.y. This can also be used on the return value: def foo() -&gt; TaintSource[Test, ReturnPath[_.all_static_fields()]]: ...  In general, we recommend to mark the whole parameter or return value as a source or sink. This feature is only useful for power users that post process the result of the analysis and extract leaf ports. It is also verycomputationally expensive. parameter_name()​ .parameter_name() will be replaced by the name of the parameter that is being modelled. This can only be used for TaintInTaintOut on parameters of functions or methods. This is usually useful to model constructors of dataclass-like classes. For instance: class A: def __init__(self, x, y, z): # method too complicated pass  Using the following model query: ModelQuery( name=&quot;constructors&quot;, find=&quot;method&quot;, where=[fully_qualified_name.equals(&quot;A.__init__&quot;)], model=[ Parameters(TaintInTaintOut[LocalReturn, NoCollapse, ReturnPath[_.parameter_name()]]), Modes([SkipAnalysis]) ] )  This will automatically propagate taint from parameters x, y, z toself.x, self.y and self.z. Note that if the code is available and the constructor is not too complex, Pysa will do that automatically without the need for a model. ","version":"Next","tagName":"h3"},{"title":"Taint In Taint Out​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#taint-in-taint-out","content":"ParameterPath and ReturnPath can also be used to give more information about a propagation. For instance: def foo(arg): return {&quot;a&quot;: arg[&quot;b&quot;][42]}  This can be represented by the model: def foo(arg: TaintInTaintOut[ParameterPath[_[&quot;b&quot;][42]], ReturnPath[_[&quot;a&quot;]]]): ...  Note that Pysa will automatically infer propagations if it has access to the body of the function. Writing taint-in-taint-out models should rarely be required. When using the Updates annotation, the annotation UpdatePath is used instead of ReturnPath. For instance: def MyClass.updates_foo(self, x: TaintInTaintOut[Updates[self], UpdatePath[_.foo]]): ...  ","version":"Next","tagName":"h3"},{"title":"Taint propagation from arguments to self​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#taint-propagation-from-arguments-to-self","content":"By default, Pysa only infers taint propagation from arguments to self for constructors, property setters and the special __setitem__ method. For instance: class Foo: def __init__(self, x): self.x = x def set_x(self, x): self.x = x def issue(): foo = Foo(source()) sink(foo) # Issue found. foo = Foo(&quot;&quot;) foo.set_x(source()) sink(foo) # Issue NOT found.  To enable the inference of propagations from arguments to self for all methods, one can provide the command line argument --infer-self-tito or use the taint annotation @InferSelfTito in a .pysa file: @InferSelfTito def my_module.Foo.set_x(): ...  Pysa would now find the second issue properly. Note that --infer-self-tito can significantly increase the analysis time as well as the amount of false positives. ","version":"Next","tagName":"h2"},{"title":"Taint propagation between arguments​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#taint-propagation-between-arguments","content":"By default, Pysa does NOT infer taint propagation between arguments. For short, it assumes that functions do not mutate their arguments. For instance, this flow will NOT be found: def append_wrapper(l: List[str], v: str) -&gt; None: l.append(v) def issue(): l = [] append_wrapper(l, source()) sink(l[0]) # Issue NOT found.  To enable the inference of propagations between arguments for all functions and methods, one can provide the command line argument --infer-argument-tito or use the taint annotation @InferArgumentTito in a .pysa file: @InferSelfTito def my_module.append_wrapper(): ...  Pysa would now find the issue properly. Note that --infer-argument-tito can significantly increase the analysis time as well as the amount of false positives. ","version":"Next","tagName":"h2"},{"title":"Taint broadening​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#taint-broadening","content":"Taint broadening is an over-approximation performed by the taint analysis for correctness or performance reasons. After applying broadening, Pysa considers that a whole object or variable is tainted when only some attributes or keys were initially tainted. This is also called taint collapsing or tree collapsing because the taint is internally represented as a tree structure where edges are attributes or keys. Collapsing means merging the taint on all children into the root of the tree. For instance, this happens when Pysa does not have access to the body of a function: def obscure_function(arg): ... def foo(): # Only `x['a']` is tainted. x = {&quot;a&quot;: source()} # Taint broadening happens, `y` and all its attributes are considered tainted. y = obscure_function(x) # This is considered an issue, even if only `x['a']` was initially tainted. sink(y['b']) # Also an issue, `y` is entirely tainted. sink(y)  Note that whenever broadening happens, Pysa will automatically add a broadeningfeature on the taint flow, which can help discard false positives in post processing. Fine grained features are used for each different scenario leading to broadening. The most common causes for taint broadening are the following: ","version":"Next","tagName":"h2"},{"title":"Broadening on obscure models​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#broadening-on-obscure-models","content":"Taint that flows through an obscure model - for instance, when Pysa does not have access to the body of the callee - is collapsed, since we must assume anything could get tainted, for correctness. In this scenario, the tito-broadening and via:obscure:model features are added to the flow. ","version":"Next","tagName":"h3"},{"title":"Broadening on taint-in-taint-out (TITO)​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#broadening-on-taint-in-taint-out-tito","content":"When specifying a taint propagation (also called Taint In Taint Out or TITO) in a .pysa file, the propagation will collapse the taint by default. For instance: # models.pysa def tito(arg: TaintInTaintOut): ...  def foo(): x = {&quot;a&quot;: source()} y = tito(x) sink(y['b']) # Considered an issue because of taint broadening.  In this scenario, the tito-broadening feature is added to the flow. If the function is known to preserve the structure of the argument, theNoCollapse annotation can be used to disable collapsing. For instance: def tito(arg: TaintInTaintOut[NoCollapse]): ...  This would remove the issue from the previous example. Note that this can be used in combination withParameterPath and ReturnPath. ","version":"Next","tagName":"h3"},{"title":"Model broadening​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#model-broadening","content":"When the number of tainted attributes or keys hits a certain threshold, taint broadening is applied to prevent the analysis from blowing up by tracking too many values. This is referred as Model broadening since this happens when the model (or summary) of a function is computed. For instance, this can happen when the number of tainted key-value pairs of a dictionary hit a certain threshold. For scalability reasons, Pysa cannot track an infinite amount of indices, and thus makes the approximation that the whole object is tainted. def foo(condition): d = {} if condition: d[&quot;a&quot;] = source() d[&quot;b&quot;] = source() # c, d, e, etc. else: d[&quot;1&quot;] = source() d[&quot;2&quot;] = source() # etc. return d # too many indexes, the whole return value is considered tainted.  In this scenario, the model-broadening feature is added to the flow. See analysis thresholds for documentation about the different scenarios of model broadening. Note that model broadening can be disabled for a given function or method using the @SkipModelBroadening annotation in a .pysa file: @SkipModelBroadening def foo(): ...  This can also be used in a ModelQuery using theModes clause. Note that this should be used sparingly since this can potentially lead to an increase in analysis time. ","version":"Next","tagName":"h3"},{"title":"Model shaping​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#model-shaping","content":"When a specific attribute or key is tainted when the whole object is tainted with the same taint kind (e.g, UserControlled), taint collapsing is applied as an optimization to save analysis time. This is called model shaping and is applied right before model broadening. For instance: def my_sink(x): sink(x) sink(x.foo)  The sink on x.foo (represented as formal(x)[foo]) is merged into the sink on x. Note that this is sound since attributes of a tainted object are also considered tainted. Thus if my_sink is actually called with x.foo tainted, the flow will be found as expected. The downside is that this can lead to false positives in cases where my_sinkis called with another attribute (say x.bar) tainted. We would find a flow from x.bar to x.foo in my_sink. In this scenario, the model-shaping feature is added to the flow. The featuresmodel-source-shaping, model-sink-shaping and model-tito-shaping are also added to differentiate whether the shaping was on sources, sinks or tito. ","version":"Next","tagName":"h3"},{"title":"Widen broadening​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#widen-broadening","content":"When the number of tainted attributes or keys is potentially infinite because of a loop or recursion, taint broadening is applied to allow the termination of the analysis. The term &quot;widen&quot; or &quot;widening&quot; refers to an operator that is applied to ensure convergence. It commonly happens within loops. For instance: def foo(n): d = {} for _ in range(n): d = { &quot;a&quot;: source(), &quot;b&quot;: d, } return d  Technically, d['b']...['b']['a'] (with an infinite number of access to b) could be tainted. To allow the analysis to terminate, Pysa stops at a certain depth. See analysis thresholds for documentation about the different scenarios of widen broadening. Another example: def foo(person): while person.parent is not None: person = person.parent # Infer sinks on person.name, person.parent.name, person.parent.parent.name, etc. sink(person.name)  In these scenarios, the widen-broadening feature is added to the flow. ","version":"Next","tagName":"h3"},{"title":"Issue broadening​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#issue-broadening","content":"When an object with a tainted attribute or key reaches a sink, Pysa considers the flow as valid even if the whole object is not tainted. For instance: d = {&quot;a&quot;: source(), &quot;b&quot;: &quot;foo&quot;} sink(d) # `d` itself is not tainted, but `d[&quot;a&quot;]` is, thus we emit an issue.  In this scenario, the issue-broadening feature is added to the issue. ","version":"Next","tagName":"h3"},{"title":"Tainting Specific kwargs​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#tainting-specific-kwargs","content":"Sometimes, a function can have potential sinks mixed together with benign parameters in the keyword arguments (kwargs) that it accepts. In these cases, tainting the whole kwargs variable will result in false positives when tainted data flows into a benign kwarg. Instead, for a function like this: def eval_and_log(**kwargs): eval(kwargs[&quot;eval&quot;]) logging.debug(kwargs[&quot;log&quot;])  We can lie a bit in our .pysa file, and break out the dangerous argument for tainting: def eval_and_log(*, eval: TaintSink[RemoteCodeExecution], **kwargs): ...  This allows us to catch flows only into the eval keyword argument. ","version":"Next","tagName":"h2"},{"title":"Instance attributes versus class attributes​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#instance-attributes-versus-class-attributes","content":"Models can specify sources and sinks on attributes, following the type annotation syntax: django.http.request.HttpRequest.GET: TaintSource[UserControlled]  Any access to request.GET will be tainted when request is an instance ofHttpRequest or any of its children. However, note that the access to the class attribute (i.e, HttpRequest.GET) won't be considered tainted. To specify sources and sinks on class attributes, use the __class__ prefix: django.http.request.HttpRequest.__class__.GET: TaintSource[UserControlled]  To specify a source on both the class attribute and instance attribute, simply use both lines. ","version":"Next","tagName":"h2"},{"title":"Literal String Sources And Sinks​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#literal-string-sources-and-sinks","content":"Some security vulnerabilities are best captured by modeling strings of a given form flowing to dangerous functions, or format strings that match a pattern getting tainted data passed in. To mark all literal strings matching a pattern as sources, you first need to add a regular expression corresponding to the pattern to your taint.config: { &quot;sources&quot;: [ { &quot;name&quot;: &quot;IPAddress&quot; } ], &quot;implicit_sources&quot;: { &quot;literal_strings&quot;: [ { &quot;regexp&quot;: &quot;\\\\d{1,3}(\\\\.\\\\d{1,3})+&quot;, &quot;kind&quot;: &quot;IPAddress&quot;, &quot;description&quot;: &quot;String that looks like an IP address.&quot; } ] } }  With this regex in place, whenever Pysa sees a string such as 123.456.789.123, it will flag it as a taint source with the kind IPAddress. def test() -&gt; None: ip_address = &quot;123.456.789.123&quot; dont_pass_an_ip_address(ip_address) # Pysa will now flag this.  The converse of supporting literal strings as sinks is also supported, for data flowing into a tainted string. The syntax allows you to model data being used to format strings, like f-strings, manual string formatting, the string format() method, and printf-style string formatting with %. Template strings and manual string formatting with more than two subexpressions are not yet supported. To add a literal sink, first add the literal_sink to your configuration { &quot;sinks&quot;: [ { &quot;name&quot;: &quot;MayBeRendered&quot; }, { &quot;name&quot;: &quot;MayBeSQL&quot; } ], &quot;implicit_sinks&quot;: { &quot;literal_strings&quot;: [ { &quot;regexp&quot;: &quot;^&lt;.*&gt;$&quot;, &quot;kind&quot;: &quot;MayBeRendered&quot;, &quot;description&quot;: &quot;Indicates a string whose contents may be rendered.&quot; }, { &quot;regexp&quot;: &quot;^SELECT *.&quot;, &quot;kind&quot;: &quot;MayBeSQL&quot;, &quot;description&quot;: &quot;Indicates a string whose contents may be a SQL query.&quot; } ] }  Now, Pysa will treat any values flowing into a each of the following as a regular sink: def may_render(parameter: str) -&gt; None: result = f&quot;&lt;content={parameter}&gt;&quot; result = &quot;&lt;content={}&gt;&quot;.format(parameter) result = &quot;&lt;content%s&gt;&quot; % (parameter,)  As well as values flowing into each of these as a regular sink: def build_sql_query(columns: str) -&gt; None: result = f&quot;SELECT {columns} FROM users;&quot; result = &quot;SELECT {} FROM users;&quot;.format(columns) result = &quot;SELECT %s FROM users&quot; % (columns,) result = &quot;SELECT &quot; + columns + &quot; FROM users;&quot;  Note that string literal sinks have some limitations. For instance, they cannot catch issues if the string literal is stored in a temporary variable (e.g., x = &quot;SELECT {}&quot;; x.format(input)). We recommend using string combine rules instead (see below). ","version":"Next","tagName":"h2"},{"title":"Combined Source Rules​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#combined-source-rules","content":"Some security vulnerabilities are better modeled as two sources reaching sinks at the same call site. For example, leaking credentials via requests.get could be modeled as user controlled data flowing into the url parameter and credentials flowing into the params parameter. These flows can be modeled by combined source rules. Sources for combined source rules are declared as normal in taint.config. Sinks, however, are declared inside the rule definition, and are referred to as partial sinks. The rule itself is declared in the combined_source_rules top level entry. The actual flows are defined under section rule, which must contain two flows, one for each source. Each flow specifies a pair of (potentially multiple) sources and a single partial sink: { &quot;sources&quot;: [ { &quot;name&quot;: &quot;UserControlled&quot; }, { &quot;name&quot;: &quot;Credentials&quot; } ], &quot;combined_source_rules&quot;: [ { &quot;name&quot;: &quot;Credentials leaked through requests&quot;, &quot;rule&quot;: [ { &quot;sources&quot;: [ &quot;UserControlled&quot; ], &quot;partial_sink&quot;: &quot;UserControlledRequestSink&quot; }, { &quot;sources&quot;: [ &quot;Credentials&quot; ], &quot;partial_sink&quot;: &quot;CredentialsSink&quot; } ], &quot;code&quot;: 1, &quot;message_format&quot;: &quot;Credentials leaked through requests&quot;, &quot;main_trace_source&quot;: &quot;url&quot;, } ] }  Sources are declared as normal in .pysa files. Instead of specifying sinks with a TaintSink annotation, however, PartialSink annotations are used to specify where each source needs to flow for the combined source rule. ThesePartialSink must reference the ones that were declared by the rule above: def requests.api.get( url: PartialSink[UserControlledRequestSink], params: PartialSink[CredentialsSink], **kwargs ): ...  With the above configuration, Pysa can detect cases where UserControlled flows into url and Credentials flow into params at the same time (or at the same call site). Note that the same partial sink can be used in different rules, which avoids duplicating a given model for each rule (in some cases). ","version":"Next","tagName":"h2"},{"title":"String Combine Rules​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#string-combine-rules","content":"It is sometimes useful to detect data tainted with a source (e.g., UserControlled data) that is incorporated into a suspicious looking string (e.g., a string that looks like a SQL query). Detecting such a pattern is useful, because it allows Pysa to detect dynamic creation of SQL queries which could lead to SQL injection, even if the code under analysis is using a SQL framework that Pysa does not have models for. To detect such flows, one can specify a variant of combined source rules, called string combine rules, to detect when the suspicious string (identified via regex match) and the other configured source both flow into string formatting call sites (such as calling str.__add__, str.__mod__, str.format or constructing f-strings). For example, to detect flows from source UserControlled to sink StringMayBeSQL, one should specify the following contents in the taint configuration file, where UserControlled and StringMayBeSQL are both declared as sources: { &quot;sources&quot;: [ { &quot;name&quot;: &quot;UserControlled&quot; }, { &quot;name&quot;: &quot;StringMayBeSQL&quot; } ], &quot;implicit_sources&quot;: { &quot;literal_strings&quot;: [ { &quot;regexp&quot;: &quot;SELECT.*&quot;, &quot;kind&quot;: &quot;StringMayBeSQL&quot;, &quot;comment&quot;: &quot;matches a SQL statement&quot; } ] }, &quot;string_combine_rules&quot;: [ { &quot;name&quot;: &quot;User controlled data flows into potential SQL strings&quot;, &quot;rule&quot;: [ { &quot;sources&quot;: [ &quot;UserControlled&quot; ], &quot;partial_sink&quot;: &quot;UserControlledDataSink&quot; }, { &quot;sources&quot;: [ &quot;StringMayBeSQL&quot; ], &quot;partial_sink&quot;: &quot;StringMayBeSQLSink&quot; } ], &quot;code&quot;: 4324, &quot;message_format&quot;: &quot;User controlled data flows into potential SQL strings&quot; } ] }  As shown above, the syntax is similar to that of combined source rules, especially for section rule. The above rule enables catching the following flows: def issue(): uc = user_controlled() f&quot;SELECT {uc} FROM async_query&quot; &quot;SELECT &quot; + uc + &quot; FROM async_query&quot; &quot;SELECT %s FROM async_query&quot; % uc &quot;SELECT {} FROM async_query&quot;.format(uc)  Note that the string combine rules are strictly more powerful than the feature of implicit literal string sinks. That is, any flow that can be detected via implicit literal string sinks can also be detected via string combine rules, but not vice versa. Hence, we recommend using the string combine rules. ","version":"Next","tagName":"h2"},{"title":"Prevent Inferring Models with SkipAnalysis​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#prevent-inferring-models-with-skipanalysis","content":"In addition to the models defined in .pysa files, Pysa will infer models for functions based what sources, sinks, etc. they call in their body. TheSkipAnalysis annotation can be used to prevent Pysa from inferring models, and instead force it to use only the user defined models for determining taint flow: @SkipAnalysis def qualifier.dont_generate_models(argument): ...  SkipAnalysis can be applied at the class level as a shorthand to prevent pysa from infering models for all functions in a class: class skip_analysis.SkipMe(SkipAnalysis): ...  ","version":"Next","tagName":"h2"},{"title":"Ignoring overrides​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#ignoring-overrides","content":"When a method is called on a base class, Pysa has to assume that that call could actually invoke any subclass methods that override the base class's method. For heavily overriden methods, this can lead to both performance impacts and false positives. When running Pysa, you may see messages such as this in the output: 2020-09-02 09:25:50,677 WARNING `object.__init__` has 106 overrides, this might slow down the analysis considerably.  The above message indicates that 106 subclasses of object have overridden__init__. If Pysa sees taint flowing into object.__init__, then it will treat all 106 overrides of object.__init__ as also receiving that taint. The @SkipOverrides decorator can be applied to deal with false positives or performance issues from having too many overrides on a given function: @SkipOverrides def object.__init__(self): ...  This annotation will cause Pysa not to propagate taint into to and from overridden methods on subclasses, when analyzing functions that call the overriden method on the base class. maximum_overrides_to_analyze can be added the the options block oftaint.config to limit the number of overrides that Pysa will analyze: { &quot;sources&quot;: [], &quot;sinks&quot;: [], &quot;features&quot;: [], &quot;rules&quot;: [], &quot;options&quot;: { &quot;maximum_overrides_to_analyze&quot;: 60 } }  This option can also be provided in the command line, using--maximum-overrides-to-analyze. This can speed up the analysis, but it will lead to false negatives, because Pysa will only propagate taint to or from 60 (in the case of the above example) overriden methods on subclasses. The remaining overriding methods will be ignored and treated as if they weren't actually overriding the base class method. By default, Pysa skips overrides on some functions that are typically problematic. You can find the full list of default-skipped functions instubs/taint/common/skipped_overrides.pysa ","version":"Next","tagName":"h2"},{"title":"Force to analyze all overrides​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#force-to-analyze-all-overrides","content":"We also allow the use of decorator @AnalyzeAllOverrides to force analyzing all overriding methods of a given method, regardless of the configured maximum number of overrides to analyze (e.g., via command line option --maximum-overrides-to-analyze), or if there simultaneously exists an @SkipOverrides on the given method. An example is: @AnalyzeAllOverrides def BaseClass.method(self): ...  Decorator @AnalyzeAllOverrides is often used to reduce false negatives, by analyzing all overrides of some selected methods. This offers a more fine-grained option than tweaking --maximum-overrides-to-analyze for all methods. Adding decorator @AnalyzeAllOverrides to some selected methods is faster than using a large threshold of maximum overrides for all methods, but achieves better precision than using a small threshold. ","version":"Next","tagName":"h2"},{"title":"Limit the trace length for better signal and performance​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#limit-the-trace-length-for-better-signal-and-performance","content":"By default, Pysa will find all flows from sources to sinks matching a rule. This can lead to very long traces which are hard to understand and tend to be false positives. This also brings down the performance a lot. Pysa provides a --maximum-trace-length &lt;integer&gt; command line argument which limits the length of traces that it finds. In general, this will also make Pysa faster. This option can also be added in the taint.config as follows: { &quot;sources&quot;: [], &quot;sinks&quot;: [], &quot;features&quot;: [], &quot;rules&quot;: [], &quot;options&quot;: { &quot;maximum_trace_length&quot;: 20 } }  Note that this is not a silver bullet and that this might hide security vulnerabilities. Use it with caution. ","version":"Next","tagName":"h2"},{"title":"Limit the trace length for a given rule​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#limit-the-trace-length-for-a-given-rule","content":"Similarly to the option described above, one can limit the trace length for a given rule, using the filters option: &quot;rules&quot;: [ { &quot;name&quot;: &quot;SQL injection.&quot;, &quot;code&quot;: 1, &quot;sources&quot;: [ &quot;UserControlled&quot; ], &quot;sinks&quot;: [ &quot;SQL&quot; ], &quot;message_format&quot;: &quot;Data from [{$sources}] source(s) may reach [{$sinks}] sink(s)&quot;, &quot;filters&quot;: { &quot;maximum_source_distance&quot;: 10, &quot;maximum_sink_distance&quot;: 5 } } ]  This will limit the trace length from the root to the source by 10, and the trace length from the root to the sink by 5, only for that specific rule. Note: This is meant to be used to limit the number of issues written to the database. Prefer using SAPP to filter out false positives. ","version":"Next","tagName":"h2"},{"title":"Limit the tito depth for better signal and performance​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#limit-the-tito-depth-for-better-signal-and-performance","content":"Pysa automatically infers when a function propagate the taint from one argument to its return value. This is called tito, for &quot;Taint In Taint Out&quot;. In practice, infering it can be very expensive since the taint can go through an arbitrary number of hops (i.e, depth). For instance: def foo(x): return x def bar(x): return foo(x) def baz(x): return bar(x)  In this example, baz propagates the taint on its argument to the return value using 3 hops. Pysa provides a --maximum-tito-depth &lt;integer&gt; command line argument which limints the depth of inferred propagations. In combination with the trace length limit, this usually makes Pysa faster. This option can also be added in the taint.config as follows: { &quot;sources&quot;: [], &quot;sinks&quot;: [], &quot;features&quot;: [], &quot;rules&quot;: [], &quot;options&quot;: { &quot;maximum_tito_depth&quot;: 20 } }  ","version":"Next","tagName":"h2"},{"title":"Decorators​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#decorators","content":"By default, Pysa does not generally understand decorators, and will treat a call to a decorated function as an obscure call. This will usually lead to false negatives if the decorated functions has sources or sinks. For instance: def identity(f: Callable[[str], None]) -&gt; Callable[[str], None]: return f @identity def decorated_sink(x: str) -&gt; None: sink(x) decorated_sink(source()) # False negative, issue will NOT be found!  This also leads to false negatives if the decorator adds a flow to a sink. For instance: def with_sink(f: Callable[[str], None]) -&gt; Callable[[str], None]: def inner(x: str) -&gt; None: sink(x) f(x) return inner @with_sink def foo(x: str) -&gt; None: print(x) foo(source()) # False negative, issue will NOT be found!  Since the call to a decorated function is treated as an obscure call, it will conservatively propagate taint through decorated function: def identity(f: Callable[[str], str]) -&gt; Callable[[str], str]: return f @identity def decorated(x: str) -&gt; str: # Whatever happens here will not be considered at the call site. return 'hello %s' % x sink(decorated(source())) # Issue is properly found.  Pysa provides a few ways to deal with these limitations. ","version":"Next","tagName":"h2"},{"title":"Ignoring decorators​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#ignoring-decorators","content":"Pysa can entirely ignore a decorator, as if it was not present in the source code. This can be done safely when the decorator does not change the signature of the decorated function (i.e, it does not add or remove parameters). To ignore a decorator, use the @IgnoreDecorator annotation in a .pysa file: @IgnoreDecorator def module.decorator(): ...  ","version":"Next","tagName":"h2"},{"title":"Inlining decorators​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#inlining-decorators","content":"Pysa can try to inline decorators into decorated functions before analyzing them. This can be enabled with the --inline-decorators flag. Inlining will take the code of the decorator and copy it within the decorated function. For instance: def my_decorator(f: Callable[[int], int]) -&gt; Callable[[int], int]: def inner(x: int) -&gt; int: before(x) result = f(x) after(x) return result return inner @my_decorator def decorated(x: int) -&gt; int: return x + 1  Will be inlined as: def decorated(x: int) -&gt; int: before(x) result = x + 1 after(x) return result  ","version":"Next","tagName":"h2"},{"title":"Prevent Inlining Decorators with SkipDecoratorWhenInlining​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#prevent-inlining-decorators-with-skipdecoratorwheninlining","content":"Decorator inlining comes at the cost of increasing the analysis time and also increasing the lengths of traces. If you would like to prevent certain decorators from being inlined, you can mark them in your .pysa file using @SkipDecoratorWhenInlining: # foo.pysa @SkipDecoratorWhenInlining def foo.decorator_to_be_skipped(f): ...  # foo.py @decorator_to_be_skipped def bar(x: int) -&gt; None: pass  This will prevent the decorator from being inlined when analyzing bar. Note that we use @SkipDecoratorWhenInlining on the decorator that is to be skipped, not the function on which the decorator is applied. Unfortunately, this will lead back to false negatives as described earlier. For instance: @decorator_to_be_skipped def bar(x: int) -&gt; None: sink(x) bar(source()) # False negative, issue will NOT be found!  ","version":"Next","tagName":"h3"},{"title":"Single trace sanitizers with @SanitizeSingleTrace​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#single-trace-sanitizers-with-sanitizesingletrace","content":"Sanitizers, as described in the Overview, are applied in both the forward (i.e source) trace and backward (i.e sink) trace. For instance, with the given .pysa file: @Sanitize(TaintInTaintOut[TaintSink[RemoteCodeExecution]]) def shlex.quote(x): ...  And the following Python code: import subprocess from shlex import quote def quoted_input(): x = input() # source 'UserControlled' y = quote(x) return y def echo(argument): subprocess.run(f'/bin/echo {argument}', shell=True) # sink 'RemoteCodeExecution' def issue(): x = quoted_input() # source trace: input -&gt; quoted_input -&gt; issue echo(x) # sink trace: issue -&gt; echo -&gt; subprocess.run  Pysa will NOT find an issue here, as expected. This is because during the propagation of the 'UserControlled' source in the forward trace, pysa remembers that it was sanitized for the sink 'RemoteCodeExecution'. However, Pysa provides a simpler version of sanitizers, which only sanitizes in the forward trace or the backward trace: @SanitizeSingleTrace(TaintSource) def f(): ... @SanitizeSingleTrace(TaintSource[UserControlled]) def g(): ... @SanitizeSingleTrace(TaintSink) def h(): ... @SanitizeSingleTrace(TaintSink[RemoteCodeExecution]) def i(): ...  These sanitizers are a lot cheaper and could save analysis time. However, these might introduce false positives, so we recommend to use the default sanitizers. ","version":"Next","tagName":"h2"},{"title":"Filtering the call graph with @Entrypoint​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#filtering-the-call-graph-with-entrypoint","content":"By default, Pysa will analyze the entire call graph of your program. This can lead to longer analysis times for larger programs, especially when you'd only like to perform analysis on specific parts of the program. This decorator will mark a specified function and the functions it calls as the only functions to be analyzed. Note: the flag --limit-entrypoints must be passed to pyre analyze for call graph filtering to occur, even if the @Entrypoint decorator is present. This allows for call graph filtering to be easily enabled or disabled without editing your .pysa files. If you have the following Python file: class MyClass: def class_entrypoint(): taint_sink(taint_source()) def my_bad_func_1(): taint_sink(taint_source()) def my_bad_func_2(): taint_sink(taint_source()) def func_entrypoint(): my_bad_func_1() def main(): func_entrypoint() my_bad_func_2() MyClass().class_entrypoint() main()  And the following .pysa file: @Entrypoint def my_file.MyClass.class_entrypoint(): ... @Entrypoint def func_entrypoint(): ...  Then issues will be found for taint in calls to class_entrypoint and my_bad_func_1, but not my_bad_func_2, since it isn't called by a function marked by an @Entrypoint. ","version":"Next","tagName":"h2"},{"title":"Taint In Taint Out Transforms​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#taint-in-taint-out-transforms","content":"Taint in taint out transforms can be used to capture more precise flows. As an example: def read_file(path): with open(path, &quot;r&quot;) as f: content = f.read() return content  Without taint in taint transforms we can write a rule that captures a UserControlled path is read. Such a rule can be made much higher signal if we can detect that content is also ReturnedToUser. We can use taint in taint out transforms to stitch the two flows together. We mark read with a taint in taint out transform FileRead, and the rule becomes UserControlled -&gt; FileRead -&gt; ReturnedToUser. To contrast with feature annotations, there are two differences: The filtering is done during analysis itself, and limits the issues generated (as opposed to a post-processing step by the user)Taint in taint out transforms can be used to reason about the order of events ","version":"Next","tagName":"h2"},{"title":"Syntax​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#syntax","content":"In taint.config, one can specify transforms to define new transforms. Each transform is defined by following fields: name: name of the transform, this is used when defining rules, as well as writing modelscomment: description of the transform { ... &quot;transforms&quot;: [ { &quot;name&quot;: &quot;MyTransform&quot;, &quot;comment&quot;: &quot;This is my transform&quot; }, ... ], ... }  Then, one may use these transforms in rules as follows:  { ... &quot;rules&quot;: [ { &quot;name&quot;: ..., &quot;code&quot;: ..., &quot;sources&quot;: [&quot;SourceA&quot;], &quot;transforms&quot;: [&quot;MyTransform1&quot;, &quot;MyTransform2&quot;], &quot;sinks&quot;: [&quot;SinkB&quot;], &quot;message_format&quot;: &quot;[{$sources}] transformed by [${transforms}] may reach [${sinks}]&quot; }, ... ], ... }  Intuitively, one can think of the rule above as SourceA -&gt; MyTransform1 -&gt; MyTransform2 -&gt; SinkB. The order is important. Finally, in .pysa model files a taint transform can be specified using a TaintInTaintOut[Transform[...]] annotation, where the parameter is the name of the transform. def my_function(arg: TaintInTaintOut[Transform[MyTransform]]): ...  ","version":"Next","tagName":"h3"},{"title":"Semantics​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#semantics","content":" y = my_function(x)  If x has source taint SourceA, the taint of y is MyTransform:SourceA. This will correspond to matching SourceA -&gt; MyTransform in a rule. Likewise, if y has sink taint SinkB, then the taint of x is MyTransorm:SinkB. This will correspond to matching MyTransform -&gt; SinkB in a rule. Note that a transform modifies the taint itself. Hence, if a flow passes through a transform, it will no longer match rules which do not contain the transform. RuleX: SourceA -&gt; SinkB RuleY: SourceA -&gt; MyTransform -&gt; SinkB Flow1: SourceA -&gt; SinkB Flow2: SourceA -&gt; MyTransform -&gt; SinkB  Flow1 matches RuleX but not RuleY. Flow2 matches RuleY but not RuleX. Consider the scenario where we have an additional rule: RuleZ: SourceC -&gt; SinkD  If transform MyTransform is applied to taint SourceC, there is no possible rule it can possibly match. As an optimization, we check for this continuously in our analysis and filter out eagerly. Also note that the existing TaintInTaintOut annotation semantics of TITO being assumed (instead of inferred) on the argument are unchanged. ","version":"Next","tagName":"h3"},{"title":"Analysis thresholds​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#analysis-thresholds","content":"Pysa provides many options to fine tune the taint analysis. The following options can be provided either via the command line or in the taint.config file, under the options section. For instance: { &quot;sources&quot;: [], &quot;sinks&quot;: [], &quot;features&quot;: [], &quot;rules&quot;: [], &quot;options&quot;: { &quot;maximum_model_source_tree_width&quot;: 10, &quot;maximum_model_sink_tree_width&quot;: 10, &quot;maximum_model_tito_tree_width&quot;: 10 } }  When not provided, these are set to the following defaults: maximum_model_source_tree_width = 25; maximum_model_sink_tree_width = 25; maximum_model_tito_tree_width = 5; maximum_tree_depth_after_widening = 4; maximum_return_access_path_width = 10; maximum_return_access_path_depth_after_widening = 4; maximum_tito_collapse_depth = 4; maximum_tito_positions = 50;  ","version":"Next","tagName":"h2"},{"title":"Maximum model source tree width​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#maximum-model-source-tree-width","content":"Command line option: --maximum-model-source-tree-widthtaint.config option: maximum_model_source_tree_width See taint broadening and model broadening. This limits the width of the source tree in the model for a callable, i.e the number of output paths in the return value. For instance: def foo(): return {&quot;a&quot;: source(), &quot;b&quot;: source(), &quot;c&quot;: source()}  The source tree for foo has a width of 3. Above the provided threshold, pysa will collapse the taint and consider the whole dictionary tainted. When that happens, the breadcrumbs model-broadening and model-source-broadening will be added to the flow. ","version":"Next","tagName":"h3"},{"title":"Maximum model sink tree width​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#maximum-model-sink-tree-width","content":"Command line option: --maximum-model-sink-tree-widthtaint.config option: maximum_model_sink_tree_width See taint broadening and model broadening. This limits the width of the sink tree in the model for a callable, i.e the number of input paths leading to a sink for a given parameter. For instance: def foo(arg): sink(arg[1]) sink(arg[2]) sink(arg[3])  The sink tree for foo and parameter arg has a width of 3. Above the provided threshold, pysa will collapse the taint and consider that the whole argument leads to a sink. When that happens, the breadcrumbsmodel-broadening and model-sink-broadening will be added to the flow. ","version":"Next","tagName":"h3"},{"title":"Maximum model tito tree width​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#maximum-model-tito-tree-width","content":"Command line option: --maximum-model-tito-tree-widthtaint.config option: maximum_model_tito_tree_width See taint broadening and model broadening. This limits the width of the taint-in-taint-out tree in the model for a callable, i.e the number of input paths propagated to the return value, for a given parameter. For instance: def foo(arg): return '%s:%s:%s' % (arg.a, arg.b, arg.c)  The taint-in-taint-out tree for foo and parameter arg has a width of 3. Above the provided threshold, pysa will collapse the taint and consider that the taint on the whole argument is propagated to the return value. When that happens, the breadcrumbs model-broadening and model-tito-broadening will be added to the flow. ","version":"Next","tagName":"h3"},{"title":"Maximum tree depth after widening​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#maximum-tree-depth-after-widening","content":"Command line option: --maximum-tree-depth-after-wideningtaint.config option: maximum_tree_depth_after_widening See taint broadening and widen broadening. This limits the depth of the source, sink and tito trees within loops, i.e the length of source, sink and tito paths for each variables. For instance: def foo(): variable = MyClass() for x in generate(): variable.a.b.c = source() return result  The source tree for variable has a depth of 3 (i.e, a -&gt; b -&gt; c). Within a loop, pysa limits the depth to the provided threshold. For instance, if that threshold is 1, we would consider that variable.a is entirely tainted. When that happens, the breadcrumb widen-broadening will be added to the flow. ","version":"Next","tagName":"h3"},{"title":"Maximum return access path width​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#maximum-return-access-path-width","content":"Command line option: --maximum-return-access-path-widthtaint.config option: maximum_return_access_path_width See taint broadening and model broadening. This limits the width of the return access path tree in the model for a callable, i.e the number of output paths propagated to the return value, for a given parameter. For instance: def foo(arg): return {'a': arg, 'b': arg, 'c': arg}  The return access path tree for foo and parameter arg has a width of 3. Above the provided threshold, pysa will collapse the taint and consider that the whole return value is tainted whenever arg is tainted. When that happens, the breadcrumbs model-broadening and model-tito-broadering will be added to the flow. ","version":"Next","tagName":"h3"},{"title":"Maximum return access path depth after widening​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#maximum-return-access-path-depth-after-widening","content":"Command line option: --maximum-return-access-path-depth-after-wideningtaint.config option: maximum_return_access_path_depth_after_widening See taint broadening and widen broadening. This limits the depth of the return access path tree within loops, i.e the length of output paths propagated to the return value, for a given parameter. For instance: def foo(arg): result = MyClass() for x in generate(): result.a.b.c = arg return result  The return access path tree for foo and parameter arg has a depth of 3 (i.e, a -&gt; b -&gt; c). Within a loop, pysa limits the depth to the provided threshold. For instance, if that threshold is 2, we would cut the output path to just a.b. When that happens, the breadcrumb model-broadening andmodel-tito-broadening will be added to the flow. ","version":"Next","tagName":"h3"},{"title":"Maximum tito collapse depth​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#maximum-tito-collapse-depth","content":"Command line option: --maximum-tito-collapse-depthtaint.config option: maximum_tito_collapse_depth This limits the depth of the taint tree after applying taint-in-taint-out, i.e the length of paths for taint propagated from a parameter to the return value. For instance: def identity(arg): return arg def foo(): input = {'a': {'b': {'c': source()}}} output = identity(input)  The taint tree for input has a depth of 3 (i.e, a -&gt; b -&gt; c). When the taint is propagated to the return value of identity, we limit the resulting taint tree to the given depth. For instance, if that threshold is 1, we would consider that output['a'] is tainted. This is also applied for sinks in the backward analysis: def foo(arg): output = identity(arg) sink(output['a']['b']['c'])  With a threshold of 1, we would consider that output['a'] leads to a sink. ","version":"Next","tagName":"h3"},{"title":"Maximum tito positions​","type":1,"pageTitle":"Advanced Topics","url":"/docs/pysa-advanced/#maximum-tito-positions","content":"Command line option: --maximum-tito-positionstaint.config option: maximum_tito_positions This limits the number of positions to keep track of when propagating taint. When taint is propagated through a function and returned (i.e, taint-in-taint-out), pysa will keep track of the position of the argument, and display it in the trace. For instance: def foo(): x = source() y = tito(x) ^ z = {&quot;a&quot;: y} ^ sink(z)  In this example, we have 2 tito positions. Above the provided threshold, pysa simply discards all positions. Note that the taint is still propagated. ","version":"Next","tagName":"h3"},{"title":"Quickstart","type":0,"sectionRef":"#","url":"/docs/pysa-quickstart/","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Quickstart","url":"/docs/pysa-quickstart/#overview","content":"By the end of this guide, you will be able to run Pysa to find bugs on most Python web servers, and view those bugs on Static Analysis Post Processor (SAPP). This guide was tested on Ubuntu 18.04.5 LTS, macOS 10.15.7, and Ubuntu 20.04 LTS on WSL1 If you run into any issues along the way, please refer to the common issues section to help you debug ","version":"Next","tagName":"h2"},{"title":"Install dependencies​","type":1,"pageTitle":"Quickstart","url":"/docs/pysa-quickstart/#install-dependencies","content":"UbuntumacOS Pysa runs on Pyre, so we require the same dependencies as Pyre. You will need Python 3.8 or later, and setuptools and wheel Python packages. $ python3.8 -m pip install --upgrade setuptools $ pip3 install wheel  ","version":"Next","tagName":"h2"},{"title":"Initial configuration​","type":1,"pageTitle":"Quickstart","url":"/docs/pysa-quickstart/#initial-configuration","content":"Set up the virtual environment: $ python3.8 -m venv ~/.venvs/pysa $ source ~/.venvs/pysa/bin/activate  Install Pyre and SAPP in the virtual environment: (pysa) $ pip install pyre-check fb-sapp  Initialize Pysa and SAPP You can quickly setup a suitable environment to run Pysa and SAPP with the following command: (pysa) $ pyre init-pysa  This command setups sets up your repo to run Pysa and provides some optional tweaks to your repo to improve Pysa's results. ","version":"Next","tagName":"h2"},{"title":"Run Pysa​","type":1,"pageTitle":"Quickstart","url":"/docs/pysa-quickstart/#run-pysa","content":"Now that Pysa is set up to run on your project, you won't need to repeat any of the earlier steps to run Pysa on subsequent runs. You can run Pysa with pyre analyze. (pysa) $ pyre analyze --no-verify --save-results-to ./pysa-runs  This command will run Pysa and store the results of the Pysa run into a pysa-runs folder in your project directory. The output of Pysa runs will be used later by SAPP to help you filter and refine the results Pysa provides you. ","version":"Next","tagName":"h2"},{"title":"Run SAPP​","type":1,"pageTitle":"Quickstart","url":"/docs/pysa-quickstart/#run-sapp","content":"After you have the results from your Pysa run stored in pysa-runs, we will ingest those runs into SAPP for analysis with the following command: (pysa) $ sapp analyze ./pysa-runs/taint-output.json  We imported some filters into SAPP earlier and now that SAPP has processed your latest Pysa run, you can run the following command to spawn the server for the SAPP Web UI at http://localhost:5000: (pysa) $ sapp server   Through SAPP's Web UI, you can view and filter the issues Pysa found by clicking on the &quot;Filter&quot; button. A list of filters should appear under &quot;Saved Filters&quot; for you to choose from. Note that unfiltered Pysa issues can be noisy by default, so it is usually preferable to browse issues via these saved filters.  ","version":"Next","tagName":"h2"},{"title":"Going beyond the basics​","type":1,"pageTitle":"Quickstart","url":"/docs/pysa-quickstart/#going-beyond-the-basics","content":"We've provided you with some filters in SAPP to help you find a small subset of the bugs Pysa is able to catch. If you want to use Pysa to its full potential and find more bugs than the ones in your current Pysa run, you can learn how to write your own filters and tailor Pysa for your codebase below: Introduction to PysaDEF CON 28 Pysa TutorialPysa Debugging False Positives and NegativesSAPP Documentation ","version":"Next","tagName":"h2"},{"title":"Common Issues​","type":1,"pageTitle":"Quickstart","url":"/docs/pysa-quickstart/#common-issues","content":"Problem: Installing my project dependencies while in my virtual environment gives me errors, because some of my project dependencies are not compatible with Python 3+. Solution: Fortunately, you can still run Pysa and SAPP on your project, so feel free to continue with the Quickstart instructions. However, Pysa may miss some taint flows.  Problem: pip install fb-sapp or pip install pyre-check results in ERROR: Could not install packages due to an OSError: [Error 13] Permission denied Solution: Likely you are not installing fb-sapp or pyre-check in the virtual environment we created earlier. Try running source ~/.venvs/pysa/bin/activate before running pip install. $ source ~/.venvs/pysa/bin/activate (pysa) $ pip install pyre-check   Problem: pip install fb-sapp or pip install pyre-check fails, because it has multiple compilation errors like fatal error: Python.h: No such file or directory #include &lt;Python.h&gt; ^~~~~~~~~~ compilation terminated. error: command 'x86_64-linux-gnu-gcc' failed with exit status  Solution: You are missing setuptools python package or python3.8-dev $ sudo apt install python3.8-dev -y $ source ~/.venvs/pysa/bin/activate $ (pysa) python3.8 -m pip install --upgrade setuptools   Problem: Attempting to create a virtual environment with python3.8 -m venv ~/.venvs/pysa results in The virtual environment was not created successfully because ensurepip is not available. Solution: You are either missing python3.8-venv or python3.8-dev package. Make sure you delete the directory created by the failed virtual environment command earlier. $ sudo apt install python3.8-venv python3.8-dev -y $ rm -rf ~/.venvs/pysa $ python3.8 -m venv ~/.venvs/pysa   Problem: Running pip install fb-sapp or pip install pyre-check fails to install, because of a series of error: invalid command 'bdist_wheel' errors Solution: You are missing either wheel or setuptools package $ (pysa) pip3 install wheel $ (pysa) python3.8 -m pip install --upgrade setuptools   Problem: pyre init-pysa shows ƛ Source directory path/to/dir does not exist. Be sure the source path is relative to the import_root. Solution: You will need to manually update source_directories in .pyre_configuration. Refer to Pyre Global configuration section to set up source_directories.  Problem: Running pyre analyze --no-verify command results in ƛ Error: Could not find a pyre client. Solution: Some shells (e.g. zsh) require a restart to pick up updated PATH variables. For example: (pysa) $ pip install pyre-check (pysa) $ cd demo-project (pysa) $ pyre analyze --no-verify ƛ Error: Could not find a pyre client. (pysa) $ which pyre /usr/local/bin/pyre  which pyre points to a path not within the virtual environment (e.g. /usr/local/bin) (pysa) $ deactivate (pysa) $ zsh $ source ~/.venvs/pysa/bin/activate (pysa) $ which pyre /Users/unixname/.venvs/pysa/bin/  which pyre now points to a path in the virtual environment (e.g. ~/.venvs/pysa/bin/) Ideally, if you have a local installation of Pyre, it would be best to remove the installation and only install Pyre in a virtual environment.  Problem: Running pyre analyze results in a bunch of errors and Pysa stops running Solution: Run pyre analyze --no-verify to skip model validation.  Problem: Running pyre analyze --no-verify will freeze when parsing stubs and sources or processing functions, but the seconds runtime timer is still increasing Solution: Unfortunately, it is likely the case that your machine doesn't have enough memory to run Pysa on projects with similar size to yours.  Problem: pyre analyze --no-verify exits with error ƛ Uncaught exception: (Invalid_argument &quot;~/.venvs/pysa/lib/pyre_check/typeshed/stdlib/zlib.pyi is not a directory&quot;) Solution: Delete your virtual environment and recreate your virtual environment by following the steps in the Initial configuration section (pysa) $ deactivate $ rm -rf ~/.venvs/pysa   Problem: I'm seeing a bunch of errors like ~/.venvs/pysa/lib/pyre_check/taint/filename.pysa: module.path.function_name is not part of the environment! Solution: If you don't use the module.path.function_name mentioned in your project, you can ignore them. Pysa ships with many taint models for code that isn't present in all projects. The errors you are seeing is Pysa informing you that Pysa hasn't found the source code for that particular function in your project or your venv. If you do use the module.path.function_name mentioned in your project and the package wasn't installed with pip, you will need to add the package's path to search_path in your .pyre_configuration. Eventually, your .pyre_configuration should look something like this: { &quot;source_directories&quot;: [ &quot;.&quot; ], &quot;search_path&quot;: [ &quot;path/to/external/library&quot; ], &quot;taint_models_path&quot;: &quot;~/.venvs/pysa/lib&quot;, }   Problem: Running any sapp command results in SyntaxError: future feature annotations is not defined Solution: SAPP requires Python 3.8. Ensure you are running a Python version later than Python 3.8 $ python3 --version   Problem: Running any sapp command results in a bunch of SAWarnings like SAWarning: SAWarning: relationship 'Child.parent' will copy column parent.id to column child.parent_id, which conflicts with relationship(s): 'Parent.children' (copies parent.id to child.parent_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards. The 'overlaps' parameter may be used to remove this warning.  Solution: Please ignore the SAWarnings. They don't affect the functionality of SAPP and everything should be working as intended.  Problem: I can't connect to the Web UI and it displays an error related to SSL. The SAPP server log displays a bunch of 400 Bad Request error codes Solution: Make sure you are visiting http://localhost:5000 and not https://localhost:5000  Problem: If your SAPP server shows 404 Not found and the webpage shows The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again. Solution: The SAPP Web UI will show this error when there are no issues imported during sapp analyze. Check if Pysa has found any issues with your project and if SAPP has imported any of those issues. Checking if Pysa found any issues - you should expect the following command return at least one line: (pysa) $ cat taint-output.json | grep &quot;issue&quot;  Checking which issues SAPP imported - you should expect the following lines to appear after running sapp analyze: (pysa) $ sapp analyze [INFO] Parsing analysis output... [INFO] Generating issues and traces [INFO] Run starting... [INFO] Preparing bulk save. [INFO] Dropped 0 unused TraceKind.precondition, 0 are missing [INFO] Dropped 6 unused TraceKind.postcondition, 0 are missing [INFO] Saving 10 issues, 21 trace frames, 0 trace annotations, 50 trace frame leaf assocs ... [INFO] Run finished (0:00:00)   Problem: The issues on SAPP Web UI have boxes with No file found for filename.py, so I cannot see the source code related to the trace for my issues Solution: Try passing the path to your project source code with --source-directory to sapp server (pysa) $ sapp server --source-directory path/to/project_source_code   Problem: Pysa still doesn't work despite trying everything above Solution: Ensure you are not running a nightly version of Pyre (pysa) $ pip uninstall pyre-check-nightly (pysa) $ pip install pyre-check  Some shells (e.g. zsh) will require extra steps: (pysa) $ pip uninstall pyre-check-nightly (pysa) $ deactivate $ zsh (pysa) $ source ~/.venvs/pysa/bin/activate (pysa) $ pip install pyre-check  If you are still unable to get Pysa to run, please file an issue on pyre-check GitHub repo with some information about what OS you are running on, what error you are running into, and how to reproduce the error. ","version":"Next","tagName":"h2"},{"title":"Running Pysa","type":0,"sectionRef":"#","url":"/docs/pysa-running/","content":"","keywords":"","version":"Next"},{"title":"Setup​","type":1,"pageTitle":"Running Pysa","url":"/docs/pysa-running/#setup","content":"The setup requires the following 4 types of files. Source Code (*.py): This is your application's code.Taint Config (taint.config): This file declares sources, sinks, features, and rules.Taint Models (.pysa): These files link together the information in your source code and taint.config. They tell Pysa where in our code there exist sources and sinks.Pysa Configuration (.pyre_configuration): Parts of this file are critical to using Pysa. source_directories tells Pysa the directory containing the source code you want to analyze.taint_models_path tells Pysa where to find the config and model files. ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Running Pysa","url":"/docs/pysa-running/#example","content":"Let's look at a simple taint analysis example. To follow along, create a directory static_analysis_example and navigate to it. Paste the code snippets into the appropriately named files. ","version":"Next","tagName":"h2"},{"title":"1. Source Code​","type":1,"pageTitle":"Running Pysa","url":"/docs/pysa-running/#1-source-code","content":"# static_analysis_example/source.py import os def get_image(url): command = &quot;wget -q https:{}&quot;.format(url) return os.system(command) def convert(): image_link = input(&quot;image link: &quot;) image = get_image(image_link)  Notice the following: The input function is a taint source since it gets input directly from the user.The os.system function is a taint sink, since we do not want user-controlled values to flow into it.The return value of input is used as the URL for a wget call, which is executed by os.system. The wget can therefore be doing anything, out of the programmer's control.This data flow should be identified as a potential security issue. ","version":"Next","tagName":"h3"},{"title":"2. Taint Config​","type":1,"pageTitle":"Running Pysa","url":"/docs/pysa-running/#2-taint-config","content":"# static_analysis_example/stubs/taint/core_privacy_security/taint.config { &quot;sources&quot;: [ { &quot;name&quot;: &quot;UserControlled&quot;, &quot;comment&quot;: &quot;use to annotate user input&quot; } ], &quot;sinks&quot;: [ { &quot;name&quot;: &quot;RemoteCodeExecution&quot;, &quot;comment&quot;: &quot;use to annotate execution of code&quot; } ], &quot;features&quot;: [], &quot;rules&quot;: [ { &quot;name&quot;: &quot;Possible shell injection&quot;, &quot;code&quot;: 5001, &quot;sources&quot;: [ &quot;UserControlled&quot; ], &quot;sinks&quot;: [ &quot;RemoteCodeExecution&quot; ], &quot;message_format&quot;: &quot;Data from [{$sources}] source(s) may reach [{$sinks}] sink(s)&quot; } ] }  This declares the valid sources and sinks that Pysa should recognize. We also tell Pysa that data flowing from a UserControlled source to aRemoteCodeExecution sink is a possible shell injection. ","version":"Next","tagName":"h3"},{"title":"3. Taint Models​","type":1,"pageTitle":"Running Pysa","url":"/docs/pysa-running/#3-taint-models","content":"# static_analysis_example/stubs/taint/core_privacy_security/general.pysa # model for raw_input def input(__prompt) -&gt; TaintSource[UserControlled]: ... # model for os.system def os.system(command: TaintSink[RemoteCodeExecution]): ...  This file links together the information in source.py and taint.config. We use it to tell Pysa where in our code there exist sources and sinks. ","version":"Next","tagName":"h3"},{"title":"4. Pysa Configuration​","type":1,"pageTitle":"Running Pysa","url":"/docs/pysa-running/#4-pysa-configuration","content":"# static_analysis_example/.pyre_configuration { &quot;source_directories&quot;: [&quot;.&quot;], &quot;taint_models_path&quot;: &quot;stubs/taint&quot; }  Pysa needs to know what directory to analyze, as well as where to find the config and model files. ","version":"Next","tagName":"h3"},{"title":"Analysis​","type":1,"pageTitle":"Running Pysa","url":"/docs/pysa-running/#analysis","content":"Now let's run the static analysis: [~/static_analysis_example] $ pyre analyze ƛ Fixpoint iterations: 2 [ { &quot;line&quot;: 9, &quot;column&quot;: 22, &quot;path&quot;: &quot;source.py&quot;, &quot;code&quot;: 5001, &quot;name&quot;: &quot;Possible shell injection&quot;, &quot;description&quot;: &quot;Possible shell injection [5001]: Data from [UserControlled] source(s) may reach [RemoteCodeExecution] sink(s)&quot;, &quot;long_description&quot;: &quot;Possible shell injection [5001]: Data from [UserControlled] source(s) may reach [RemoteCodeExecution] sink(s)&quot;, &quot;concise_description&quot;: &quot;Possible shell injection [5001]: Data from [UserControlled] source(s) may reach [RemoteCodeExecution] sink(s)&quot;, &quot;define&quot;: &quot;source.convert&quot; } ]  Looking at the output, we see that pyre surfaces the tainted data flow that we expected. Let's run it again and save the results: [~/static_analysis_example] $ pyre analyze --save-results-to ./  The --save-results-to option will save more detailed results to./taint-output.json. ","version":"Next","tagName":"h3"},{"title":"Understanding the results​","type":1,"pageTitle":"Running Pysa","url":"/docs/pysa-running/#understanding-the-results","content":"See Static Analysis Post Processor. ","version":"Next","tagName":"h3"},{"title":"Shipping Pysa Models and Rules","type":0,"sectionRef":"#","url":"/docs/pysa-shipping-rules-models/","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Shipping Pysa Models and Rules","url":"/docs/pysa-shipping-rules-models/#prerequisites","content":"This document assumes you: Have followed these instructions to set up Pysa and SAPP.Understand the basic concepts of sources, sinks, sanitizers, and rules as well as features.Have completed a successful run of PysaKnow the sources and sinks you'd like to detect. Ideally, you will also have completed the Pysa tutorial (code,video). ","version":"Next","tagName":"h2"},{"title":"Where to put your models / taint.config changes​","type":1,"pageTitle":"Shipping Pysa Models and Rules","url":"/docs/pysa-shipping-rules-models/#where-to-put-your-models--taintconfig-changes","content":"Common privacy/security-related rules and models should be placed under stubs/taint/core_privacy_security. These should only reference entities that exist in the Python standard library, or the type stubs that are shipped with Pyre. Models for third-party libraries should be placed under stubs/third_party_taint. ","version":"Next","tagName":"h2"},{"title":"Writing your models / taint.config changes​","type":1,"pageTitle":"Shipping Pysa Models and Rules","url":"/docs/pysa-shipping-rules-models/#writing-your-models--taintconfig-changes","content":"Refer to the docs on sources, sinks, sanitizers, rules, andfeatures when you need help. You can usually find pre-existing examples ofsources,sinks,sanitizers, andfeaturesto copy as a starting point if you get stuck. When adding models for a pre-existing source/sink/feature type (e.g.UserControlled, you won't need to modify taint.config. Make sure to check for pre-existing source, sink, and feature declarations before declaring a new one; most types of source and sinks are already declared, and it can be more sustainable to add an additional model to an existing category, rather than creating a whole new one. When adding a new rule, you will need to update taint.config. As with the previous paragraph, try to put existing sources and sinks to use. For example, if you're writing a sensitive data logging rule, using theLoggingsink will allow you to detect your chosen data flowing into many different types of loggers that we model. ","version":"Next","tagName":"h2"},{"title":"Testing​","type":1,"pageTitle":"Shipping Pysa Models and Rules","url":"/docs/pysa-shipping-rules-models/#testing","content":"Providing a quick explanation of the issue you intended to catch and evidence that the issue was caught in your local run is usually sufficient. This can be in the form of a screenshot of the issue in SAPP, a sample or paste of the taint-output.json produced by Pysa, etc. ","version":"Next","tagName":"h2"},{"title":"Catching Known Issues​","type":1,"pageTitle":"Shipping Pysa Models and Rules","url":"/docs/pysa-shipping-rules-models/#catching-known-issues","content":"To test, you need to have an issue that you want to find. The best option is to have a known vulnerability from a past CVEor issue. You can manually identify the flow of data that caused the issue, make sure you have the correct sources and sinks, and then verify that your new rule/source/sink catches the issue. Follow these instructions to run Pysa and import the results into the SAPP UI. Once your run completes, you should be able to see the issue you intended to catch in the UI. If there are a lot of issues showing up, you may need to usefilters to find the particular issue you were looking for. If you're not finding your issue, read through the development tips for help debugging. ","version":"Next","tagName":"h3"},{"title":"Integration Test​","type":1,"pageTitle":"Shipping Pysa Models and Rules","url":"/docs/pysa-shipping-rules-models/#integration-test","content":"If you don't have an existing project to test on, you can also use the integration test environment provided with the pyre-check repo. This is a minimal, deliberately vulnerable Flask web app. You can find all the details and instructions on how to set it up here. It should already be set up to use the taint models in the pyre-check/stubs folder, so you can easily make your changes to existing Pysa models and observe the effects. For example, suppose we wanted to add a new rule for some builtin Python functions. We would add our new source, sink and rule in stubs/taint/core_privacy_security/taint.config: { ... &quot;sources&quot;: [ ..., { &quot;name&quot;: &quot;Foo&quot;, &quot;comment&quot;: &quot;used to annotate a foo source&quot; }, ], &quot;sinks&quot;: [ ..., { &quot;name&quot;: &quot;Bar&quot;, &quot;comment&quot;: &quot;used to annotate a bar sink&quot; }, ], &quot;rules&quot;: [ ..., { &quot;name&quot;: &quot;Foo to Bar&quot;, &quot;code&quot;: 9000, &quot;sources&quot;: [ &quot;Foo&quot; ], &quot;sinks&quot;: [ &quot;Bar&quot; ], &quot;message_format&quot;: &quot;Data from [{$sources}] source(s) may reach [{$sinks}] sink(s)&quot; }, ], }  Make sure your new rule has a unique number and new source and sink names are also unique! We can now add our models in a .pysa file under stubs/taint/core_privacy_security/: def input() -&gt; TaintSource[Foo]: ... def ascii(__source: TaintSink[Bar]): ...  Then, we can open a source file in the vulnerable Flask app (e.g. app.py), and inject an issue of the type we want to catch: def alarm1() -&gt; None: x = input() ascii(x)  Finally, we can run the integration test using the run_integration_tests.sh script (or just run pyre analyze) and verify that the issue we expect to be caught is indeed caught: ERROR ----BEGIN PYSA INTEGRATION TEST ERROR---- ERROR Output differs from expected: ... @@ -46,5 +46,11 @@ ... + }, + { + &quot;code&quot;: 9000, + &quot;define&quot;: &quot;app.alarm1&quot;, + &quot;description&quot;: &quot;Foo to Bar [9000]: Data from [Foo] source(s) may reach [Bar] sink(s)&quot;, + &quot;path&quot;: &quot;app.py&quot; } ] ERROR ----END PYSA INTEGRATION TEST ERROR----  ","version":"Next","tagName":"h3"},{"title":"Contributing Coverage Improvements to Pysa​","type":1,"pageTitle":"Shipping Pysa Models and Rules","url":"/docs/pysa-shipping-rules-models/#contributing-coverage-improvements-to-pysa","content":"When you've proven that you can catch issues with your changes, send a PR to the pyre-check Github repository. Please make sure you include a test plan in your PR that follows thetesting guidelines mentioned above! If you used the deliberately_vulnerable_flask_app for testing, free to also include your integration test changes with your injected issue in your PR to help us expand our open source integration tests! Note this will require you to update thefull_result.json file in the same folder. When you run the integration test script, afull_result.actual file will be produced when the output does not match the existing expected output. Simply copy the contents of that file tofull_result.json, e.g. in the example above, we would add the following lines to full_result.json:  ... { &quot;code&quot;: 9000, &quot;column&quot;: 10, &quot;define&quot;: &quot;app.alarm1&quot;, &quot;description&quot;: &quot;Foo to Bar [9000]: Data from [Foo] source(s) may reach [Bar] sink(s)&quot;, &quot;line&quot;: 64, &quot;name&quot;: &quot;Foo to Bar&quot;, &quot;path&quot;: &quot;app.py&quot;, &quot;stop_column&quot;: 11, &quot;stop_line&quot;: 64 } ]  ","version":"Next","tagName":"h2"},{"title":"General Tips","type":0,"sectionRef":"#","url":"/docs/pysa-tips/","content":"","keywords":"","version":"Next"},{"title":"Features/Limitations​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#featureslimitations","content":"","version":"Next","tagName":"h2"},{"title":"Inheritance​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#inheritance","content":"Pysa is aware of inheritance, so you can add taint annotations to a base class, and Pysa will detect when the tainted attribute or function is accessed via a child class. For example, this flow will be detected during static analysis: class Parent: def some_source(self): # Annotated as a source pass class Child(Parent): pass child = Child() some_sink(child.some_source()) # Detected as a tainted flow  Additionally, Pysa is aware that child classes can be used anywhere a parent classes's type is present. If you access a method on a parent class and the implementation on any child class returns taint, Pysa will detect that and treat the return from the parent class as tainted. For example, this will be detected as a tainted flow during static analysis: class Parent: def some_fn(self): &quot;&quot;&quot;Benign function with no annotations&quot;&quot;&quot; pass class Child(Parent): def some_fn(self): &quot;&quot;&quot;Function returning a tainted value&quot;&quot;&quot; return get_some_tainted_value() def fn(obj: Parent): some_sink(obj.some_fn()) # Detected as a tainted flow  A huge caveat here is that Pysa needs to be aware of these inheritance relationships and function definitions for it to work. Code that lives outside the repo under analysis might not be visible to Pysa, so these inheritances/implementations may be missed. See the Stubs section below for more details. ","version":"Next","tagName":"h3"},{"title":"Stubs​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#stubs","content":"The concept of stubs is covered in general here, but this section in particular will cover specific issues you may encounter with .pyistubs. These stubs can be used to prevent pyre errors for types that live outside the codebase you are running Pysa on. The simplest stubs are just empty files in the root of the stubs directory (assuming you have a stubsdirectory specified in the search_path list in your .pyre_configurationfile). An empty stub basically prevents all type checking errors within the namespace of that stub. So for uwsgi.pyi, in the stubs directory, the following code would not raise pyre errors (though it would obviously fail to run): import uwsgi from uwsgi import asdf, ZXCV uwsgi.qwer() variable = ZXCV() variable.hjkl()  If you want to be able to create .pysa models (i.e. annotate sources, sinks, etc.) for something that is outside your codebase, such as Django'sdjango.http.request.HttpRequest object, you need more than just an empty stub file. You need a directory structure and .pyi file that matches your import, such as stubs/django/http/request.pyi. Within that .pyi file, you then need a stub of the class: class HttpRequest(BinaryIO): def __init__(self) -&gt; None: ... COOKIES: Any = ... GET: QueryDict = ... # And a bunch more stuff...  Only at this point can you add .pysa files with annotations such as these: django.http.request.HttpRequest.COOKIES: TaintSource[UserControlled] django.http.request.HttpRequest.GET: TaintSource[UserControlled]  There is a huge gotcha here: If you had both an empty stubs/django.pyifile, and the stubs/django/http/request.pyi file shown above, pyre will see the django.pyi file first and ignore the request.pyi file (followingPEP 484). This would mean that your stub of HttpRequest would be missed, and yourHttpRequest.COOKIES and HttpRequest.GET annotations would cause errors when running Pysa. The fix is simply to delete the django.pyi file. When deleting that file, you may all of a sudden see new typing errors for other types within Django, for which you'll need to add new .pyi files at the appropriate locations. Since definitions in type stubs don't have bodies, all functions and methods will be treated as obscure models. If this leads to false positives, you will want to write a model for it. ","version":"Next","tagName":"h3"},{"title":"Helpful Python knowledge​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#helpful-python-knowledge","content":"Pretty much all python operators are reduced down to double underbar functions. For example, constructing an object results in a call to __init__(self, ...)and an asterisk operator results in a call to __mul__(a, b). A full list of these operators can be foundhere. This is useful to know when you need to add annotations to the usage of operators, such as the use of square brackets to access a dictionary. ","version":"Next","tagName":"h2"},{"title":"Debugging Tools​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#debugging-tools","content":"","version":"Next","tagName":"h2"},{"title":"pyre_dump()​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#pyre_dump","content":"You can insert a call to the (non-existent) pyre_dump() function in your code to enable verbose logging of the call graph, forward and backward analysis of the current function or method. This can be useful as a starting point to figure out why something is/isn't happening. This will produce very verbose output. ","version":"Next","tagName":"h3"},{"title":"pyre_dump_call_graph​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#pyre_dump_call_graph","content":"You can insert a call to pyre_dump_call_graph (no import needed) in a function or method to enable logging of the call graph building. This will produce verbose output. ","version":"Next","tagName":"h3"},{"title":"reveal_type(YOUR_VARIABLE)​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#reveal_typeyour_variable","content":"If you only want to check what pyre knows about the types of variables, inject a call to reveal_type(YOUR_VARIABLE) (no import needed) in your code. Running Pyre on your code will then give you compact output indicating what Pyre thinks the type of your variable is. ","version":"Next","tagName":"h3"},{"title":"reveal_taint(YOUR_VARIABLE)​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#reveal_taintyour_variable","content":"Similarly to reveal_type, if you only want to check what pyre knows about the taint on variables, inject a call to reveal_taint(YOUR_VARIABLE) (no import needed) in your code. Running Pysa on your code will then give you compact output indicating what taint Pysa has discovered. Note that each time Pysa analyzes the function (which could be many times) it will update it's understanding of the taint flowing into the function and output the current state. The final output will be the most complete. ","version":"Next","tagName":"h3"},{"title":"pyre_dump_perf()​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#pyre_dump_perf","content":"You can insert a call to pyre_dump_perf (no import needed) in a function or method to profile the current analysis on that function or method, and dump the results on stdout. ","version":"Next","tagName":"h3"},{"title":"results.json​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#resultsjson","content":"Another strategy for getting a bit more metadata is adding a function into your code, which simply constructs and returns the type you want to examine. You can then run Pysa, and grep for the function's name in the results.json file located wherever you pointed --save-results-to= to when running Pysa. You should then be able to see if that function is detected as returning taint, plus a bit more metadata about it. ","version":"Next","tagName":"h3"},{"title":"sapp​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#sapp","content":"The Static Analysis Post Processor (SAPP)has access to the same information as results.json. While SAPP doesn't display all the information results.json contains, it can display the information in a more user-friendly gdb-style way. It's especially useful for exploring flows which pass through many frames. ","version":"Next","tagName":"h3"},{"title":"Developer Quality-of-Life​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#developer-quality-of-life","content":"","version":"Next","tagName":"h2"},{"title":"Iterating quickly with Pysa​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#iterating-quickly-with-pysa","content":"On large projects, Pysa can take a long time to run; it takes about an hour to run on Instagram, which contains millions of lines of Python code. A few tricks to iterate more quickly with Pysa are: Run in a sample project or test environment. Pysa runs much more quickly on smaller projects, so if you need to test something that isn't specific to your environment (eg. a model that corresponds to code in typeshed) then do your testing in a smaller codebase. Even if you are iterating on something specific to your codebase, it can sometimes be worthwhile to port the code snippet you're working on into a test project. The stub integration tests will validate any stubs in tools/pyre/taint, and this can be a fast shortcut for validating new stubs you want to write. These tests reside in stubs/integration_test and can be invoked by running make stubs_integration_test in the root of the repo.The interprocedural analysis tests dump information about models, issues, the call graph, and overrides. It can be very helpful to test code in this environment if you need a detailed understanding of Pysa's internal state to debug a false positive or negative. Note that these tests do not have access to typeshed or any other type stubs. These tests reside ininterprocedural_analyses/taint/test/integration and can be invoked by running make test in the root of the repo. Skip analysis entirely if you only need to validate taint models.pyre validate-models can be used to validate taint models without having to run the entire analysis.Filter runs with --rule ###, --source ### or --sink ###. These options will cause Pysa to ignore sources and sinks that are not mentioned, or sources and sinks that are not involved in the given rule. This will save analysis time. E.g, pyre analyze --rule 5000 orpyre analyze --source UserControlled --sink RCE.Parallelize across machines. If working in a could hosted environment, reserving a second machine and working on two projects in parallel can be effective. As Pysa is running on one machine, you can switch to the other, make changes there, kick off a run, and then switch back to the first to look at results.Put in all debug statements up front. When using the debugging tools outlined above, put in way more debug statments than you think you need, dumping type info and taint for anything remotely related to the flow you're looking at. This will reduce the odds that you need to do a second run to figure out what's going wrong.Enable the --use-cache flag. All Pysa runs require some information from Pyre, such as the typechecking environment, dependencies, etc. Computing this information can be time-consuming on larger projects. However, if you're only editing taint models and not the project source, this information isn't expected to change between Pysa runs. By enabling this flag, you can tell Pysa to save this information to cache files (located in .pyre/.pysa_cache) and load from cache in subsequent runs, rather than computing it from scratch each time. The cache will be invalidated if any of the project source files change, in which case Pysa will fall back to doing a clean run and then saving the computed artifacts in new cache files. ","version":"Next","tagName":"h3"},{"title":"File Types​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#file-types","content":"taint.config is a JSON file and .pysa files use Python syntax. If you update your editor to recognize those files as JSON and Python respectively, it'll make development easier. To configure this in VSCode: Press Cmd-Shift-P and type User Settings (JSON)Add the following definition: &quot;files.associations&quot;: { &quot;*.pysa&quot;: &quot;python&quot;, &quot;taint.config&quot;: &quot;json&quot; },  ","version":"Next","tagName":"h3"},{"title":"Usage Examples​","type":1,"pageTitle":"General Tips","url":"/docs/pysa-tips/#usage-examples","content":"Not all Pysa features will be covered in these docs, and provided examples won't always be complete. Every feature, however, will be covered in the tests locatedhere. These tests can be a useful resource to discover how to use Pysa features. ","version":"Next","tagName":"h2"},{"title":"Static Analysis Post Processor","type":0,"sectionRef":"#","url":"/docs/static-analysis-post-processor/","content":"Static Analysis Post Processor The pyre analyze command runs static analysis and outputs the result as JSON. The Static Analysis Post Processor (SAPP) tool can process these results and allows the user to explore the results. Documentation for SAPP is available here.","keywords":"","version":"Next"},{"title":"Types in Python","type":0,"sectionRef":"#","url":"/docs/types-in-python/","content":"","keywords":"","version":"Next"},{"title":"Why Types?​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#why-types","content":"","version":"Next","tagName":"h2"},{"title":"Gradual Typing​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#gradual-typing","content":"Most Python code does not (yet) start out typed. PEP 484 specifies a gradual type system, which is built to allow you to gradually add annotations over time. It does so by only reporting errors on functions that have an explicit return or parameter type annotation,introducing an escape hatch: a special type Any that has all possible attributes and is both sub- and super-type of any other type,and assuming that all untyped fuctions implicitly return Any. For example, from typing import List def unannotated(): # implictly returns `Any` return b&quot;&quot; + &quot;&quot; # function body is not checked def annotated() -&gt; List: # explicit return annotation means we type check `annotated` any = unannotated() any.attribute # `Any` has all possible attributes return 1 # Error: returning `int` but expecting `List`  In combination, these rules allow you to slowly annotate code without getting overwhelmed by type errors in one sitting. Incrementally adding more annotations will give you stronger safety and consistency guarantees in your codebase. In the example above, if you changed unannotated to return str, you would get a type error when accessing the attribute any.attribute in annotated. ","version":"Next","tagName":"h2"},{"title":"Strict Mode​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#strict-mode","content":"While Any is a necessary escape hatch when annotating large codebases over time, it can hide legitimate type errors. We've introduced strict mode in Pyre to address this problem. Strict mode can be toggled at a module level by introducing a # pyre-strict comment to the file. In strict mode, Pyre will run on all functions, whether they are annotated or not,error on functions, globals, or attributes that are missing annotations,and error on annotations containing Any (with some exceptions to accommodate for common patterns). In our previous example, # pyre-strict from typing import List def unannotated(): # Error: missing return annotation return b&quot;&quot; + &quot;&quot; # Error: function body *is* checked def annotated() -&gt; List: # Error: implicit `Any` for generic parameter to `List` any = unannotated() any.attribute # Note: the type of `any` is still any. return 1 # Error: returning `int` but expecting `List`  As you can see in the example, Any can still sneak into modules that are strict, but increasing strict coverage and fixing the surfaced errors will gradually eliminate them. ","version":"Next","tagName":"h2"},{"title":"Strict-By-Default​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#strict-by-default","content":"Strict mode can also be set as the default in a project configuration. To opt individual files out of strict mode, use # pyre-unsafe in place of # pyre-strict. ","version":"Next","tagName":"h3"},{"title":"How to move away from Any​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#how-to-move-away-from-any","content":"","version":"Next","tagName":"h2"},{"title":"What if I want to use Any?​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#what-if-i-want-to-use-any","content":"It may be tempting to annotate a generic function parameter with Any. But while it is a convenient utility for quickly annotating untyped code, it has no place in a strict-mode codebase. The main problem with Any is that it unifies with every type - which effectively hides all potential type errors that could stem from incorrect usage of anything annotated with Any. It is not, therefore, a good idea to use it in generic code. ","version":"Next","tagName":"h3"},{"title":"What then?​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#what-then","content":"We have two main methods for annotating generic code: object and TypeVar. As it turns out, it is not at all obvious which of them should be used where. However, the general TL;DR is that object is an opaque superclass of all types, while TypeVar is for preserving a type across one or more function calls. ","version":"Next","tagName":"h3"},{"title":"About object​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#about-object","content":"The advantage of using object over Any is that while any type can be “put inside” it, it is an error to use it as any type other than object. This can be useful everywhere we need type erasure, like (de)serialization or generic heterogeneous containers where there is no obvious common supertype. Thanks to Python’s runtime reflection, the original type can be recovered, e.g. through isinstance. Note that such checks are valid only for a short time, see here. ","version":"Next","tagName":"h3"},{"title":"About TypeVar​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#about-typevar","content":"TypeVars are somewhat interesting beasts, as in a vacuum, they can behave both like Any and like object. Like object, they accept all types, but within a single typecheck (i.e. one line/function call/operation) they remember what type they were. This makes them useful for e.g. linking the parameters and return types of a function, or class attribute types with its method signatures. There are, however, a couple of caveats. It doesn’t make sense to use a TypeVar on a function or method when it’s only used in its parameters (just use the most general known supertype instead). Another story is the difference between TypeVars’ invariance, variance and contravariance, which is covered in here. ","version":"Next","tagName":"h3"},{"title":"When Source Code is not Available​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#when-source-code-is-not-available","content":"We do not always have access to all the source code that contributes type information to our project: e.g. builtins is compiled native code, and other libraries may be using Cython. Other times, we may be working with Python code that is just too dynamic to be reasonably typed. To address these cases, Pyre will give precedence to type stub files with a *.pyi extension over source files when these are specified in the search path in the project configuration or if they are located next to the implementation file. Stub files have the same structure as implementation files but only contain class and function signatures: # my_dynamic_module.pyi def dynamic_function() -&gt; int: ... # Function body is omitted  If a __getattr__ function is defined in the stub file as follows, Pyre will take it as a signal that the stub file is partially complete: accessing attributes whose name is not defined in the stub file will result in Any instead of a type error. # my_stub.pyi from typing import Any foo: int = 42 # Parameter needs to be typed as `str` and return type needs to be `Any` def __getattr__(name: str) -&gt; Any: ... # my_source.py import my_stub reveal_type(my_stub.foo) # Reveals `int` reveal_type(my_stub.undefined) # Reveals `Any`  ","version":"Next","tagName":"h2"},{"title":"Typeshed​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#typeshed","content":"","version":"Next","tagName":"h3"},{"title":"Strategies for Increasing Coverage​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#strategies-for-increasing-coverage","content":"Pyre comes with tooling to make it easy to increase type coverage in your project. ","version":"Next","tagName":"h2"},{"title":"Upgrade​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#upgrade","content":"When upgrading the type checker, new errors inevitably get surfaced. In order to keep a codebase clean through upgrades we've built pyre-upgrade, which automatically suppresses newly surfaced type errors. It takes Pyre's output and adds supression comments to the code explaining what's wrong so that developers can easily address the issues individually. You can run pyre-upgrade with (venv) $ pyre --output=json | pyre-upgrade fixme  or if you are using a local configuration (venv) $ pyre --output=json -l &lt;project&gt; | pyre-upgrade fixme  ","version":"Next","tagName":"h3"},{"title":"Automatic Type Inference​","type":1,"pageTitle":"Types in Python","url":"/docs/types-in-python/#automatic-type-inference","content":"We have found tools that automatically add type annotations to code useful to get started with a project. There are two general approaches to automatic type inference: static inference and dynamic inference from runtime information. Both approaches come with their own trade-offs and we have found a combination of the two to be useful. Pyre can do static type inference. You can run (venv) $ cd &lt;path to project&gt;; pyre infer -i  to automatically apply annotations. For dynamic inference we recommend you give MonkeyType a try. ","version":"Next","tagName":"h3"},{"title":"5001 - Code Injection","type":0,"sectionRef":"#","url":"/docs/warning_codes/code-5001-public/","content":"","keywords":"","version":"Next"},{"title":"TL;DR​","type":1,"pageTitle":"5001 - Code Injection","url":"/docs/warning_codes/code-5001-public/#tldr","content":"This category indicates that user-controlled input flows into a sink that allows code or shell command execution. This directly leads to Remote Code Execution which can be assumed to mean complete compromise of the server. ","version":"Next","tagName":"h2"},{"title":"RCE via Code Injection (eval/exec)​","type":1,"pageTitle":"5001 - Code Injection","url":"/docs/warning_codes/code-5001-public/#rce-via-code-injection-evalexec","content":"","version":"Next","tagName":"h2"},{"title":"ISSUE​","type":1,"pageTitle":"5001 - Code Injection","url":"/docs/warning_codes/code-5001-public/#issue","content":"The simplest kind of RCE involves user input flowing into a function such as eval or exec which are intended to interpret or run python code. ","version":"Next","tagName":"h3"},{"title":"EXAMPLE​","type":1,"pageTitle":"5001 - Code Injection","url":"/docs/warning_codes/code-5001-public/#example","content":"def update_search_account_filtering(request: HttpRequest) -&gt; HttpResponse: ... if action in [&quot;delete&quot;, &quot;add&quot;, &quot;update&quot;]: ... filter_by_username = eval(request.POST.get(&quot;filter_by_username&quot;, &quot;True&quot;))  ","version":"Next","tagName":"h3"},{"title":"RECOMMENDED SOLUTION​","type":1,"pageTitle":"5001 - Code Injection","url":"/docs/warning_codes/code-5001-public/#recommended-solution","content":"There are few reasons to use these functions, and even fewer reasons to allow a user to control the content of these functions. Generally, we recommend not making calls to these functions with user input. If you only need to eval python datatypes you can use ast.literal_eval. Using it on arbitrary user input can still lead to DOS attack but can't be exploited for code execution (details). ","version":"Next","tagName":"h3"},{"title":"RCE via Command Injection (os.system)​","type":1,"pageTitle":"5001 - Code Injection","url":"/docs/warning_codes/code-5001-public/#rce-via-command-injection-ossystem","content":"","version":"Next","tagName":"h2"},{"title":"ISSUE​","type":1,"pageTitle":"5001 - Code Injection","url":"/docs/warning_codes/code-5001-public/#issue-1","content":"This kind of RCE involves user input flowing into a command executed in a system shell. If a user can control a portion of the command being executed in a shell, they can potentially add additional arbitrary commands to be executed. ","version":"Next","tagName":"h3"},{"title":"EXAMPLE​","type":1,"pageTitle":"5001 - Code Injection","url":"/docs/warning_codes/code-5001-public/#example-1","content":"The following code is intended to run the spellcheck binary on a user provided text: def spellcheck(request: HttpRequest): command = f&quot;/usr/bin/spellcheck -l {request.GET['text']}&quot; return subprocess.getoutput(command)  An attacker, however, can supply a path such as 'test' &amp;&amp; rm -rf /, which would result in the following command being executed: /usr/bin/spellcheck -l 'test' &amp;&amp; rm -rf /. Since this command is executed in a system shell the rm -rf / command will be executed after the spellcheck command. ","version":"Next","tagName":"h3"},{"title":"RECOMMENDED SOLUTION​","type":1,"pageTitle":"5001 - Code Injection","url":"/docs/warning_codes/code-5001-public/#recommended-solution-1","content":"In general, we recommend avoiding creation of a subprocess and prefer using the API provided by the language. However, if you need to create a subprocess, we recommend using an API such as subprocess.run, which allows you to separate arguments from the executable being invoked. DO NOT add the shell=True argument otherwise the code would still be vulnerable like the previous example def spellcheck(request: HttpRequest): command = [&quot;/usr/bin/spellcheck&quot;, &quot;-l&quot;, request.GET['text']] subprocess.run(command)  NOTE: be conscious of the fact that arguments to an executable can still lead to code execution (e.g., the -exec argument of find). ","version":"Next","tagName":"h3"},{"title":"6065 - Commandline arguments injection","type":0,"sectionRef":"#","url":"/docs/warning_codes/code-6065-public/","content":"","keywords":"","version":"Next"},{"title":"TL;DR​","type":1,"pageTitle":"6065 - Commandline arguments injection","url":"/docs/warning_codes/code-6065-public/#tldr","content":"This category indicates that user-controlled input flows into a command-line argument used to execute an external process. Unlike category 5001, this leads to a Remote Code Execution issue only in specific cases (e.g., shell=True parameter or when executing particular binaries). ","version":"Next","tagName":"h2"},{"title":"ISSUE​","type":1,"pageTitle":"6065 - Commandline arguments injection","url":"/docs/warning_codes/code-6065-public/#issue","content":"subprocess.Popen, subprocess.run, subprocess.call, and other functions do a good job in preventing by default the command injection issues we described in category 5001. The values supplied in the args parameter (excluding the first which represents the executable) are considered only as arguments and not as commands to be interpreted in a system shell (more details in the python documentation). However, this safe behaviour can be manually bypassed by specifying the shell=True parameter, which reintroduces the command injection issue. ","version":"Next","tagName":"h3"},{"title":"EXAMPLE​","type":1,"pageTitle":"6065 - Commandline arguments injection","url":"/docs/warning_codes/code-6065-public/#example","content":"The following code is intended to run the spellcheck binary on a user provided text: def spellcheck(request: HttpRequest): command = &quot;/usr/bin/spellcheck -l {}&quot;.format(request.GET['text']) return subprocess.run(command, shell=True)  An attacker, however, can supply a path such as 'test' &amp;&amp; rm -rf /, which would result in the following command being executed: /usr/bin/spellcheck -l 'test' &amp;&amp; rm -rf /. Since this command is executed in a system shell the rm -rf / command will be executed after the spellcheck command. ","version":"Next","tagName":"h3"},{"title":"RECOMMENDED SOLUTION​","type":1,"pageTitle":"6065 - Commandline arguments injection","url":"/docs/warning_codes/code-6065-public/#recommended-solution","content":"In general, we recommend avoiding creation of a subprocess and prefer using the API provided by the language. However, if you need to create a subprocess, we recommend using a safe API such as subprocess.run and avoiding use of the shell=True argument. If this is not possible, we recommend ensuring that the user-controlled values are shell-escaped with shlex.quote. def spellcheck(request: HttpRequest): command = [&quot;/usr/bin/spellcheck&quot;, &quot;-l&quot;, request.GET['text']] subprocess.run(command)  NOTE: be conscious of the fact that arguments to an executable can still lead to code execution (e.g., the -exec argument of find). ","version":"Next","tagName":"h3"},{"title":"Overview","type":0,"sectionRef":"#","url":"/docs/warning_codes/overview-public/","content":"Overview Pysa tracks data flows from a set of sources to sinks. Each set of sources we track to sinks is assigned a unique code. When Pysa finds a flow, it emits issues associated with the unique code. This section of the website contains documentation for the warning codes we emit. The source of truth for these warning codes is the taint_config.json files used in a given run.","keywords":"","version":"Next"},{"title":"Querying Pyre","type":0,"sectionRef":"#","url":"/docs/querying-pyre/","content":"","keywords":"","version":"Next"},{"title":"Supported Queries​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#supported-queries","content":"","version":"Next","tagName":"h2"},{"title":"Attributes​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#attributes","content":"The command attributes gives you the list of attributes for a class. # a.py class C: a: int = 2 def foo(self) -&gt; str: return &quot;&quot;  $ pyre query &quot;attributes(a.C)&quot; { &quot;response&quot;: { &quot;attributes&quot;: [ { &quot;annotation&quot;: &quot;int&quot;, &quot;name&quot;: &quot;a&quot; }, { &quot;annotation&quot;: &quot;typing.Callable(a.C.foo)[[], str]&quot;, &quot;name&quot;: &quot;foo&quot; } ] } }  ","version":"Next","tagName":"h3"},{"title":"Callees​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#callees","content":"The command callees returns a list of all calls from a given function, including locations if using callees_from_location. # a.py def foo() -&gt; None: pass def bar() -&gt; None: foo()  $ pyre query &quot;callees(a.bar)&quot; { &quot;response&quot;: { &quot;callees&quot;: [ { &quot;kind&quot;: &quot;function&quot;, &quot;target&quot;: &quot;a.foo&quot; } ] } }  $ pyre query &quot;callees_with_location(a.bar)&quot; { &quot;response&quot;: { &quot;callees&quot;: [ { &quot;locations&quot;: [ { &quot;path&quot;: &quot;a.py&quot;, &quot;start&quot;: { &quot;line&quot;: 6, &quot;column&quot;: 5 }, &quot;stop&quot;: { &quot;line&quot;: 6, &quot;column&quot;: 8 } } ], &quot;kind&quot;: &quot;function&quot;, &quot;target&quot;: &quot;a.foo&quot; } ] } }  ","version":"Next","tagName":"h3"},{"title":"Defines​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#defines","content":"The command defines returns all function and method definitions for a given module or class. # a.py class C: a: int = 2 def foo(self) -&gt; str: return &quot;&quot; def bar() -&gt; None: pass  $ pyre query &quot;defines(a.C)&quot; { &quot;response&quot;: [ { &quot;name&quot;: &quot;a.C.foo&quot;, &quot;parameters&quot;: [ { &quot;name&quot;: &quot;self&quot;, &quot;annotation&quot;: null } ], &quot;return_annotation&quot;: &quot;str&quot; } ] }  $ pyre query &quot;defines(a)&quot; { &quot;response&quot;: [ { &quot;name&quot;: &quot;a.C.foo&quot;, &quot;parameters&quot;: [ { &quot;name&quot;: &quot;self&quot;, &quot;annotation&quot;: null } ], &quot;return_annotation&quot;: &quot;str&quot; }, { &quot;name&quot;: &quot;a.bar&quot;, &quot;parameters&quot;: [], &quot;return_annotation&quot;: &quot;None&quot; } ] }  ","version":"Next","tagName":"h3"},{"title":"Dump class hierarchy​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#dump-class-hierarchy","content":"The command dump_class_hierarchy() returns the entire class hierarchy as Pyre understands it; elides type variables. ","version":"Next","tagName":"h3"},{"title":"Global leaks​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#global-leaks","content":"The command global_leaks([function1[, function2[, ...]]]) gives you the list of mutations to global variables and class attributes within the bodies of the given callables. If no callables are provided to the query, it is a no-op. # a.py class A: my_class_variable: int = 3 def foo(self) -&gt; None: pass # b/c.py from a import A from typing import Dict MY_GLOBAL: Dict[str, int] = {&quot;a&quot;: 1} def bar() -&gt; None: A.my_class_variable = 4 def baz() -&gt; None: MY_GLOBAL.setdefault(&quot;b&quot;, 2)  $ pyre query &quot;global_leaks(a.A.foo, b.c.bar, b.c.baz)&quot; { &quot;response&quot;: { &quot;query_errors&quot;: [], &quot;global_leaks&quot;: [ { &quot;line&quot;: 8, &quot;column&quot;: 4, &quot;stop_line&quot;: 8, &quot;stop_column&quot;: 27, &quot;path&quot;: &quot;/path/to/b/c.py&quot;, &quot;code&quot;: 3103, &quot;name&quot;: &quot;Leak to a class variable&quot;, &quot;description&quot;: &quot;Leak to a class variable [3103]: Data write to global variable `a.A` of type `typing.Type[a.A]`.&quot;, &quot;long_description&quot;: &quot;Leak to a class variable [3103]: Data write to global variable `a.A` of type `typing.Type[a.A]`.&quot;, &quot;concise_description&quot;: &quot;Leak to a class variable [3103]: Data write to global variable `A` of type `typing.Type[a.A]`.&quot;, &quot;define&quot;: &quot;b.c.bar&quot; }, { &quot;line&quot;: 12, &quot;column&quot;: 4, &quot;stop_line&quot;: 12, &quot;stop_column&quot;: 24, &quot;path&quot;: &quot;/path/to/b/c.py&quot;, &quot;code&quot;: 3101, &quot;name&quot;: &quot;Leak to a mutable datastructure&quot;, &quot;description&quot;: &quot;Leak to a mutable datastructure [3101]: Data write to global variable `b.c.MY_GLOBAL` of type `typing.Dict[str, int]`.&quot;, &quot;long_description&quot;: &quot;Leak to a mutable datastructure [3101]: Data write to global variable `b.c.MY_GLOBAL` of type `typing.Dict[str, int]`.&quot;, &quot;concise_description&quot;: &quot;Leak to a mutable datastructure [3101]: Data write to global variable `MY_GLOBAL` of type `typing.Dict[str, int]`.&quot;, &quot;define&quot;: &quot;b.c.baz&quot; } ] } }  Five kinds of leaks are checked for, which can be found in source/analysis/analysisError.ml, under the GlobalLeaks module: Direct mutations to a global The mutation methods checked for include any mutation methods on dict, list, or set, as well as __setitem__ calls on any type. def foo() -&gt; None: MY_GLOBAL = 1 # leak MY_LIST.append(1) # leak MY_DICT[&quot;a&quot;] = 2 # leak MY_SET |= {2} # leak MY_CUSTOM_GLOBAL.custom_mutation_method(5) # no leak  Mutations of class attributes The same cases as direct mutations to a global are checked, as well as __setattr__ and setattr(...) calls on any type. def foo() -&gt; None: MY_GLOBAL.x = 1 # leak MY_GLOBAL.y.z.a.b = 1 # leak MY_GLOBAL.some_list.append(3) # leak setattr(MY_GLOBAL, &quot;b&quot;, 2) # leak MY_GLOBAL.__setattr__(&quot;c&quot;, 3) # leak  Assignment of a global or its attributes into a local variable def foo() -&gt; None: my_local: int = MY_GLOBAL_INT # leak my_other_local: List[str] = MY_OTHER_GLOBAL.str_list # leak  Passing a global or its attribtues as a parameter def foo() -&gt; None: my_other_function(MY_GLOBAL) # leak a = MyClass() a.some_method(MY_GLOBAL.x) # leak  Returning a global or its attributes from a function or method def foo() -&gt; None: return MY_GLOBAL # leak def bar() -&gt; None: return MY_GLOBAL.x # leak  ","version":"Next","tagName":"h3"},{"title":"Less or equal​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#less-or-equal","content":"The command less_or_equal returns whether the type on the left can be used when the type on the right is expected. # a.py class C: pass class D(C): pass  $ pyre query &quot;less_or_equal(a.D, a.C)&quot; {&quot;response&quot;:{&quot;boolean&quot;:true}} $ pyre query &quot;less_or_equal(a.C, a.D)&quot; {&quot;response&quot;:{&quot;boolean&quot;:true}}  ","version":"Next","tagName":"h3"},{"title":"Model Query​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#model-query","content":"The command model_query returns the models generated by a given ModelQuery. Valid path inputs are absolute paths to directories containing a taint.config file. One can find all valid paths by using the validate_taint_models command. # a.py def foo(x): ... def food(y): ...  # test.pysa ModelQuery( name = &quot;get_foo_sources&quot;, find = &quot;functions&quot;, where = [ name.matches(&quot;foo&quot;) ], model = [ Parameters(TaintSource[Test]) ] )  $ pyre query &quot;model_query(path='/absolute/path/to/test_pysa/directory', query_name='get_foo_sources')&quot; { &quot;response&quot;: [ { &quot;callable&quot;: &quot;test.foo&quot;, &quot;model&quot;: { &quot;kind&quot;: &quot;model&quot;, &quot;data&quot;: { &quot;callable&quot;: &quot;test.foo&quot;, &quot;sources&quot;: [ { &quot;port&quot;: &quot;formal(x)&quot;, &quot;taint&quot;:[ { &quot;kinds&quot;:[{&quot;kind&quot;:&quot;Test&quot;}], &quot;decl&quot;:null } ] } ] } } }, { &quot;callable&quot;: &quot;test.food&quot;, &quot;model&quot;: { &quot;kind&quot;: &quot;model&quot;, &quot;data&quot;: { &quot;callable&quot;: &quot;test.food&quot;, &quot;sources&quot;: [ { &quot;port&quot;: &quot;formal(y)&quot;, &quot;taint&quot;:[ { &quot;kinds&quot;:[{&quot;kind&quot;:&quot;Test&quot;}], &quot;decl&quot;:null } ] } ] } } } ] }  caution pyre query does not include external sources by default, which leads to discrepancies with pyre analyze (i.e, Pysa). To avoid this problem, we recommend starting a pyre server with the following parameters: $ pyre --no-saved-state start --skip-initial-type-check --wait-on-initialization --analyze-external-sources  ","version":"Next","tagName":"h3"},{"title":"Path of module​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#path-of-module","content":"The command path_of_module returns the full absolute path for a given module. $ pyre query &quot;path_of_module(module_name)&quot; { &quot;response&quot;: { &quot;path&quot;: &quot;/Users/user/my_project/module_name.py&quot; } }  ","version":"Next","tagName":"h3"},{"title":"Save server state​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#save-server-state","content":"The command save_server_state saves the server's serialized state into the given path, which can the be used to start up the identical server without re-analyzing all project files. $ pyre query &quot;save_server_state('my_saved_state')&quot; { &quot;response&quot;: { &quot;message&quot;: &quot;Saved state.&quot; } } $ pyre stop $ pyre --load-initial-state-from my_saved_state start  ","version":"Next","tagName":"h3"},{"title":"Superclasses​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#superclasses","content":"The command superclasses returns the superclasses of given class names. $ pyre query &quot;superclasses(int, str)&quot; { &quot;response&quot;: [ { &quot;int&quot;: [ &quot;complex&quot;, &quot;float&quot;, &quot;numbers.Complex&quot;, &quot;numbers.Integral&quot;, &quot;numbers.Number&quot;, &quot;numbers.Rational&quot;, &quot;numbers.Real&quot;, &quot;object&quot;, &quot;typing.Generic&quot;, &quot;typing.Protocol&quot;, &quot;typing.SupportsFloat&quot; ] }, { &quot;str&quot;: [ &quot;object&quot;, &quot;typing.Collection&quot;, &quot;typing.Container&quot;, &quot;typing.Generic&quot;, &quot;typing.Iterable&quot;, &quot;typing.Protocol&quot;, &quot;typing.Reversible&quot;, &quot;typing.Sequence&quot; ] } ] }  ","version":"Next","tagName":"h3"},{"title":"Type​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#type","content":"The command type evaluates the type of the given expression. $ pyre query &quot;type([1 + 2, ''])&quot; { &quot;response&quot;: { &quot;type&quot;: &quot;typing.List[typing.Union[int, str]]&quot; } }  ","version":"Next","tagName":"h3"},{"title":"Types in file​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#types-in-file","content":"The command types returns all the types for a file that Pyre has been able to resolve. Paths must be relative paths relative to the pyre_configuration for this file. It can be called on multiple files at once withtypes('path1', 'path2', ...). # a.py class C: attribute = &quot;&quot;  $ pyre query &quot;types(path='a.py')&quot; { &quot;response&quot;: [ { &quot;path&quot;: &quot;a.py&quot;, &quot;types&quot;: [ { &quot;annotation&quot;: &quot;str&quot;, &quot;location&quot;: { &quot;path&quot;: &quot;a.py&quot;, &quot;start&quot;: { &quot;column&quot;: 16, &quot;line&quot;: 2 }, &quot;stop&quot;: { &quot;column&quot;: 18, &quot;line&quot;: 2 } } }, { &quot;annotation&quot;: &quot;str&quot;, &quot;location&quot;: { &quot;path&quot;: &quot;a.py&quot;, &quot;start&quot;: { &quot;column&quot;: 4, &quot;line&quot;: 2 }, &quot;stop&quot;: { &quot;column&quot;: 13, &quot;line&quot;: 2 } } }, { &quot;annotation&quot;: &quot;typing.Type[a.C]&quot;, &quot;location&quot;: { &quot;path&quot;: &quot;a.py&quot;, &quot;start&quot;: { &quot;column&quot;: 4, &quot;line&quot;: 2 }, &quot;stop&quot;: { &quot;column&quot;: 13, &quot;line&quot;: 2 } } } ] } ] }  ","version":"Next","tagName":"h3"},{"title":"Validate Taint Models​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#validate-taint-models","content":"The command validate_taint_models returns the absolute paths of all the directories in which Pysa recognises all the models their TARGETS file's environment. $ pyre query &quot;validate_taint_models()&quot; { &quot;response&quot;: { &quot;message&quot;: &quot;Models in `/data/users/$USER/valid/path/one, /data/users/$USER/valid/path/two` are valid.&quot; } }  ","version":"Next","tagName":"h3"},{"title":"API Details​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#api-details","content":"","version":"Next","tagName":"h2"},{"title":"Location Guidelines​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#location-guidelines","content":"We determine locations for expressions using the following guidelines: Ignore leading and trailing whitespace, commas, comments, and wrapping parenthesis.Include whitespace, parenthesis or other noop tokens in the locations of compound expressions they are nested inside. Ex. (a).b will register two expressions, a at columns 1-2 (still following the guideline above), and a.b at columns 0-5 Similarly, compound expression locations must encompass the locations of all of its components. Ex. a = b = 1 will register the assignment a = 1 at columns 0-9, with a at columns 0-1 and 1 at columns 8-9The only exception are classes, which do not encompass their decorators All semantically meaningful tokens and reserved words are included in the node they define. Ex. await a will register the awaitable node at columns 0-7, and the included identifier a at columns 6-7Ex. async def foo(): ... will register the define node at columns 0-20Ex. foo(*args, **kwargs) will register args at columns 4-9 and kwargs at columns 11-19Ex. &quot;&quot;&quot;string&quot;&quot;&quot; will register the string string at columns 0-12 All implicit values in the AST contribute a length of 0 and point to the closest location to where an equivalent explicit value would live. Ex. a: int would register an Ellipsis object at columns 6-6Ex. a[0] would register a at columns 0-1 and a.__getitem__ at columns 0-1Ex. a[:1] would register the first argument of slice to be None at columns 2-2, the second argument to be 1 at columns 3-4, and the third argument to be None at columns 4-4. ","version":"Next","tagName":"h3"},{"title":"Batching Queries​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#batching-queries","content":"The batch command can be used to run several queries at once and return a map of responses. The list of queries to batch may include any combination of other valid queries except for batch itself. The response for a batch command will be a list of responses the same length as the number of queries getting batched, and the order of the responses will match the order of the queries. $ pyre query &quot;batch(less_or_equal(int, str), join(int, str))&quot; { &quot;response&quot;: [ { &quot;response&quot;: { &quot;boolean&quot;: false } }, { &quot;response&quot;: { &quot;type&quot;: &quot;typing.Union[int, str]&quot; } } ] }  ","version":"Next","tagName":"h3"},{"title":"Caching​","type":1,"pageTitle":"Querying Pyre","url":"/docs/querying-pyre/#caching","content":"Pyre rechecks each file when queried to generate the location-type mapping, caching results for re-queries of the same file. If you anticipate a large codemod where significant portions of the codebase will be queried, you may increase incremental performance by starting a temporary server with the flag: pyre start --store-type-check-resolution. ","version":"Next","tagName":"h3"},{"title":"Model Domain Specific Language (DSL)","type":0,"sectionRef":"#","url":"/docs/pysa-model-dsl/","content":"","keywords":"","version":"Next"},{"title":"Basics​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#basics","content":"The most basic form of querying Pysa's DSL is by generating models based on function names. To do so, add a ModelQuery to your .pysa file: ModelQuery( # Indicates the name of the query name = &quot;get_foo_sources&quot;, # Indicates that this query is looking for functions find = &quot;functions&quot;, # Indicates those functions should be called 'foo' where = [name.matches(&quot;foo&quot;)], # Indicates that matched function should be modeled as returning 'Test' taint model = [ Returns(TaintSource[Test]), ], # Indicates that the generated models should include the 'foo' and 'foo2' functions expected_models = [ &quot;def file.foo() -&gt; TaintSource[Test]: ...&quot;, &quot;def file.foo2() -&gt; TaintSource[Test]: ...&quot; ], # Indicates that the generated models should not include the 'bar' function unexpected_models = [ &quot;def file.bar() -&gt; TaintSource[Test]: ...&quot; ] )  Things to note in this example: The name clause is the name of your query.The find clause lets you pick whether you want to model functions, methods or attributes.The where clause is how you refine your criteria for when a model should be generated - in this example, we're filtering for functions whose names contain foo.The model clause is a list of models to generate. Here, the syntax means that the functions matching the where clause should be modelled as returningTaintSource[Test].The expected_models and unexpected_models clauses are optional and allow you to specify models that should or should not be generated by your query. When invoking Pysa, if you add the--dump-model-query-results /path/to/output/file flag to your invocation, the generated models, sorted under the respective ModelQuery that created them, will be written to a file in JSON format. $ pyre analyze --dump-model-query-results /path/to/output/file.txt ... &gt; Emitting the model query results to `/my/home/dir/.pyre/model_query_results.pysa`  You can then view this file to see the generated models. You can also test DSL queries usingpyre query. ","version":"Next","tagName":"h2"},{"title":"Name clauses​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#name-clauses","content":"The name clause describes what the query is meant to find. Normally it follows the format of get_ + [what the query matches with in the where clause] +[_sinks, _source and/or _tito]. This clause should be unique for every ModelQuery within a file. ","version":"Next","tagName":"h2"},{"title":"Find clauses​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#find-clauses","content":"The find clause specifies what entities to model, and currently supports&quot;functions&quot;, &quot;methods&quot;, &quot;attributes&quot;, and &quot;globals&quot;. &quot;functions&quot;indicates that you're querying for free functions, &quot;methods&quot; indicates that you're only querying class methods, &quot;attributes&quot; indicates that you're querying for attributes on classes, and &quot;globals&quot; indicates that you're querying for names available in the global scope. Note that &quot;attributes&quot; also includes constructor-initialized attributes, such as C.y in the following case: class C: x = ... def __init__(self): self.y = ...  Note that &quot;globals&quot; currently don't infer the type annotation of their value, so querying is more effective when they're properly annotated. def fun(x: int, y: str) -&gt; int: return x + int(y) a = fun(1, &quot;2&quot;) # -&gt; typing.Any b: int = fun(1, &quot;2&quot;) # -&gt; int  ","version":"Next","tagName":"h2"},{"title":"Where clauses​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#where-clauses","content":"where clauses are a list of predicates, all of which must match for an entity to be modelled. Note that certain predicates are only compatible with specific find clause kinds. ","version":"Next","tagName":"h2"},{"title":"fully_qualified_name.matches​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#fully_qualified_namematches","content":"The most basic query predicate is a name match - the name you're searching for is compiled as a regex, and the entity's fully qualified name is compared against it. A fully qualified name includes the module and class - for example, for a method foo in class C which is part of module bar, the fully qualified name is bar.C.foo. Example: ModelQuery( name = &quot;get_starting_with_foo&quot;, find = ..., where = [ fully_qualified_name.matches(&quot;foo.*&quot;) ], model = ... )  caution matches performs a partial match! For instance, matches(&quot;bar&quot;) will match against a function named my_module.foobarbaz. To perform a full match, use ^and $. For instance: matches(&quot;^.*\\.bar$&quot;). ","version":"Next","tagName":"h3"},{"title":"fully_qualified_name.equals​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#fully_qualified_nameequals","content":"This clause will match when the entity's fully qualified name is exactly the same as the specified string. Example: ModelQuery( name = &quot;get_bar_C_foo&quot;, find = ..., where = [ fully_qualified_name.equals(&quot;bar.C.foo&quot;) ], model = ... )  ","version":"Next","tagName":"h3"},{"title":"name.matches​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#namematches","content":"The name.matches clause is similar to fully_qualified_name.matches, but matches against the actual name of the entity, excluding module and class names. Example: ModelQuery( name = &quot;get_starting_with_foo&quot;, find = ..., where = [ name.matches(&quot;foo.*&quot;) ], model = ... )  caution matches performs a partial match! For instance, matches(&quot;bar&quot;) will match against a function named foobarbaz. To perform a full match, use ^ and $. For instance: matches(&quot;^.*bar$&quot;). ","version":"Next","tagName":"h3"},{"title":"name.equals​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#nameequals","content":"The name.equals clause is similar to fully_qualified_name.equals, but matches against the actual name of the entity, excluding module and class names. ModelQuery( name = &quot;get_foo&quot;, find = ..., where = [ name.equals(&quot;foo&quot;) ], model = ... )  ","version":"Next","tagName":"h3"},{"title":"return_annotation clauses​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#return_annotation-clauses","content":"Model queries allow for querying based on the return annotation of a callable. Note that this where clause does not work when the find clause specifies&quot;attributes&quot;. return_annotation.equals​ The clause will match when the fully-qualified name of the callable's return type matches the specified value exactly. ModelQuery( name = &quot;get_return_HttpRequest_sources&quot;, find = &quot;functions&quot;, where = [ return_annotation.equals(&quot;django.http.HttpRequest&quot;), ], model = Returns(TaintSource[UserControlled, Via[http_request]]) )  return_annotation.matches​ This is similar to the previous clause, but will match when the fully-qualified name of the callable's return type matches the specified pattern. ModelQuery( name = &quot;get_return_Request_sources&quot;, find = &quot;methods&quot;, where = [ return_annotation.matches(&quot;.*Request&quot;), ], model = Returns(TaintSource[UserControlled, Via[http_request]]) )  return_annotation.is_annotated_type​ This will match when a callable's return type is annotated withtyping.Annotated. This is a type used to decorate existing types with context-specific metadata, e.g. from typing import Annotated def bad() -&gt; Annotated[str, &quot;SQL&quot;]: ...  Example: ModelQuery( name = &quot;get_return_annotated_sources&quot;, find = functions, where = [ return_annotation.is_annotated_type(), ], model = Returns(TaintSource[SQL]) )  This query would match on functions like the one shown above. return_annotation.extends​ This will match when a callable's return type is a class that is a subclass of the provided class names. Note that this will only work on class names. More complex types like Union, Callable are not supported. The extends clause also takes boolean parameters is_transitive, which when set to true means it will match when the class is a transitive subclass, otherwise it will only match when it is a direct subclass, and includes_self, which determines whetherextends(T) should include T itself. Example: ModelQuery( name = &quot;get_return_annotation_extends&quot;, find = functions, where = [ return_annotation.extends(&quot;test.A&quot;, is_transitive=True, includes_self=True), ], model = Returns(TaintSource[Test]) )  Given the following Python code in module test: class A: pass class B(A): pass class C: pass def foo() -&gt; A: ... def bar() -&gt; B: ... def baz() -&gt; C: ...  The above query would match bar and baz which are transitive subclasses ofA, but not foo, since includes_self was False. If the return type is Optional[T], or ReadOnly[T], they will be effectively treated as if they were type T for the purpose of matching. from typing import Optional from pyre_extensions import ReadOnly # These should all also match def bar_optional() -&gt; Optional[B]: ... def bar_readonly() -&gt; ReadOnly[B]: ... def baz2() -&gt; Optional[ReadOnly[Optional[C]]]: ...  ","version":"Next","tagName":"h3"},{"title":"type_annotation clauses​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#type_annotation-clauses","content":"Model queries allow for querying based on the type annotation of a global. Note that this is similar to thereturn_annotation clauses shown previously. See also: Parameters model type_annotation clauses. type_annotation.equals​ The clause will match when the fully-qualified name of the global's explicitly annotated type matches the specified value exactly. ModelQuery( name = &quot;get_string_dicts&quot;, find = &quot;globals&quot;, where = [ type_annotation.equals(&quot;typing.Dict[(str, str)]&quot;), ], model = GlobalModel(TaintSource[SelectDict]) )  For example, the above query when run on the following code: unannotated_dict = {&quot;hello&quot;: &quot;world&quot;, &quot;abc&quot;: &quot;123&quot;} annotated_dict: Dict[str, str] = {&quot;hello&quot;: &quot;world&quot;, &quot;abc&quot;: &quot;123&quot;}  will result in a model for annotated_dict: TaintSource[SelectDict]. type_annotation.matches​ This is similar to the previous clause, but will match when the fully-qualified name of the global's explicit type annotation matches the specified pattern. ModelQuery( name = &quot;get_anys&quot;, find = &quot;globals&quot;, where = [ return_annotation.matches(&quot;.*typing.Any.*&quot;), ], model = GlobalModel(TaintSource[SelectAny]) )  type_annotation.is_annotated_type​ This will match when a global's type is annotated withtyping.Annotated. This is a type used to decorate existing types with context-specific metadata, e.g. from typing import Annotated result: Annotated[str, &quot;SQL&quot;] = ...  Example: ModelQuery( name = &quot;get_return_annotated_sources&quot;, find = globals, where = [ return_annotation.is_annotated_type(), ], model = GlobalModel(TaintSource[SQL]) )  This query would match on functions like the one shown above. type_annotation.extends​ This behaves the same way as the return_annotation.extends() clause. Please refer to the section above. ","version":"Next","tagName":"h3"},{"title":"any_parameter clauses​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#any_parameter-clauses","content":"Model queries allow matching callables where any parameter matches a given clause. For now, the only clauses we support for parameters is specifying conditions on the type annotation of a callable's parameters. These can be used in conjunction with the Parameters model clause (seetype_annotation) to taint specific parameters. Note that this where clause does not work when the find clause specifies&quot;attributes&quot;. any_parameter.annotation.equals​ This clause will match all callables which have at least one parameter where the fully-qualified name of the parameter type matches the specified value exactly. Example: ModelQuery( name = &quot;get_parameter_HttpRequest_sources&quot;, find = &quot;functions&quot;, where = [ any_parameter.annotation.equals(&quot;django.http.HttpRequest&quot;) ], model = Parameters( TaintSource[UserControlled], where=[ name.equals(&quot;request&quot;), name.matches(&quot;data$&quot;) ] ) )  any_parameter.annotation.matches​ This clause will match all callables which have at least one parameter where the fully-qualified name of the parameter type matches the specified pattern. Example: ModelQuery( name = &quot;get_parameter_Request_sources&quot;, find = &quot;methods&quot;, where = [ any_parameter.annotation.matches(&quot;.*Request&quot;) ], model = Parameters( TaintSource[UserControlled], where=[ type_annotation.matches(&quot;.*Request&quot;), ] ) )  any_parameter.annotation.is_annotated_type​ This clause will match all callables which have at least one parameter with typetyping.Annotated. Example: ModelQuery( name = &quot;get_parameter_annotated_sources&quot;, find = &quot;functions&quot;, where = [ any_parameter.annotation.is_annotated_type() ], model = Parameters( TaintSource[Test], where=[ type_annotation.is_annotated_type(), ] ) )  ","version":"Next","tagName":"h3"},{"title":"AnyOf clauses​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#anyof-clauses","content":"There are cases when we want to model entities which match any of a set of clauses. The AnyOf clause represents exactly this case. Example: ModelQuery( name = &quot;get_AnyOf_example&quot;, find = &quot;methods&quot;, where = [ AnyOf( any_parameter.annotation.is_annotated_type(), return_annotation.is_annotated_type(), ) ], model = ... )  ","version":"Next","tagName":"h3"},{"title":"AllOf clauses​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#allof-clauses","content":"There are cases when we want to model entities which match all of a set of clauses. The AllOf clause may be used in this case. Example: ModelQuery( name = &quot;get_AllOf_example&quot;, find = &quot;methods&quot;, where = [ AnyOf( AllOf( cls.extends(&quot;a.b&quot;), cls.name.matches(&quot;Foo&quot;), ), AllOf( cls.extends(&quot;c.d&quot;), cls.name.matches(&quot;Bar&quot;) ) ) ], model = ... )  ","version":"Next","tagName":"h3"},{"title":"Decorator clauses​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#decorator-clauses","content":"Decorator clauses are used to find callables decorated with decorators that match a pattern. This clause takes decorator clauses as arguments. Decorator fully_qualified_callee clauses​ The fully_qualified_callee decorator clause is used to match on the fully qualified name of a decorator. That is, the fully qualified name of a higher order function. The supported name clauses are the same as the ones discussed above for model query constraints, i.e., fully_qualified_callee.matches(&quot;pattern&quot;), which will match when the decorator matches the regex pattern specified as a string, andfully_qualified_callee.equals(&quot;foo.bar.d1&quot;), which will match when the fully-qualified name of the decorator equals the specified string exactly. For example, if you wanted to find all functions that are decorated by@App().route(), a decorator whose definition is in file my_module.py: class App: def route(self, func: Callable) -&gt; Callable: ...  You can write: ModelQuery( name = &quot;get_my_module_app_route_decorator&quot;, find = &quot;functions&quot;, where = Decorator(fully_qualified_callee.equals(&quot;my_module.App.route&quot;)), ... )  which is arguably better because it is more precise than regex matching, or ModelQuery( name = &quot;get_app_route_decorator&quot;, find = &quot;functions&quot;, where = Decorator(fully_qualified_callee.matches(&quot;.*\\.App\\.route&quot;)), ... )  Clarification. As another example, assume the following code is in filetest.py: class Flask: def route(self, func: Callable) -&gt; Callable: ... application = Flask() @application.route def my_view(): pass  Then, for decorator @application.route, clause fully_qualified_calleematches against the decorator's fully qualified name test.Flask.route, as oppposed to the local identifier's fully qualified name test.application.route(that refers to this decorator). Decorator name clauses​ The name clause is similar to fully_qualified_name, but matches against the actual name of the entity, excluding module and class names. Decorator arguments clauses​ The arguments clauses is used to match on the arguments provided to the decorator. The supported arguments clauses are arguments.contains(...), which will match when the arguments specified are a subset of the decorator's arguments, and arguments.equals(...), which will match when the decorator has the specified arguments exactly. arguments.contains() supports both positional and keyword arguments. For positional arguments, the list of positonal arguments supplied to thearguments.contains() clause must be a prefix of the list of positional arguments on the actual decorator, i.e. the value of the argument at each position should be the same. For example, with the following Python code: @d1(a, 2) def match1(): ... @d1(a, 2, 3, 4) def match2(): ... @d1(2, a): def nomatch(): ...  This query will match both match1() and match2(), but not nomatch(), since the values of the positional arguments don't match up. ModelQuery( name = &quot;get_d1_decorator&quot;, find = &quot;functions&quot;, where = Decorator( fully_qualified_name.matches(&quot;d1&quot;), arguments.contains(a, 2) ), ... )  For keyword arguments in arguments.contains(), the specified keyword arguments must be a subset of the decorator's keyword arguments, but can be specified in any order. For example, with the following Python code: @d1(a, 2, foo=&quot;Bar&quot;) def match1(): ... @d1(baz=&quot;Boo&quot;, foo=&quot;Bar&quot;) def match2(): ...  This query will match both match1() and match2(): ModelQuery( name = &quot;get_d1_decorator&quot;, find = &quot;functions&quot;, where = Decorator( fully_qualified_name.matches(&quot;d1&quot;), arguments.contains(foo=&quot;Bar&quot;) ), ... )  arguments.equals() operates similarly, but will only match if the specified arguments match the decorator's arguments exactly. This means that for positional arguments, all arguments in each position must match by value exactly. Keyword arguments can be specified in a different order, but the set of specified keyword arguments and the set of the decorator's actual keyword arguments must be the same. For example, with the following Python code: @d1(a, 2, foo=&quot;Bar&quot;, baz=&quot;Boo&quot;) def match1(): ... @d1(a, 2, baz=&quot;Boo&quot;, foo=&quot;Bar&quot;) def match2(): ... @d1(2, a, baz=&quot;Boo&quot;, foo=&quot;Bar&quot;) def nomatch1(): ... @d1(a, 2, 3, baz=&quot;Boo&quot;, foo=&quot;Bar&quot;) def nomatch2(): ...  This query will match both match1() and match2(), but not nomatch1() ornomatch2(): ModelQuery( name = &quot;get_d1_decorator&quot;, find = &quot;functions&quot;, where = Decorator( fully_qualified_name.matches(&quot;d1&quot;), arguments.equals(a, 2, foo=&quot;bar&quot;, baz=&quot;Boo&quot;) ), ... )  Decorator Not, AllOf and AnyOf clauses​ The Not, AllOf and AnyOf clauses can be used in decorators clauses in the same way as they are in the main where clause of the model query. ","version":"Next","tagName":"h3"},{"title":"cls.fully_qualified_name.equals clause​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#clsfully_qualified_nameequals-clause","content":"You may use the cls clause to specify predicates on the class. This predicate can only be used when the find clause specifies methods or attributes. The cls.fully_qualified_name.equals clause is used to model entities when the class's fully qualified name is an exact match for the specified string. Example: ModelQuery( name = &quot;get_childOf_foo_Bar&quot;, find = &quot;methods&quot;, where = cls.name.equals(&quot;foo.Bar&quot;), ... )  ","version":"Next","tagName":"h3"},{"title":"cls.fully_qualified_name.matches clause​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#clsfully_qualified_namematches-clause","content":"The cls.fully_qualified_name.matches clause is used to model entities when the class's fully qualified name matches the provided regex. Example: ModelQuery( name = &quot;get_childOf_Foo&quot;, find = &quot;methods&quot;, where = cls.fully_qualified_name.matches(&quot;.*Foo.*&quot;), ... )  ","version":"Next","tagName":"h3"},{"title":"cls.name.matches clause​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#clsnamematches-clause","content":"The cls.name.matches clause is similar to cls.fully_qualified_name.matches, but matches against the actual name of the class, excluding modules. ","version":"Next","tagName":"h3"},{"title":"cls.name.equals clause​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#clsnameequals-clause","content":"The cls.name.equals clause is similar to cls.fully_qualified_name.equals, but matches against the actual name of the class, excluding modules. ","version":"Next","tagName":"h3"},{"title":"cls.extends clause​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#clsextends-clause","content":"The cls.extends clause is used to model entities when the class is a subclass of the provided class name. Example: ModelQuery( name = &quot;get_subclassOf_C&quot;, find = &quot;attributes&quot;, where = cls.extends(&quot;C&quot;), ... )  The default behavior is that it will only match if the class is an instance of, or a direct subclass of the specified class. For example, with classes: class C: x = ... class D(C): y = ... class E(D): z = ...  the above query will only model the attributes C.z and D.y, since C is considered to extend itself, and D is a direct subclass of C. However, it will not model E.z, since E is a sub-subclass of C. If you would like to model a class and all subclasses transitively, you can use the is_transitive flag. Example: ModelQuery( name = &quot;get_transitive_subclassOf_C&quot;, find = &quot;attributes&quot;, where = cls.extends(&quot;C&quot;, is_transitive=True), ... )  This query will model C.x, D.y and E.z. If you do not want to match on the class itself, you can use the includes_selfflag. Example: ModelQuery( name = &quot;get_transitive_subclassOf_C&quot;, find = &quot;attributes&quot;, where = cls.extends(&quot;C&quot;, is_transitive=True, includes_self=False), ... )  This query will model D.y and E.z. ","version":"Next","tagName":"h3"},{"title":"cls.decorator clause​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#clsdecorator-clause","content":"The cls.decorator clause is used to specify constraints on a class decorator, so you can choose to model entities on classes only if the class it is part of has the specified decorator. The arguments for this clause are identical to the non-class constraintDecorator, for more information, please see theDecorator clauses section. Example: ModelQuery( name = &quot;get_childOf_d1_decorator_sources&quot;, find = &quot;methods&quot;, where = [ cls.decorator( fully_qualified_name.matches(&quot;d1&quot;), arguments.contains(2) ), name.equals(&quot;__init__&quot;) ], model = [ Parameters(TaintSource[Test], where=[ Not(name.equals(&quot;self&quot;)), Not(name.equals(&quot;a&quot;)) ]) ] )  For example, the above query when run on the following code: @d1(2) class Foo: def __init__(self, a, b): ... @d1() class Bar: def __init__(self, a, b): ... @d2(2) class Baz: def __init__(self, a, b): ...  will result in a model for def Foo.__init__(b: TaintSource[Test]). ","version":"Next","tagName":"h3"},{"title":"cls.any_child clause​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#clsany_child-clause","content":"The cls.any_child clause is used to model entities when any child of the current class meets the specified constraints. The arguments for this clause are any combination of valid class constraints (cls.name.equals, cls.name.matches, cls.fully_qualified_name.equals,cls.fully_qualified_name.matches, cls.extends, cls.decorator) and logical clauses (AnyOf, AllOf, Not), along with the optional is_transitive andincludes_self clauses. Example: ModelQuery( name = &quot;get_parent_of_d1_decorator_sources&quot;, find = &quot;methods&quot;, where = [ cls.any_child( cls.decorator( fully_qualified_name.matches(&quot;d1&quot;), arguments.contains(2) ) ), name.equals(&quot;__init__&quot;) ], model = [ Parameters(TaintSource[Test], where=[ Not(name.equals(&quot;self&quot;)), Not(name.equals(&quot;a&quot;)) ]) ] )  Similar to the cls.extends constraint, the default behavior is that it will only match if any immediate children (or itself) of the class of the method or attribute matches against the inner clause. For example, with classes: class Foo: def __init__(self, a, b): ... class Bar(Foo): def __init__(self, a, b): ... @d1(2) class Baz(Bar): def __init__(self, a, b): ...  The above query will only model the methods Bar.__init__ and Baz.__init__, since Bar is an immediate parent of Baz, and Baz is considered to extend itself. However, it will not model Foo.__init__, since Bar is a sub-subclass of Foo. If you would like to model a class and all subclasses transitively, you can use the is_transitive flag. Example: ModelQuery( name = &quot;get_transitive_parent_of_d1_decorator_sources&quot;, find = &quot;attributes&quot;, where = [ cls.any_child( cls.decorator( fully_qualified_name.matches(&quot;d1&quot;), arguments.contains(2) ), is_transitive=True ), name.equals(&quot;__init__&quot;) ], ... )  This query will model Foo.__init__, Bar.__init__ and Baz.__init__. If you would like to model all subclasses of a class excluding itself, you can use the includes_self flag. Example: ModelQuery( name = &quot;get_transitive_parent_of_d1_decorator_sources&quot;, find = &quot;attributes&quot;, where = [ cls.any_child( cls.decorator( fully_qualified_name.matches(&quot;d1&quot;), arguments.contains(2) ), is_transitive=True, includes_self=False ), name.equals(&quot;__init__&quot;) ], ... )  This query will model Foo.__init__, Bar.__init__ but NOT Baz.__init__. tip We recommend to always specify both is_transitive and includes_self to avoid confusion. ","version":"Next","tagName":"h3"},{"title":"cls.any_parent clause​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#clsany_parent-clause","content":"The cls.any_parent clause is used to model entities when any parent of the current class meets the specified constraints. The arguments for this clause are any combination of valid class constraints (cls.name.equals, cls.name.matches, cls.fully_qualified_name.equals,cls.fully_qualified_name.matches, cls.extends, cls.decorator) and logical clauses (AnyOf, AllOf, Not), along with the optional is_transitive andincludes_self clauses. Example: ModelQuery( name = &quot;get_children_of_d1_decorator_sources&quot;, find = &quot;methods&quot;, where = [ cls.any_parent( cls.decorator( fully_qualified_name.matches(&quot;d1&quot;), arguments.contains(2) ) ), name.equals(&quot;__init__&quot;) ], model = [ Parameters(TaintSource[Test], where=[ Not(name.equals(&quot;self&quot;)), Not(name.equals(&quot;a&quot;)) ]) ] )  Similar to the cls.extends constraint, the default behavior is that it will only match if any immediate parent (or itself) of the class of the method or attribute matches against the inner clause. For example, with classes: @d1(2) class Foo: def __init__(self, a, b): ... class Bar(Foo): def __init__(self, a, b): ... class Baz(Bar): def __init__(self, a, b): ...  The above query will only model the methods Bar.__init__ and Foo.__init__, since Foo is an immediate parent of Bar, and Foo is considered to extend itself. However, it will not model Baz.__init__, since Foo is not an immediate parent of Baz. If you would like to model a class and all transitive parents, you can use theis_transitive flag. Example: ModelQuery( name = &quot;get_transitive_children_of_d1_decorator_sources&quot;, find = &quot;attributes&quot;, where = [ cls.any_parent( cls.decorator( fully_qualified_name.matches(&quot;d1&quot;), arguments.contains(2) ), is_transitive=True ), name.equals(&quot;__init__&quot;) ], ... )  This query will model Foo.__init__, Bar.__init__ and Baz.__init__. If you would like to model all parents of a class excluding itself, you can use the includes_self flag. Example: ModelQuery( name = &quot;get_transitive_parent_of_d1_decorator_sources&quot;, find = &quot;attributes&quot;, where = [ cls.any_parent( cls.decorator( fully_qualified_name.matches(&quot;d1&quot;), arguments.contains(2) ), is_transitive=True, includes_self=False ), name.equals(&quot;__init__&quot;) ], ... )  This query will model Bar.__init__, Baz.__init__ but NOT Foo.__init__. tip We recommend to always specify both is_transitive and includes_self to avoid confusion. ","version":"Next","tagName":"h3"},{"title":"Not clauses​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#not-clauses","content":"The Not clause negates any existing clause that is valid for the entity being modelled. Example: ModelQuery( name = &quot;get_Not_example&quot;, find = &quot;methods&quot;, where = [ Not( name.matches(&quot;foo.*&quot;), cls.fully_qualified_name.matches(&quot;testing.unittest.UnitTest&quot;), ) ], model = ... )  ","version":"Next","tagName":"h3"},{"title":"Generated models (Model clauses)​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#generated-models-model-clauses","content":"The last bit of model queries is actually generating models for all entities that match the provided where clauses. For callables, we support generating models for parameters by name or position, as well as generating models for all paramaters. Additionally, we support generating models for the return annotation. ","version":"Next","tagName":"h2"},{"title":"Returned taint​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#returned-taint","content":"Returned taint takes the form of Returns(TaintSpecification), whereTaintSpecification is either a taint annotation or a list of taint annotations. ModelQuery( name = &quot;get_Returns_sources&quot;, find = &quot;methods&quot;, where = ..., model = [ Returns(TaintSource[Test, Via[foo]]) ] )  ","version":"Next","tagName":"h3"},{"title":"Parameter taint​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#parameter-taint","content":"Parameters can be tainted using the Parameters() clause. By default, all parameters will be tained with the supplied taint specification. If you would like to only taint specific parameters matching certain conditions, an optionalwhere clause can be specified to accomplish this, allowing for constraints on parameter names, the annotation type of the parameter, or parameter position. For example: ModelQuery( name = &quot;get_Parameters_sources&quot;, find = &quot;methods&quot;, where = ..., model = [ Parameters(TaintSource[A]), # will taint all parameters by default Parameters( TaintSource[B], where=[ Not(index.equals(0)) # will only taint parameters that are not the first parameter ] ), ] )  name clauses​ To specify a constraint on parameter name, the name.equals() orname.matches() clauses can be used. As in the main where clause of the model query, equals() searches for an exact match on the specified string, whilematches() allows a regex to be supplied as a pattern to match against. Example: ModelQuery( name = &quot;get_request_data_sources&quot;, find = &quot;methods&quot;, where = ..., model = [ Parameters( TaintSource[Test], where=[ name.equals(&quot;request&quot;), name.matches(&quot;data$&quot;) ] ) ] )  index clause​ To specify a constraint on parameter position, the index.equals() clause can be used. It takes a single integer denoting the position of the parameter. Example: ModelQuery( name = &quot;get_index_sources&quot;, find = &quot;methods&quot;, where = ..., model = [ Parameters( TaintSource[Test], where=[ index.equals(1) ] ) ] )  has_position clause​ To match on parameters that have a position, the has_position() clause can be used. This is mostly used to exclude keyword-only parameters, *args and**kwargs. Example: ModelQuery( name = &quot;get_index_sources&quot;, find = &quot;methods&quot;, where = ..., model = [ Parameters( TaintSource[Test], where=[ has_position() ] ) ] )  has_name clause​ To match on parameters that have a name, the has_name() clause can be used. This is mostly used to exclude *args and **kwargs. Example: ModelQuery( name = &quot;get_index_sources&quot;, find = &quot;methods&quot;, where = ..., model = [ Parameters( TaintSource[Test], where=[ has_name() ] ) ] )  type_annotation clause​ This clause is used to specify a constraint on parameter type annotation. Currently the clauses supported are: type_annotation.equals(), which takes the fully-qualified name of a Python type or class and matches when there is an exact match, type_annotation.matches(), which takes a regex pattern to match type annotations against, and type_annotation.is_annotated_type(), which will match parameters of typetyping.Annotated. Example: ModelQuery( name = &quot;get_annotated_parameters_sources&quot;, find = &quot;methods&quot;, where = ..., model = [ Parameters( TaintSource[Test], where=[ type_annotation.equals(&quot;foo.bar.C&quot;), # exact match type_annotation.matches(&quot;^List\\[&quot;), # regex match type_annotation.is_annotated_type(), # matches Annotated[T, x] ] ) ] )  To match on the annotation portion of Annotated types, consider the following example. Suppose this code was in test.py: from enum import Enum from typing import Annotated, Option class Color(Enum): RED = 1 GREEN = 2 BLUE = 3 class Foo: x: Annotated[Optional[int], Color.RED] y: Annotated[Optional[int], Color.BLUE] z: Annotated[int, &quot;z&quot;]  Note that the type name that should be matched against is its fully qualified name, which also includes the fully qualified name of any other types referenced (for example, typing.Optional rather than just Optional). When multiple arguments are provided to the type they are implicitly treated as being in a tuple. Here are some examples of where clauses that can be used to specify models for the annotated attributes in this case: ModelQuery( name = &quot;get_annotated_attributes_sources&quot;, find = &quot;attributes&quot;, where = [ AnyOf( type_annotation.equals(&quot;typing.Annotated[(typing.Optional[int], test.Color.RED)]&quot;), type_annotation.equals(&quot;typing.Annotated[(int, z)]&quot;), type_annotation.matches(&quot;.*Annotated\\[.*Optional[int].*Color\\..*\\]&quot;) type_annotation.is_annotated_type() ) ], model = [ AttributeModel(TaintSource[Test]), ] )  This query should generate the following models: test.Foo.x: TaintSource[Test] test.Foo.y: TaintSource[Test] test.Foo.z: TaintSource[Test]  Not, AllOf and AnyOf clauses​ The Not, AllOf and AnyOf clauses can be used in the same way as they are in the main where clause of the model query. Not can be used to negate any existing clause, AllOf to match when all of several supplied clauses match, and AnyOf can be used to match when any one of several supplied clauses match. Example: ModelQuery( name = &quot;get_Not_AnyOf_AllOf_example_sources&quot;, find = &quot;methods&quot;, where = ..., model = [ Parameters( TaintSource[Test], where=[ Not( AnyOf( AllOf( cls.extends(&quot;a.b&quot;), cls.name.matches(&quot;Foo&quot;), ), AllOf( cls.extends(&quot;c.d&quot;), cls.name.matches(&quot;Bar&quot;) ) ) ) ] ) ] )  Using ViaTypeOf with the Parameters clause​ Usually when specifying a ViaTypeOf the argument that you want to capture the value or type of should be specified. However, when writing model queries and trying to find all parameters that match certain conditions, we may not know the exact name of the parameters that will be modelled. For example: def f1(bad_1, good_1, good_2): pass def f2(good_3, bad_2, good_4): pass  Suppose we wanted to model all parameters with the prefix bad_ here and attach a ViaTypeOf to them. In this case it is still possible to attach these features to the parameter model, by using a standalone ViaTypeOf as follows: ModelQuery( name = &quot;get_f_sinks&quot;, find = &quot;functions&quot;, where = name.matches(&quot;f&quot;), model = [ Parameters( TaintSink[Test, ViaTypeOf], where=[ name.matches(&quot;bad_&quot;) ] ) ] )  This would produce models equivalent to the following: def f1(bad_1: TaintSink[Test, ViaTypeOf[bad_1]]): ... def f2(bad_2: TaintSink[Test, ViaTypeOf[bad_2]]): ...  ","version":"Next","tagName":"h3"},{"title":"Models for attributes​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#models-for-attributes","content":"Taint for attribute models requires a AttributeModel model clause, which can only be used when the find clause specifies attributes. Example: ModelQuery( name = &quot;get_attribute_sources_sinks&quot;, find = &quot;attributes&quot;, where = ..., model = [ AttributeModel(TaintSource[Test], TaintSink[Test]) ] )  Using ViaAttributeName with the AttributeModel clause​ ViaAttributeName can be used within AttributeModel to add a feature containing the name of the attribute to any taint flowing through the given attributes. For instance: ModelQuery( name = &quot;get_attribute_of_Foo&quot;, find = &quot;attributes&quot;, where = [cls.name.equals(&quot;Foo&quot;)], model = [ AttributeModel(ViaAttributeName[WithTag[&quot;Foo&quot;]]) ] )  On the following code: class Foo: first_name: str last_name: str def last_name_to_sink(foo: Foo): sink(foo.last_name)  This will add the feature via-Foo-attribute:last_name on the flow to the sink. ","version":"Next","tagName":"h3"},{"title":"Models for globals​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#models-for-globals","content":"Taint for global models requires a GlobalModel model clause, which can only be used when the find clause specifies globals. Example: ModelQuery( name = &quot;get_global_sources&quot;, find = &quot;globals&quot;, where = ..., model = [ GlobalModel(TaintSource[Test]) ] )  ","version":"Next","tagName":"h3"},{"title":"Models for setting modes​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#models-for-setting-modes","content":"This model clause is different from the others in this section in the sense that it doesn't produce taint for the models it targets, but updates their models with specific modes to change their behavior with taint analysis. The available modes are: Obscure Marks the function or method as obscure SkipObscure Prevents a function or method from being marked as obscure SkipAnalysis Skips inference of the function or model targeted, and forces the use of user-defined models for taint flow SkipOverrides Prevents taint propagation from the targeted model into and from overridden methods on subclasses Entrypoint Specifies functions or methods to be used as entrypoints for analysis, so only transitive calls from that function are analyzed SkipDecoratorWhenInlining Prevents the selected decorator from being inlined during analysisNote: this mode will be a no-op, since model queries are generated after decorators are inlined SkipModelBroadening Prevents model broadening for the given function or method For instance, instead of annotating each function separately, as in the following .pysa file: @Entrypoint def myfile.func1(): ... @Entrypoint def myfile.func2(): ... @Entrypoint def myfile.func3(): ... @Entrypoint def myfile.func4(): ...  One could instead use the following model query: ModelQuery( name = &quot;get_myfile_entrypoint_functions&quot;, find = &quot;functions&quot;, where = [ name.matches(&quot;myfile\\.func.*&quot;) ], model = [ Modes([Entrypoint]) ] )  The benefit is that any new functions that matches that name will also be considered entrypoints. Note that it is also possible to include multiple modes in a Modes model clause by extending the list (e.g Modes([SkipOverrides, Obscure]). ","version":"Next","tagName":"h3"},{"title":"Expected and Unexpected Models clauses​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#expected-and-unexpected-models-clauses","content":"The optional expected_models and unexpected_models clauses allow you to specify models that your ModelQuery should or should not generate the equivalent of. The models in these clauses should be syntactically correct Pysa models (seethis documentationfor a guide on how to write a Pysa model). If your query does not generate a model in expected_models, or if it generates a model in unexpected_models, an error will be raised. Example: ModelQuery( name = &quot;get_foo_returns_sources&quot;, find = &quot;functions&quot;, where = [name.matches(&quot;foo&quot;)], model = [ Returns(TaintSource[Test]), ], expected_models = [ &quot;def file.foo() -&gt; TaintSource[Test]: ...&quot;, &quot;def file.foo2() -&gt; TaintSource[Test]: ...&quot; ], unexpected_models = [ &quot;def file.bar() -&gt; TaintSource[Test]: ...&quot; ] )  This would not produce any errors, since the models the ModelQuery generates will contain expected_models and not unexpected_models. ","version":"Next","tagName":"h2"},{"title":"Cache Queries​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#cache-queries","content":"Generating models for a large number of queries can be quite slow. Cache queries allow to speed up model generation by factoring out queries with similar whereclause into a single query, which builds a mapping from an arbitrary name to a set of matching entities. Then, other queries can read from this cache, making them quick to execute. For instance, imagine having the following queries: ModelQuery( ... find = &quot;methods&quot;, where = [ AnyOf(cls.extends(&quot;my_module.Foo&quot;), cls.extends(&quot;other_module.Bar&quot;)), fully_qualified_name.matches(&quot;\\.ClassA\\.method$&quot;), ], model = ... ) ModelQuery( ... find = &quot;methods&quot;, where = [ AnyOf(cls.extends(&quot;my_module.Foo&quot;), cls.extends(&quot;other_module.Bar&quot;)), fully_qualified_name.matches(&quot;\\.ClassB\\.method$&quot;), ], model = ... ) ModelQuery( ... find = &quot;methods&quot;, where = [ AnyOf(cls.extends(&quot;my_module.Foo&quot;), cls.extends(&quot;other_module.Bar&quot;)), fully_qualified_name.matches(&quot;\\.ClassC\\.other_method$&quot;), ], model = ... ) # etc.  We can factor out the expensive where clause into a single query which writes to a key-value cache, using the WriteToCache clause. ModelQuery( ... find = &quot;methods&quot;, where = [AnyOf(cls.extends(&quot;my_module.Foo&quot;), cls.extends(&quot;other_module.Bar&quot;))], model = WriteToCache(kind=&quot;FooBar&quot;, name=f&quot;{class_name}:{function_name}&quot;) )  All matching methods will be stored in a cache named FooBar, under the key{class_name}:{function_name}. After executing the query, we might get the following cache FooBar: ClassA:method -&gt; {some_module.ClassA.method} ClassB:method -&gt; {some_other_module.ClassB.method} ClassC:other_method -&gt; {some_module.ClassC.other_method}  We can then read from the cache using the where clause read_from_cache: ModelQuery( find = &quot;methods&quot;, where = read_from_cache(kind=&quot;FooBar&quot;, name=&quot;ClassA:method&quot;, model = ... ) ModelQuery( find = &quot;methods&quot;, where = read_from_cache(kind=&quot;FooBar&quot;, name=&quot;ClassB:method&quot;, model = ... ) ModelQuery( find = &quot;methods&quot;, where = read_from_cache(kind=&quot;FooBar&quot;, name=&quot;ClassC:other_method&quot;, model = ... )  This will generate the same models as the first example, but model generation will be a lot faster. In terms of time complexity, if the number of entities (methods here) is N, the number of queries is Q and the average cost of evaluating a where clause is C, the first example would have a O(N*Q*C) complexity. Using cache queries, this turns into O(N*C+Q), which is much better. ","version":"Next","tagName":"h2"},{"title":"WriteToCache clause​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#writetocache-clause","content":"WriteToCache is a model clause that is used to store entities into a cache. It takes the following arguments: A kind, which is the name of the cache.A name as a format string, which will be the key for the entity in the cache. For instance: ModelQuery( ... find = &quot;methods&quot;, model = WriteToCache(kind=&quot;cache_name&quot;, name=f&quot;{class_name}:{function_name}&quot;) )  Note that you can write multiple entities under the same name. For instance, this happens if you use name=f&quot;{class_name}&quot; and multiple methods of the same class match against the where clause. ","version":"Next","tagName":"h3"},{"title":"read_from_cache clause​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#read_from_cache-clause","content":"read_from_cache is a where clause that will only match against entities with the given name in the cache. It takes the following arguments: A kind, which is the name of the cache.A name as a string, which is the key for the entities in the cache. For instance: ModelQuery( find = &quot;methods&quot;, where = read_from_cache(kind=&quot;cache_name&quot;, name=&quot;Class:method&quot;), model = ... )  Note that you can use read_from_cache in combination with other where clauses, as long as at least one read_from_cache clause is active on all branches. For instance, this is disallowed: ModelQuery( find = &quot;methods&quot;, where = AnyOf( read_from_cache(kind=&quot;cache_name&quot;, name=&quot;Class:method&quot;), cls.extends(&quot;module.Foo&quot;) ), model = ... )  ","version":"Next","tagName":"h3"},{"title":"Format strings​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#format-strings","content":"Format strings can be used to craft a string using information from the matched entity. They can be used in the WriteToCache name argument as well as theCrossRepositoryTaintAnchor canonical name and port arguments. For instance: WriteToCache(kind=&quot;cache_name&quot;, name=f&quot;{class_name}:{function_name}&quot;)CrossRepositoryTaintAnchor[TaintSink[Thrift], f&quot;{class_name}:{function_mame}&quot;, f&quot;formal({parameter_position + 1})&quot;] The following variables can be used: function_name: The (non-qualified) name of the function;method_name: The (non-qualified) name of the method;class_name: The (non-qualified) name of the class;parameter_name: The parameter name, when used within the Parametersclause;parameter_position: The parameter position, when used within theParameters clause. This will give -1 for keyword only parameters;capture(identifier): The regular expression capture group calledidentifier. See documentation below. Math operators such as +, - and * can be used on parameter_position and integer literals, such as f&quot;{parameter_position * 2 + 1}&quot;. ","version":"Next","tagName":"h2"},{"title":"Regular expression capture​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#regular-expression-capture","content":"name.matches and cls.name.matches clause can use named capturing groups, which can be used in the name of WriteToCache clauses. For instance: ModelQuery( find = &quot;functions&quot;, where = name.matches(&quot;^get_(?P&lt;attribute&gt;[a-z]+)$&quot;), model = WriteToCache(kind=&quot;cache_name&quot;, name=f&quot;{capture(attribute)}&quot;) )  For a function get_foo, this will create a cache for key foo. caution Be careful when using regular expression captures. If the capture group is not found (e.g, a typo), WriteToCache will use the empty string. Note that we do not support numbered capture groups, e.g Foo(.*). ","version":"Next","tagName":"h3"},{"title":"Logging group clauses​","type":1,"pageTitle":"Model Domain Specific Language (DSL)","url":"/docs/pysa-model-dsl/#logging-group-clauses","content":"The logging_group_name clause specifies that the model query should be considered part of the given group for logging purposes. This is useful when auto generating large amounts of model queries. When verbose logging is enabled (-n), Pysa will print a single lineModel Query group 'XXX' generated YYY models instead of printing one line per model query in the group. For instance: ModelQuery( name = &quot;generated_dangerous_foo&quot;, logging_group_name = &quot;generated_dangerous&quot;, find = &quot;methods&quot;, where = read_from_cache(kind=&quot;annotated&quot;, name=&quot;foo&quot;), model = ... ) ModelQuery( name = &quot;generated_dangerous_bar&quot;, logging_group_name = &quot;generated_dangerous&quot;, find = &quot;methods&quot;, where = read_from_cache(kind=&quot;annotated&quot;, name=&quot;bar&quot;), model = ... )  ","version":"Next","tagName":"h2"},{"title":"Type Errors","type":0,"sectionRef":"#","url":"/docs/errors/","content":"","keywords":"","version":"Next"},{"title":"Common Issues​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#common-issues","content":"","version":"Next","tagName":"h2"},{"title":"Covariance and Contravariance​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#covariance-and-contravariance","content":"Variance is tricky and a common source of confusion for people new to Python's type system. Pyre will error when, for instance, a List[int] is passed in when a List[float] is expected, as in the following example: def to_seconds(milliseconds: List[float]) -&gt; List[int]: return [int(x/1000.0) for x in milliseconds] my_list: List[int] = [1] my_list = to_seconds(my_list) # Pyre errors here!  $ pyre Unbound name [10]: Name `List` is used but not defined in the current scope.  This code works perfectly fine at runtime, and we may think that since int is a subtype of float this should not be a problem for the type checker either. However, consider the following code: def halve_first_element(list: List[float]) -&gt; None: list[0] /= 2 def function_taking_int(int: int) -&gt; None: return None my_list: List[int] = [1] halve_first_element(my_list) function_taking_int(my_list[0]) # Oh no, my_list[0] is 0.5!  $ pyre Incompatible parameter type [6]: In call `list.__setitem__`, for 2nd positional argument, expected `int` but got `float`.  If we allowed passing in my_list to the halve_first_element function here, the above code would type check. It's perfectly valid from the perspective of the callee to modify the list's element to be a float, as it was annotated as taking a list of floats, but because this list escapes the scope of the callee, we can't allow this in the type checker. To work around this, we can signal to the type checker that the parameter can't be modified. Here's how you can tell the type checker that you won't change the container in your function: from typing import * # I can't modify milliseconds here, so it's safe to pass a Iterable[int]. def to_seconds(milliseconds: Iterable[float]) -&gt; List[int]: return [int(x/1000.0) for x in milliseconds] my_list: List[int] = [1] my_list = to_seconds(my_list) # Type checks!  Most commonly used generic containers have immutable variants, and I would encourage you to use them for function parameters whenever you don't need to modify a container in your function. Here are some immutable variants for commonly used containers: typing.List → typing.Sequence (if you need random access via my_list[id]) typing.List → typing.Iterable (if you're just iterating over the list in a loop and want to support sets as well) typing.Dict → typing.Mapping typing.Set → typing.AbstractSet  Invariance, combined with type inference, comes with a few gotchas. When you write an expression, Pyre infers the most precise type possible. For instance, Pyre infers the List[int] type for [1, 2], even though List[float] would be a perfectly valid type here. This can cause issues, as in the following example: def zeroes(number_of_elements: int) -&gt; List[float]: a = [0] * number_of_elements return a # Pyre errors here!  $ pyre Incompatible return type [7]: Expected `List[float]` but got `List[int]`.  What happened above is that Pyre inferred a type of List[int] for a, and invariance kicked in. You can work around this by adding an explicit annotation when declaring a: def zeroes(number_of_elements: int) -&gt; List[float]: a: List[float] = [0.0] * number_of_elements return a # Type checks!  Contravariance​ Callable, on the other hand, is contravariant in its parameter types. This means that, when checking if Callable[[A], None] is compatible with Callable[[B], None], we check if B is compatible with A, not the other way around. This is because the former should be capable of accepting any arguments accepted by the latter. For example, a function of type Callable[[Base], int] may be given an argument of type Child2. But if we passed in a function of type Callable[[Child1], int], this could fail at runtime: class Base: pass class Child1(Base): size: int = 42 # No size field. class Child2(Base): pass def print_child2_size(get_size: Callable[[Base], int]) -&gt; None: child2 = Child2() size = get_size(child2) print(size) def size_of_child1(child1: Child1) -&gt; int: return child1.size print_child2_size(size_of_child1) # BAD! # At runtime: # AttributeError: 'Child2' object has no attribute 'size'  To prevent such errors, Pyre raises a type error when violating contravariance: $ pyre Incompatible parameter type [6]: Expected `typing.Callable[[Base], int]` for 1st positional only parameter to call `print_child2_size` but got `typing.Callable(size_of_child1)[[Named(child1, Child1)], int]`.  ","version":"Next","tagName":"h3"},{"title":"Optional Attributes​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#optional-attributes","content":"A common pattern in Python is to check whether an attribute is None before accessing its value. E.g. from typing import Optional class Data: field: Optional[int] def process_field(input: int) -&gt; None: ... def process_data(data: Data) -&gt; None: if data.field is not None: # ... interleaving logic process_field(data.field)  $ pyre Incompatible parameter type [6]: expected int but got Optional[int]  The above fails to type-check because Pyre cannot guarantee that data.field remains not None if the interleaving logic between the explicit check and the later reference contains anything that may have side effects, like function calls. An interleaving call could set field back to None, since it's a non local variable and is mutable. Therefore any calls between the None check and the access will invalidate the &quot;not None&quot; refinement. If data.field is defined as a class property or if the parent class has overridden __getattr__, then all bets are off even if there are no interleaving calls. The preferred way to make this code type-check is to either move the check closer to the access, or to mark the attribute Final if it is not meant to be reassigned to, and you can guarantee to the type checker that no interleaving side effects can modify this attribute. from typing import Final, Optional class Data: # Needs to be assigned in the constructor and cannot be changed afterwards. field: Final[Optional[int]] = 1  It is always safe to refine attributes when their types are Final. Alternatively, it is also safe to assign the attribute to a local variable before accessing its value: def process_data(data: Data) -&gt; None: field = data.field if field is not None: # ... interleaving logic process_field(field)  or using Python 3.8's assignment expressions: def process_data(data: Data) -&gt; None: if (field := data.field) is not None: # ... interleaving logic process_field(field)  ","version":"Next","tagName":"h3"},{"title":"Third-Party Libraries​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#third-party-libraries","content":"Not all third-party libraries come with Python code that Pyre can analyze (e.g. Cython modules), and some libraries contain source code without annotations. This will often show up in the form of undefined attribute errors: Undefined attribute [16]: Module &lt;library&gt; has no attribute &lt;some attribute&gt;.  Since it is not always possible to annotate code, PEP 484 specifies a format for stub files with a .pyi extension. Pyre will look for stub files in typeshed, or next to your source code. You can also provide additional paths to Pyre to look for stubs (see Configuration).  ","version":"Next","tagName":"h3"},{"title":"Error Codes​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#error-codes","content":"Different errors raised by Pyre have different error codes. E.g. in (venv) $ pyre ƛ Found 1 type error! test.py:1:0 Incompatible variable type [9]: a is declared to have type `int` but is used as type `str`.  The 9 in the brackets indicates that we raised an error with code 9. ","version":"Next","tagName":"h2"},{"title":"0: Unused Ignore​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#0-unused-ignore","content":"Pyre fixmes and ignores allow you to ignore specific type errors by their code until you are able to fix them. In order to avoid outdated fixme comments in your project, Pyre will also error when a fixme is no longer needed. Removing the fixme comment will resolve the error. # pyre-fixme[7] # unused ignore def foo() -&gt; int: return 1  $ pyre Unused ignore [0]: The `pyre-ignore[7]` or `pyre-fixme[7]` comment is not suppressing type errors, please remove it.  ","version":"Next","tagName":"h3"},{"title":"2: Missing Parameter Annotation​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#2-missing-parameter-annotation","content":"If strict mode is turned on, Pyre will error when a function parameter is either annotated with a type that contains typing.Any or not annotated with any type at all (in which case Pyre will treat it as typing.Any by default). It will also error when a method parameter is not annotated, unless that parameter is the first parameter of a bound or static method (i.e. self, whose type pyre can infer). We enforce typed argument because typing.Any can hide type errors that will happen at runtime: from typing import Any def say_hello(name) -&gt; None: print(&quot;Hello &quot; + name) # This line will raise at runtime, but no type error since `say_hello`s `name` has type `Any`. say_hello(42)  You can silence this by adding a non-Any annotation to all parameters of functions and methods (other than self and cls for bound and class methods, which you may omit). ","version":"Next","tagName":"h3"},{"title":"3: Missing Return Annotation​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#3-missing-return-annotation","content":"If strict mode is turned on, Pyre will error when a function is either annotated with a return type that contains typing.Any, or is not annotated with any return type at all (in which case Pyre will treat it as returning typing.Any by default). This is bad because a return type of typing.Any may potentially hiding legitimate type errors that may happen at runtime: from typing import Any def f(): return 42 print(&quot;a&quot; + f())  $ pyre Missing return annotation [3]: Returning `int` but no return type is specified.  The best way to silence this error is to add non-Any return annotation to every function. ","version":"Next","tagName":"h3"},{"title":"4: Missing Attribute Annotation​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#4-missing-attribute-annotation","content":"In strict mode, Pyre will error when an attribute does not have an annotation. def foo() -&gt; str: return &quot;Hello, World!&quot; class A: b = foo() # Missing attribute annotation  $ pyre Missing attribute annotation [4]: Attribute `b` of class `A` has no type specified.  Adding a type annotation will resolve this error: def foo() -&gt; str: return &quot;Hello, World!&quot; class A: b: str = foo()  This error can also occur when pyre is inferring attribute types from constructors. For example, here we know that b is an int based on the parameter annotation in __init__: class A: def __init__(self, b: int) -&gt; None: self.b = b  But here we need a annotations because we can't just propagate an argument annotation: class A: def __init__(self, arg: int) -&gt; None: self.a = arg + 5 self.b = arg + 5  $ pyre Missing attribute annotation [4]: Attribute `a` of class `A` has type `int` but no type is specified. Missing attribute annotation [4]: Attribute `b` of class `A` has type `int` but no type is specified.  We can fix this by making the annotation explicit, either in the class body or in __init__: class A: a: int def __init__(self, arg: int) -&gt; None: self.a = arg + 5 self.b: int = arg + 5  ","version":"Next","tagName":"h3"},{"title":"5: Missing Global Annotation​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#5-missing-global-annotation","content":"If strict mode is turned on, Pyre will error when a globally accessible variable is not annotated. If pyre was able to infer a type for the variable, it will emit this type in the error message. The fix is usually to add an annotation to the variable. Note: This error has also arisen when there is some ambiguity of whether a declaration is a global expression or a type alias, in these cases pyre assumes it is an expression. Adding a : TypeAlias annotation lets pyre know that it is a type alias and solves the problem. from typing_extensions import TypeAlias # This declaration would result in an error MyTypeAlias = Dict[str, &quot;AnotherTypeAlias&quot;]  $ pyre Missing global annotation [5]: Globally accessible variable `MyTypeAlias` has no type specified.  from typing_extensions import TypeAlias # This declaration ensures that pyre knows MyTypeAlias is a type alias MyTypeAlias: TypeAlias = Dict[str, &quot;AnotherTypeAlias&quot;]  ","version":"Next","tagName":"h3"},{"title":"6: Incompatible Parameter Type​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#6-incompatible-parameter-type","content":"Pyre will error if an argument passed into a function call does not match the expected parameter type of that function. def takes_int(x: int) -&gt; None: pass def f(x: Optional[int]) -&gt; None: takes_int(x) # Incompatible parameter type error  $ pyre Incompatible parameter type [6]: In call `takes_int`, for 1st positional argument, expected `int` but got `Optional[int]`.  If you are seeing errors with invariant containers where some Container[T] is expected but you are passing Container[S] where S &lt; T, please see Covariance and Contravariance. ","version":"Next","tagName":"h3"},{"title":"7: Incompatible Return Type​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#7-incompatible-return-type","content":"Pyre will error when the value returned from a function does not match the annotation. def foo() -&gt; int: return &quot;&quot; # incompatible return type  $ pyre Incompatible return type [7]: Expected `int` but got `str`.  Updating the return annotation, or the value returned from the function will resolve this error. def foo() -&gt; str: return &quot;&quot; # compatible: No error  ","version":"Next","tagName":"h3"},{"title":"8: Incompatible Attribute Type​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#8-incompatible-attribute-type","content":"Pyre will error if a value is assigned to an attribute that does not match the annotated type of that attribute. class Foo: x: int = 0 def f(foo: Foo) -&gt; None: foo.x = &quot;abc&quot; # Incompatible attribute type error  $ pyre Incompatible attribute type [8]: Attribute `x` declared in class `Foo` has type `int` but is used as type `str`.  If you are seeing errors with invariant containers where some Container[T] is expected but you are passing Container[S] where S &lt; T, please see Covariance and Contravariance. ","version":"Next","tagName":"h3"},{"title":"9: Incompatible Variable Type​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#9-incompatible-variable-type","content":"Pyre will error when assigning incompatible types to local variables and parameters that were explicitly annotated. That is, the following will error: def f(x: int) -&gt; None: x = &quot;&quot; # Incompatible variable type error y: int = 1 y = &quot;&quot; # Incompatible variable type error  $ pyre Incompatible variable type [9]: x is declared to have type `int` but is used as type `str`. Incompatible variable type [9]: y is declared to have type `int` but is used as type `str`.  The rationale here is that it's surprising for an explicitly annotated variable to have an incompatible type later on in the same function. If you are constructing an object that is generic over an invariant type, you may run into an error: from typing import TypeVar _T = TypeVar('_T') class Foo(Generic[_T]): def __init__(self, x: _T) -&gt; None: ... def f() -&gt; None: foo: Foo[Optional[int]] = Foo(x=1) # Incompatible variable type error  $ pyre Incompatible variable type [9]: foo is declared to have type `Foo[Optional[int]]` but is used as type `Foo[int]`.  This is due to the fact that Foo[X] is not less than Foo[Y] even if X &lt; Y when the type variable is invariant. You can declare your intention to initialize the object with a wider type than is given to fix this error: from typing import TypeVar _T = TypeVar('_T') class Foo(Generic[_T]): def __init__(self, x: _T) -&gt; None: ... def f() -&gt; None: foo: Foo[Optional[int]] = Foo[Optional[int]](x=1)  ","version":"Next","tagName":"h3"},{"title":"10: Unbound Name​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#10-unbound-name","content":"Pyre produces an Unbound Name error when your code access a variable (local or global) that pyre believes is not defined. In most cases code that does this is invalid and will always fail. For example this code will always fail at runtime: def f() -&gt; int: return x # use of an unbound name x  $ pyre Unbound name [10]: Name `x` is used but not defined in the current scope.  There are some cases where python code that works fine at runtime could produce this error, for example if a function implicitly sets a module-level global variable that is not declared in the toplevel. Pyre will not accept this because module-level globals require type annotations, and if they have no declaration there is nowhere to put the annotation: def set_x() -&gt; None: global x x = 42 def use_x() -&gt; None: print(x) # this code will run fine, but pyre cannot analyze the type or use of the # implicitly-defined global x and will complain about an unbound name. set_x() use_x()  $ pyre Unbound name [10]: Name `x` is used but not defined in the current scope.  You can fix this by explicitly adding a declaration of the top-level variable x, for example: x : Optional[int] = None def set_x() -&gt; None: global x x = 42 def use_x() -&gt; None: print(x) # this code will run fine set_x() use_x()  ","version":"Next","tagName":"h3"},{"title":"11, 31: Undefined or Invalid Type​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#11-31-undefined-or-invalid-type","content":"Pyre recognizes class names as valid annotations. Most basic types are imported from the typing module or are already available from builtins like str, int, bool, etc. You can also define your own type alias on the global scope, which can be used as annotations: from typing_extensions import TypeAlias INT_OR_STR: TypeAlias = Union[int, str]  If you use a name as an annotation that is not a valid type or valid alias, you will see this error: from typing import Callable, List from typing_extensions import Final, Literal GLOBAL_VALUE = &quot;string&quot; def f0() -&gt; GLOBAL_VALUE: ... # Error! `GLOBAL_VALUE` is a value, not a type. def f1() -&gt; type(GLOBAL_VALUE): ... # Error! Static type annotations cannot be dynamically computed. def f2() -&gt; [int]: ... # Error! `[int]` is not a valid type. If you mean a list of int, use `typing.List[int]`. def f3() -&gt; (int, str): ... # Error! `(int, str)` is not a valid type. If you mean a pair of int and str, use `typing.Tuple[int, str]`. def f4() -&gt; Callable[[int]]: ... # Error! `Callable[[int]]` is not a valid type because the return type of the callable is missing. Good example: `Callable[[int], int]`. def f5() -&gt; Callable[int, int]: ... # Error! `Callable[int, int]` is not a valid type. The parameter types of the callable must be enclosed in square brackets. Good example: `Callable[[int], int]`. def f6() -&gt; List[Final[int]]: ... # Error! `Final` may only be used as the outermost type in annotations. See PEP 591. def f7() -&gt; Literal[GLOBAL_VALUE]: ... # Error! Only literals are allowed as parameters for `Literal`. See PEP586. Good example: `Literal[42]` or `Literal[&quot;string&quot;]`.  $ pyre Undefined or invalid type [11]: Annotation `GLOBAL_VALUE` is not defined as a type. Invalid type [31]: Expression `type(GLOBAL_VALUE)` is not a valid type. Invalid type [31]: Expression `[int]` is not a valid type. Invalid type [31]: Expression `(int, str)` is not a valid type. Invalid type [31]: Expression `typing.Callable[[int]]` is not a valid type. Invalid type [31]: Expression `typing.Callable[(int, int)]` is not a valid type. Invalid type [31]: Expression `GLOBAL_VALUE` is not a literal value.  You can fix this error by verifying that your annotation is statically determined.properly imported from typing if applicable.properly defined in the module you are importing from. If the module you are importing from has a stub file, you should check the definition there.properly adhere to the additional rules of special types (e.g. Callable, Final, and Literal). Type Aliases​ For type aliases, check that your type alias is defined with a valid type on the RHS. If you provide an annotation for the TypeAlias assignment, it must be typing_extensions.TypeAlias.on the global scope, not nested inside a function or class. ParamSpec​ For ParamSpec, check that you have used both *args: P.args and **kwargs: P.kwargs in your function's parameters: from typing import Callable from pyre_extensions import ParameterSpecification P = ParameterSpecification(&quot;P&quot;) # Error because `**kwargs: P.kwargs` is missing. def bad1(f: Callable[P, int], *args: P.args) -&gt; int: return f(*args) # Error because `*args: P.args` is missing. def bad2(f: Callable[P, int], **kwargs: P.kwargs) -&gt; int: return f(**kwargs)  $ pyre Undefined or invalid type [11]: Annotation `P.args` is not defined as a type. Call error [29]: `typing.Callable[P, int]` cannot be safely called because the types and kinds of its parameters depend on a type variable. Undefined or invalid type [11]: Annotation `P.kwargs` is not defined as a type.  No type error if you have used both *args: P.args and **kwargs: P.kwargs from typing import Callable from pyre_extensions import ParameterSpecification P = ParameterSpecification(&quot;P&quot;) # OK def good(f: Callable[P, int], *args: P.args, **kwargs: P.kwargs) -&gt; int: return f(*args, **kwargs)  ","version":"Next","tagName":"h3"},{"title":"12: Incompatible Awaitable Type​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#12-incompatible-awaitable-type","content":"In strict mode, pyre will verify that all calls to await are on awaitable values, to ensure that you cannot get a runtime error awaiting an object that is not a coroutine. A common situation where working code will produce this error is when pyre cannot statically verify that an awaitable is non-Null, for example: import asyncio async def f(flag: bool) -&gt; None: if flag: task = asyncio.create_task(asyncio.sleep(1)) else: task = None await task # would throw a ValueError if flag were false asyncio.run(f(True))  In this example, task will always be a valid awaitable unless some other module overwrites the global flag, but pyre cannot prove that this does not happen. The error we get has the message $ pyre Expected an awaitable but got `typing.Optional[asyncio.tasks.Task[None]]`  You can fix this error by ensuring that the awaited object has an awaitable type. In the case of optional values, you can use refinement to rule out None. The example above can be fixed by tweaking the definition of main: async def f(flag: bool) -&gt; None: if flag: task = asyncio.create_task(asyncio.sleep(1)) else: task = None if task is not None: await task  ","version":"Next","tagName":"h3"},{"title":"13: Uninitialized Attribute​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#13-uninitialized-attribute","content":"In strict mode, pyre will throw an error for class attributes which are declared without default values if they are not initialized in a constructor, for example: class A: x : int def __init__(self) -&gt; None: pass  $ pyre Uninitialized attribute [13]: Attribute `x` is declared in class `A` to have type `int` but is never initialized.  For a case like this, you can fix the error either by setting a default value like x : int = 0 at the class level, or by setting x in the constructor e.g. self.x = 0. class A: x: int = 0 def __init__(self) -&gt; None: pass  class A: x: int def __init__(self, x: int = 0) -&gt; None: self.x = x  Dataclass-like classes​ One case where this can occur is when using a library providing a &quot;dataclass-like&quot; decorator that, for example, autogenerates a constructor setting attributes. from dataclasses import dataclass @dataclass class A: x: int  Pyre currently knows that that uninitialized attributes of classes wrapped in dataclass and attrs decorators will generate constructors that set the attributes. But it does not understand many custom libraries that do similar things, for example test frameworks, or new decorators that wrap the dataclass decorator and add more logic. There is not currently a way to fix this other than via pyre-ignore or pyre-fixme directives. The python typing community is aware of this problem but has not yet settled on a solution, you can see discussion here. ","version":"Next","tagName":"h3"},{"title":"14,15: Behavioral Subtyping​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#1415-behavioral-subtyping","content":"Method overrides should followLiskov's substitution principle. In short, parameter types can't be more restrictive and return types can't be more permissive in overridden methods. To see why, consider the following example: def width(image: Image) -&gt; float: return image.width()  Say we now have different implementations of our Image class, one of which violates the substitution principle: class Image: def width() -&gt; float: pass class JpegImage(Image): def width() -&gt; int: return 10 # this is fine class ComplexImage(Image): def width() -&gt; complex: return 1j def foo() -&gt; None: image: Image = ComplexImage() print(int(image.width()))  The above code fails at runtime with TypeError: can't convert complex to int. The case for parameters follows analogously. Common Reasons​ Could not find parameter y in overriding signature.: Check if the overriding function can accept all arguments that the overridden function can. class Base: def foo(self, x: int, y: str) -&gt; None: pass class Child(Base): def foo(self, x: int) -&gt; None: pass Type Foo is not a subtype of the overridden attribute type Bar: class Base: a: int = 0 class Child(Base): a: str = &quot;&quot; def foo() -&gt; None: base: Base = Child() base.a + 1 This would fail at runtime with TypeError: can only concatenate str (not &quot;int&quot;) to str. Returned type Foo is not a subtype of the overridden return Bar.: Check for reasons like invariance. ","version":"Next","tagName":"h3"},{"title":"16: Missing Attributes​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#16-missing-attributes","content":"Your code is most likely trying to access an attribute that Pyre does not know about. Pyre has various ways of inferring what is an attribute of an object: Explicitly Declare the Attribute​ class Derp: my_attribute: int = 1 @property def my_property(self) -&gt; int: ...  Implicitly Declare the Attribute​ class Derp: def __init__(self, foo: str) -&gt; None: self.my_attribute: int = 1 # The `foo` attribute is inferred to have type `str` because the # parameter `foo` has type `str`. self.foo = foo  Pyre does one level of inlining to infer implicit parameters We suggest you do not heavily rely on this feature as it is not sound and makes our code brittle. Support for this is temporary. Common Reasons​ Optional type has no attribute foo.: See Optional attributes. Foo has no attribute bar.: Check if you have explicitly provided the type for bar either in the constructor or as a class attribute. Module foo has no attribute bar: Check if the library has stubs. If so, you may need to add the function, class, or global variable to the stub. A library class has an attribute but it is not recognized by Pyre: Check if the library has stubs. If so, you may need to add the attribute to the class in the stub. Your class has dynamic attributes: Consider using __getattr__ in a stub so that Pyre doesn't complain about those attributes. ","version":"Next","tagName":"h3"},{"title":"17: Incompatible Constructor Annotation​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#17-incompatible-constructor-annotation","content":"PEP 484 specifies that __init__ method of any class must be annotated to return None. Pyre will emit an error if the user's annotation does not conform to the specification. # pyre-strict class A: def __init__(self) -&gt; &quot;A&quot;: # Error 17: Invalid return annotation of `__init__`. ... class B: def __init__(self) -&gt; None: # OK ...  $ pyre Incompatible constructor annotation [17]: `__init__` is annotated as returning `A`, but it should return `None`.  ","version":"Next","tagName":"h3"},{"title":"19: Too Many Arguments​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#19-too-many-arguments","content":"Pyre verifies that you pass a legal number of arguments to functions. The most obvious way to encounter this error is to just pass too many arguments to a function: def f(x: int) -&gt; int: return x f(5, 6) # this would throw a TypeError at runtime, and pyre complains  $ pyre Too many arguments [19]: Call `f` expects 1 positional argument, 2 were provided.  To fix this, make sure you pass the correct number of parameters. In some cases you may encounter this error if you intended to use a variadic argument (*args) or to set a default value. Pyre will also throw this error if you pass too many positional arguments to a function that uses python's ability restrict arguments to be keyword-only specified by PEP 3102: def f(*, x: int) -&gt; int: return x f(5) # As before, this throws a TypeError because x is positional-only f(x=5) # this line will typecheck and run without error  $ pyre Too many arguments [19]: Call `f` expects 0 positional arguments, 1 was provided.  ","version":"Next","tagName":"h3"},{"title":"20: Missing Argument​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#20-missing-argument","content":"Pyre verifies that function calls provide all the expected arguments, so it will complain about code like this: def f(x: int) -&gt; ing: return x f()  $ pyre Missing argument [20]: Call `f` expects argument `x`.  To fix this, make sure all required arguments are provided. ","version":"Next","tagName":"h3"},{"title":"21: Undefined Name, Undefined Import​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#21-undefined-name-undefined-import","content":"This is usually caused by failing to import the proper module. from my_module import my_function my_function()  $ pyre Undefined import [21]: Could not find a module corresponding to import `my_module`.  Pyre will raise error 21 instead (&quot;Undefined import&quot;) when the import statement is present, but the module to be imported could not be found in the search path. If the module provides stub files, please provide their location via the --search-path commandline parameter. Namespace Package Modules​ One case where you may run into undefined imports on code that works at runtime is when importing namespace modules. The CPython runtime allows you to import a directory that is on your PYTHONPATH, even if it contains no __init__.py; this behavior is defined in PEP 420 and the module is called a namespace package. In order to make Pyre both fast and consistent on incremental updates, in Pyre we only allow importing namespace packages that have at least one python file as a direct child. So, for example, if I have a directory tree with just a/b/c.py then Pyre will allow import a.b.c and import a.b but not import a. A namespace package module can never contain useful types or code so it is rare to directly import it, but in special cases it might be useful (for example to access the __name__ attribute). In these cases, you'll need to suppress Pyre errors. ","version":"Next","tagName":"h3"},{"title":"22: Redundant Cast​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#22-redundant-cast","content":"Pyre will warn when you attempt to use typing.cast to cast a variable to a type that the type checker already knows that variable has. This is because typing.cast is purely a tool for communicating with the static type checker, and will not provide any runtime guarantees. Therefore a redundant cast provides no value and is likely a mistake. from typing import cast def foo(x: int) -&gt; None: y = cast(int, x)  $ pyre Redundant cast [22]: The value being cast is already of type `int`.  If you are trying to document the type of the variable, you can provide an explicit annotation where it is declared. If you are trying to add a sanity check at runtime that the type of a variable is what you already believe it must be, use isinstance. ","version":"Next","tagName":"h3"},{"title":"23: Unable to Unpack​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#23-unable-to-unpack","content":"Pyre will warn you when trying to assign a value to a tuple with the wrong number of items. def foo() -&gt; None: a, b = (1, 2, 3) x, y = 42  $ pyre Unable to unpack [23]: Unable to unpack 3 values, 2 were expected. Unable to unpack [23]: Unable to unpack `int` into 2 values.  Common reasons: Trying to assign an Optional value to a tuple: def bar() -&gt; None: x = None if 2 + 2 == 4: x = (&quot;a&quot;, &quot;b&quot;) a, b = x $ pyre Unable to unpack [23]: Unable to unpack `typing.Optional[typing.Tuple[str, str]]` into 2 values. Unpacking an incorrect number of elements when looping over a list: for a, b in [1, 2, 3]: print(a, b) $ pyre Unable to unpack [23]: Unable to unpack `int` into 2 values.  ","version":"Next","tagName":"h3"},{"title":"24: Invalid Type Parameters​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#24-invalid-type-parameters","content":"Pyre will error if a generic type annotation is given with unexpected type parameters. &quot;Generic type expects X type parameters ...&quot;​ Either too few or too many type parameters were provided for the container type. For example, x: List[int, str] = [] # Invalid type parameters error  $ pyre Invalid type parameters [24]: Generic type `list` expects 1 type parameter, received 2, use `typing.List[&lt;element type&gt;]` to avoid runtime subscripting errors.  In this case, typing.List is a generic type taking exactly one type parameter. If we pass a single parameter, this resolves the issue. x: List[Union[int, str]] = [] # No error  If you do not know or do not want to specify the type parameters, use typing.Any but still ensure the arity is correct. x: List = [] # Invalid type parameters error x: List[Any] = [] # No error  Note: You may see a suggestion to use typing.List instead of builtins list as the type annotation when providing type parameters. This is to avoid runtime errors, because the builtin list does not support subscripting and list[int] is therefore not runtime-friendly. &quot;Non-generic type cannot take type parameters ...&quot;​ Type parameters are only meaningful if the container type is generic. Passing in the type parameter binds the provided parameter type to the generic in the container class. For example, class Container: def add(self,element: int) -&gt; None: ... def get_element(self) -&gt; int: ... x: Container[int] = Container() # Invalid type parameter error  $ pyre Invalid type parameters [24]: Non-generic type `Container` cannot take parameters.  from typing import TypeVar, Generic T = TypeVar('T') class Container(Generic[T]): def add(self,element: T) -&gt; None: ... def get_element(self) -&gt; T: ... x: Container[int] = Container() x.get_element() # returns int y: Container[str] = Container() y.get_element() # returns str  &quot;Type parameter violates constraints ...&quot;​ If a container class is generic over a type variable with given type bounds, any type parameter used must comply with those type bounds. For example, from typing import TypeVar, Union, Generic T = TypeVar('T', bound=Union[int, bool]) class Container(Generic[T]): def add(self, element: T) -&gt; None: ... def get_element(self) -&gt; T: ... x: Container[int] = Container() # No error y: Container[str] = Container() # Invalid type parameter error  $ pyre Invalid type parameters [24]: Type parameter `str` violates constraints on `Variable[T (bound to typing.Union[bool, int])]` in generic type `Container`.  ","version":"Next","tagName":"h3"},{"title":"26: Typed Dictionary Access With Non-Literal​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#26-typed-dictionary-access-with-non-literal","content":"In python, typed dictionaries can only be accessed using literal strings that can be statically verified as valid. As a result, code like this will not typecheck even though it works at runtime, because we cannot statically verify that key in print_value is a valid Shape key: from typing import TypedDict class Shape(TypedDict): sides: int color: str shape: Shape = {&quot;sides&quot;: 4, &quot;color&quot;: &quot;blue&quot;} print(shape[&quot;sides&quot;]) # this is fine because &quot;sides&quot; is a literal for key in [&quot;sides&quot;, &quot;color&quot;]: print(key, shape[key]) # pyre will complain here because it can't prove `key` is valid  $ pyre TypedDict accessed with a non-literal [26]: TypedDict key must be a string literal. Expected one of ('color', 'sides').  The example above shows a situation where you might hit this error: when you want to iterate over the fields of a typed dict. A suggested fix is to use type-safe operations like dictionary.items instead. For example the following code produces the same results but type checks:  class Shape(TypedDict): sides: int color: str shape: Shape = {&quot;sides&quot;: 4, &quot;color&quot;: &quot;blue&quot;} print(shape[&quot;sides&quot;]) # this is fine because &quot;sides&quot; is a literal for key, value in shape.items(): print(key, value) # no error  In other cases where you need to access a TypedDict using a variable as a key, you can use dictionary.get(key). from typing import TypedDict class Shape(TypedDict): sides: int color: str shape: Shape = {&quot;sides&quot;: 4, &quot;color&quot;: &quot;blue&quot;} print(shape[&quot;sides&quot;]) # this is fine because &quot;sides&quot; is a literal for key in [&quot;sides&quot;, &quot;color&quot;]: print(key, shape.get(key)) # no error  ","version":"Next","tagName":"h3"},{"title":"27: Typed Dictionary Key Not Found​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#27-typed-dictionary-key-not-found","content":"If you try to access a typed dictionary with a string literal that pyre knows is not a valid key, pyre will emit an error: from typing import TypedDict class Shape(TypedDict): sides: int color: str def f(shape: Shape) -&gt; None: print(shape[&quot;location&quot;]) # error here  $ pyre TypedDict accessed with a missing key [27]: TypedDict `Shape` has no key `location`.  A possible fix: pyre considers instances of any TypedDict with additional fields to be a subtype of Shape, so in many cases you could handle the need for a location field in some Shape dicts by creating a new type as follows: from typing import TypedDict class Shape(TypedDict): sides: int color: str class ShapeWithLocation(TypedDict): sides: int color: str location: str def f(shape: ShapeWithLocation) -&gt; None: print(shape[&quot;location&quot;]) # okay g(shape) # also okay: ShapeWithLocation is a subtype of Shape def g(shape: Shape) -&gt; None: print(shape)  ","version":"Next","tagName":"h3"},{"title":"28: Unexpected Keyword​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#28-unexpected-keyword","content":"Pyre will error if attempting to pass an argument by name and there are no parameters with a matching name. For example, def foo(integer: int, string: str) -&gt; None: ... foo(1, &quot;one&quot;) # no error foo(string=&quot;one&quot;, integer=1) # no error foo(integer=1, undefined=&quot;one&quot;) # type error  $ pyre Unexpected keyword [28]: Unexpected keyword argument `undefined` to call `foo`.  ","version":"Next","tagName":"h3"},{"title":"29: Call Error​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#29-call-error","content":"Pyre will emit an error on seeing a call of one of the following types: The called object is not a function. This means that its inferred type is not Callable and it is not an instance of a class which implements a __call__ method. This could happen due to user error (the object is indeed not a function) or due to an incorrect or incomplete type stub for the object's class causing pyre to infer the wrong type. The call cannot be safely typed since the types and kinds of its parameters depend on a type variable. This is seen when the callable is typed using a ParameterSpecification type variable and the *args and **kwargs are not passed into the call correctly, i.e. together and in order. (For more details see PEP 612) from pyre_extensions import ParameterSpecification from typing import Callable P = ParameterSpecification(&quot;P&quot;) def decorator(f: Callable[P, int]) -&gt; Callable[P, None]: def foo(*args: P.args, **kwargs: P.kwargs) -&gt; None: f(*args, **kwargs) # Accepted, should resolve to int f(*args) # Rejected : error here f(*kwargs, **args) # Rejected : error here f(1, *args, **kwargs) # Accepted return foo  $ pyre Call error [29]: `typing.Callable[sandbox.P, int]` cannot be safely called because the types and kinds of its parameters depend on a type variable. Call error [29]: `typing.Callable[sandbox.P, int]` cannot be safely called because the types and kinds of its parameters depend on a type variable.  ","version":"Next","tagName":"h3"},{"title":"30, 36: Terminating Analysis, Mutually Recursive Type Variables​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#30-36-terminating-analysis-mutually-recursive-type-variables","content":"Overly-complex Functions​ In very rare cases where a function has a lot of if branches or for-loops, Pyre may raise an error saying that is unable to analyze the function fully. Analyzing extremely complex functions in depth can be costly, so Pyre only does so up to a limit. This means that it won't infer precise types for some variables and won't catch errors related to their usage. For example: def my_function() -&gt; None: u = 42 if foo(): x1 = bar() if x1: x2 = baz() if x2: # &lt;more branches of code&gt; else: # &lt;more branches&gt; if foo2(): # &lt;code&gt; if foo3(): # &lt;even more branches&gt; # &lt;and even more branches&gt; $ pyre Analysis failure [30]: Pyre gave up inferring types for some variables because function `foo` was too complex. Please simplify the function by factoring out some if-statements or for-loops.  To remedy this, factor out some of the branching code into separate functions out that each function has a limited amount of branching logic: def do_stuff() -&gt; None: if foo(): # &lt;code&gt; if foo(): # &lt;even more branches&gt; # &lt;and even more branches&gt; def bar() -&gt; None: u = 42 if foo(): x1 = bar() if x1: x2 = baz() if x2: # &lt;more branches of code&gt; else: # &lt;more branches&gt; do_stuff()  Other Analysis Failures​ These errors usually indicates a bug in Pyre. Please open an issue on Github. ","version":"Next","tagName":"h3"},{"title":"31: Invalid Type​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#31-invalid-type","content":"This indicates that you are using some expression that pyre does not understand as a type. Some situations where you might run into this: Using a list of types rather than List[type]: x: [str] = [&quot;a string&quot;] You can fix this by using the List type: x: List[str] = [&quot;a string&quot;] Using a constructor call rather than a bare class name: class A: ... a: A() = A() You can fix this by using a bare type name: a: A = A()  ","version":"Next","tagName":"h3"},{"title":"32: Invalid Argument​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#32-invalid-argument","content":"This error usually means you are using a variable in a way that is incompatible with its structure, either as an argument to a function call or as part of a data structure. This could be from using an invalid variadic parameter (informally a &quot;splat&quot;): x: int = 5 print(*x) # invalid use of x, which is not iterable  $ pyre Invalid argument [32]: Unpacked argument `x` must have an unpackable type but has type `typing_extensions.Literal[5]`.  or using an invalid keyword parameter (informally a &quot;double-splat&quot;): from typing import Dict x: int = 5 d: Dict[int, int] = {**x} # invalid use of x, which is not a mapping dict(**d) # invalid use of d; function kwargs must be a mapping with string keys  $ pyre Invalid argument [32]: Keyword argument `x` has type `typing_extensions.Literal[5]` but must be a mapping. Invalid argument [32]: Keyword argument `d` has type `Dict[int, int]` but must be a mapping with string keys.  It's also possible to hit this error code on constraint mismatches when using tuple variadic variables as specified in PEP 646, which are an advanced feature of pyre. ","version":"Next","tagName":"h3"},{"title":"33: Prohibited Any​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#33-prohibited-any","content":"Pyre will warn on any usage of typing.Any when run in strict mode. Any is an escape hatch that hides type errors and introduces potential type inconsistencies which Pyre strict is designed to make explicit. import typing from typing import Any, Dict def foo() -&gt; None: x: typing.Any = 1  $ pyre Prohibited any [33]: Expression `x` has type `int`; given explicit type cannot be `Any`.  To resolve this error, replace Any with any other annotation. Using builtins object is acceptable if you are looking for a supertype of all classes. ","version":"Next","tagName":"h3"},{"title":"34: Invalid Type Variable​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#34-invalid-type-variable","content":"Type variables can only be used as types when they have already been placed &quot;in scope&quot;. A type variable can be placed into scope via: Generic class declarations for example, class C(Generic[T]): puts T into scope for the body of the class The parameter types of a generic function for example, def foo(x: T) puts T into scope for the body and return type annotation of the function For example: from typing import List class Base: foo: List[T] = [] $ pyre Invalid type variable [34]: The current class isn't generic with respect to the type variable `Variable[T]`.  def foo(x: int) -&gt; List[T]: return [x, x] $ pyre Invalid type variable [34]: The type variable `Variable[T]` isn't present in the function's parameters.  Suggested fix: from typing import Generic, List class Base(Generic[T]): foo: List[T] = [] base: Base[int] def foo(x: T) -&gt; List[T]: return [x, x]  Decorator Factories​ One common error is when defining a generic decorator factory. The Python type system doesn't currently place T into scope within a Callable type. So, it considers T to be a type variable from the outer scope. This can lead to errors for apparently valid code: from typing import Callable, TypeVar T = TypeVar(&quot;T&quot;) R = TypeVar(&quot;R&quot;) def my_decorator_factory(message: str) -&gt; Callable[[Callable[[T], R]], Callable[[T], R]]: def _decorator(f: Callable[[T], R]) -&gt; Callable[[T], R]: def _inner(x: T) -&gt; R: print(message) return f(x) return _inner return _decorator $ pyre Invalid type variable [34]: The type variable `Variable[R]` isn't present in the function's parameters. Invalid type variable [34]: The type variable `Variable[T]` isn't present in the function's parameters.  Suggested fix: Use a callback protocol to define the return type. from typing import Callable, Protocol, TypeVar T = TypeVar(&quot;T&quot;) R = TypeVar(&quot;R&quot;) class MyCallableProtocol(Protocol): def __call__(self, f: Callable[[T], R]) -&gt; Callable[[T], R]: ... def my_decorator_factory(message: str) -&gt; MyCallableProtocol: def _decorator(f: Callable[[T], R]) -&gt; Callable[[T], R]: def _inner(x: T) -&gt; R: print(message) return f(x) return _inner return _decorator  If you are using a ParamSpec in your decorator, use the following: from typing import Any, Callable, Coroutine, Protocol, TypeVar from pyre_extensions import ParameterSpecification import asyncio R = TypeVar(&quot;R&quot;) P = ParameterSpecification(&quot;P&quot;) class MyCallableProtocol(Protocol): def __call__(self, f: Callable[P, Coroutine[object, object, R]]) -&gt; Callable[P, Coroutine[object, object, R]]: ... def my_decorator_factory(message: str) -&gt; MyCallableProtocol: def _decorator(f: Callable[P, Coroutine[object, object, R]]) -&gt; Callable[P, Coroutine[object, object, R]]: async def _inner(*args: P.args, **kwargs: P.kwargs) -&gt; R: print(message) return await f(*args, **kwargs) return _inner return _decorator @my_decorator_factory(&quot;hello!&quot;) async def foo() -&gt; int: return 1 asyncio.run(foo())  Note: Support for such callables is currently experimental and varies from one typechecker to another. This behavior may change in the future. ","version":"Next","tagName":"h3"},{"title":"35: Illegal Annotation Target​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#35-illegal-annotation-target","content":"Pyre will error when a type annotation is applied to something that can't be annotated. This could happen when: A variable is re-annotated after first declaration or an explicity annotated function parameter is re-annotated within the function body. This is not allowed as re-annotating variables reduces readability and causes the annotation of a variable to depend on the position in control flow. def transformation(p: int) -&gt; str: return str(p + 1) def foo(x: int) -&gt; None: y: int = x + 2 z = x + 3 # Each of the following will produce an error x: str = transformation(x) y: str = transformation(y) z: int = 4 $ pyre Illegal annotation target [35]: Target `x` cannot be annotated after it is first declared. Illegal annotation target [35]: Target `y` cannot be annotated after it is first declared. Illegal annotation target [35]: Target `z` cannot be annotated after it is first declared. An easy fix for the first two errors is to use a new variable rather than re-annotating the old variable so it can hold a new type. For the third error, z should have been annotated at first declaration. Trying to annotate non-self attributes, i.e annotating the attributes of a different class than the one whose scope you are in: class Foo: attribute: int = 1 class Bar: def __init__(self) -&gt; None: Foo.attribute: str = &quot;hello&quot; def some_method() -&gt; None: Foo.attribute: int = 5 $ pyre Illegal annotation target [35]: Target `sandbox.Foo.attribute` cannot be annotated. Illegal annotation target [35]: Target `sandbox.Foo.attribute` cannot be annotated. This is not allowed as Pyre needs to be able to statically determine the type of globally accessible values, including class attributes. Even if Pyre followed control flow across functions to determine class attribute annotations, such re-annotations imply very dynamic behavior that makes the code difficult to work with. The fix for this situation, similar to the case above, is to annotate the class attribute at its definition in the class that owns it and remove any annotations elsewhere. If this attribute is from a third party library, then you can add a stub for the class and annotate the attribute there. ","version":"Next","tagName":"h3"},{"title":"39: Invalid Inheritance​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#39-invalid-inheritance","content":"When defining a new class, Pyre will error if the base class given is not a valid parent class. This may be caused by various conditions: The parent class is marked as final which means it explicitly is annotated as not supporting child classes. @final class Base: ... class Derived(Base): # Invalid inheritance error ... $ pyre Invalid inheritance [39]: Cannot inherit from final class `Base`. The expression given in the base class field is not a class at all. MY_GLOBAL: str = &quot;string&quot; class Foo(MY_GLOBAL): # Invalid inheritance error ... Pyre does not support dynamic expressions as base classes, even if they may evaluate to a valid class at runtime. This is because the type checker relies on building up a valid class hierarchy before it can resolve types in the Python it is analyzing. On the other hand, type aliases are equivalent to types and are acceptable as base classes. You are defining a typed dictionary that does not inherit from another typed dictionary. from typing import TypedDict class NonTypedDict: ... class Movie(TypedDict): name: str year: int class BookBasedMovie(Movie): # No error based_on: str class BookBasedMovie(NonTypedDict): # Invalid inheritance error based_on: str If inheriting from another typed dictionary, fields need to have a consistent type between child and parent, in order for subclassing to be sound. Similarly, a required field in the child must also be required for the parent. ","version":"Next","tagName":"h3"},{"title":"40: Invalid Override​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#40-invalid-override","content":"Pyre will error when methods in a child class override those in a parent class inconsistently. Static methods cannot be overwritten by non-static methods, and final methods cannot be overwritten. class A: @staticmethod def foo() -&gt; int: pass class B(A): @classmethod # Non-static method `B.foo` cannot override a static method defined in `A`. def foo(cls) -&gt; int: pass  from typing import final class Foo: @final def bar(self) -&gt; None: pass class Bar(Foo): def bar(self) -&gt; None: # Invalid override, because Foo.bar is final pass  ","version":"Next","tagName":"h3"},{"title":"41: Invalid Assignment​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#41-invalid-assignment","content":"Pyre will error on assignments to final attributes, read-only properties, and class variables from a class instance. For example, from typing import Final, Optional class Foo: field: Final[Optional[int]] = 1 def foo() -&gt; None: self.field = 2 # Invalid assignment class Bar: _x = 1 @property def x(self) -&gt; int: return self._x def bar(b: Bar) -&gt; None: b.x = 1 # Invalid assignment  To fix this error, change the definition of this attribute to something that is mutable, if it is not intended to be read-only. ","version":"Next","tagName":"h3"},{"title":"42: Missing Overload Implementation​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#42-missing-overload-implementation","content":"Pyre will throw this error if a source module specifies one or more overloads via typing.overload but fails to provide an implementation, for example: from typing import overload @overload def f(x: int) -&gt; float: ... @overload def f(x: str) -&gt; str: ...  Missing implementations are allowed in .pyi stub files. To fix it, provide exactly one implementation (a function of the same name without the typing.overload decorator). For example above we could implement f as follows: from typing import overload, Union @overload def f(x: int) -&gt; float: ... @overload def f(x: str) -&gt; str: ... @overload def f(x: str) -&gt; str: ... def f(x: Union[int, str]) -&gt; Union[float, str]: if isinstance(x, int): return float(x) else: return x  ","version":"Next","tagName":"h3"},{"title":"43: Incompatible Overload Implementation​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#43-incompatible-overload-implementation","content":"Pyre will error if you define one or more overloads using typing.overload, and your concrete implementation has an incompatible type signature. For example, this code will produce an incompatible overload implementation error # pyre-strict from typing import overload, Union @overload def f(x: int) -&gt; float: ... @overload def f(x: float) -&gt; int: ... @overload def f(x: str) -&gt; str: ... def f(x: Union[int, float, str]) -&gt; Union[int, str]: if isinstance(x, float): return int(x) elif isinstance(x, int): return float(x) else: return x  The problem here is that the return type Union[int, str] is too narrow to permit f to return float when called on an int argument. You can fix this by either removing incorrect overload delcarations or making sure all parameters and return type annotations on the concrete implementation are general enough to be consistent with the overloads: def f(x: Union[int, float, str]) -&gt; Union[int, float, str]: &lt;same implementation&gt;  ","version":"Next","tagName":"h3"},{"title":"45: Invalid Class Instantiation​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#45-invalid-class-instantiation","content":"In typed Python, some classes that represent abstract interfaces may not be directly instantiated. Pyre considers a class C abstract, and will error on invalid instantiation if you try to construct an instance directly in either of the following cases: C contains one or more abstract methods that are left not overridden. Abstract methods are defined as methods that are decorated with @abc.abstractmethod. For example, here Derived0 is abstract because it does not override bar, but Derived1 may be instantiated: import abc from typing import Protocol class Base(abc.ABC): @abc.abstractmethod def foo(self) -&gt; None: raise NotImplementedError @abc.abstractmethod def bar(self) -&gt; str: raise NotImplementedError class Derived0(Base): def foo(self) -&gt; None: print(self.bar()) class Derived1(Derived0): def bar(self) -&gt; str: return &quot;bar&quot; def test0() -&gt; None: base = Base() # Error! Class `Base` contains 2 abstract methods and therefore cannot be instantiated. derived0 = Derived0() # Error! Class `Derived0` contains 1 abstract method `bar` and therefore cannot be instantiated. derived1 = Derived1() # OK C directly inherits from typing.Protocol. For example, here MyProtocol is abstract because it inherits directly from typing.Protocol, but MyClass (which implements the protocol interface) may be instantiated: class MyProtocol(Protocol): def baz(self, x: int) -&gt; int: ... class MyClass: def baz(self, x: int) -&gt; int: return x def test1() -&gt; None: object0 = MyProtocol() # Error! Class `MyProtocol` cannot be instantiated. object1 = MyClass() # OK  ","version":"Next","tagName":"h3"},{"title":"46: Invalid Type Variance​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#46-invalid-type-variance","content":"In brief, read-only data types can be covariant, write-only data types can be contravariant, and data types that support both reads and writes must be invariant. If a data type implements any functions accepting parameters of that type, we cannot guarantee that writes are not happening. If a data type implements any functions returning values of that type, we cannot guarantee that reads are not happening. For example (note: int is a subclass of float in the type system and in these examples): Writes taking covariants: from typing import TypeVar, Generic _T_co = TypeVar(&quot;_T_co&quot;, covariant=True) class MyList(Generic[_T_co]): def write(self, element: _T_co) -&gt; None: ... # adds element to list def takes_float_list(float_list: MyList[float]) -&gt; None: float_list.write(1.0) int_list: MyList[int] = ... takes_float_list(int_list) # this call is OK because MyList is covariant: MyList[int] &lt; MyList[float] # int_list contains floats  Reads returning contravariants: from typing import TypeVar, Generic _T_cont = TypeVar(&quot;_T_cont&quot;, contravariant=True) class MyList(Generic[_T_cont]): def read(self) -&gt; _T_cont: ... # returns first element from list def takes_int_list(int_list: MyList[int]) -&gt; int: return int_list.read() float_list: MyList[float] = ... takes_int_list(float_list) # this call is OK because MyList is contravariant: MyList[float] &lt; MyList[int] # problem with return above is clear  ","version":"Next","tagName":"h3"},{"title":"47: Invalid Method Signature​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#47-invalid-method-signature","content":"Pyre will error if a non-static method fails to specify an expected implicit parameter like self for an instance method or cls for a class method, as this argument is always implicitly passed in a call and will cause a runtime crash if not specified. Additionally, Pyre will warn if this parameter is specified but typed as something incompatible with the type of the parent class. Often times, the method may not need a self or cls and should be decorated with @staticmethod to resolve this error. For example, class Foo: def foo() -&gt; None: ... # type error class Foo: @staticmethod def foo() -&gt; None: ... # no type error class Foo: def foo(self) -&gt; None: ... # no type error  Only type variables with compatible bounds can be used to annotate the self or cls parameter. For example, from typing import TypeVar P = TypeVar(&quot;T&quot;, bound=&quot;Parent&quot;) A = TypeVar(&quot;S&quot;, bound=&quot;ChildA&quot;) B = TypeVar(&quot;S&quot;, bound=&quot;ChildB&quot;) class Parent: ... class ChildA(Parent): @classmethod def foo(cls: Type[A]) -&gt; A: ... # no type error class ChildB(Parent): def foo(self: A) -&gt; A: ... # type error def bar(self: B) -&gt; B: ... # no type error def baz(self: P) -&gt; P: ... # no type error  ","version":"Next","tagName":"h3"},{"title":"48: Invalid Exception​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#48-invalid-exception","content":"In python, you can only raise objects that derive from BaseException (it's more common to subtype Exception or one of the standard library-defined errors like ValueError). Attempting to raise another object such as a bare string will result in a TypeError. As a result, pyre will flag code like this: def f(x: int) -&gt; None: if x &gt; 1: raise &quot;x is too big&quot;  To fix this, wrap the information you are trying to raise (usually an error message) in some exception type, for example: def f(x: int) -&gt; None: if x &gt; 1: raise ValueError(&quot;x is too big&quot;)  ","version":"Next","tagName":"h3"},{"title":"49: Unsafe Cast​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#49-unsafe-cast","content":"To allow &quot;safe&quot; casts that preserve type soundness, you can use pyre_extensions.safe_cast. This will verify that the type you are casting to is broader than the type of the expression. In cases where this is not the case, pyre will produce an Unsafe Cast error. For example: from pyre_extensions import safe_cast def foo(x: int) -&gt; str: y = safe_cast(str, x) # Unsafe cast error z = safe_cast(Union[int, str], x) # No error return z # Invalid return type error  Some context on this: pyre_extensions.safe_cast is a type-safe alternative to typing.cast. The typing.cast function forces type checkers to accept a type for an expression that otherwise would not be valid, which is sometimes useful but also can hide clear type errors, for example: from typing import cast def foo(x: int) -&gt; str: y = cast(str, x) return y # No type error, even though this is unsound.  ","version":"Next","tagName":"h3"},{"title":"51: Unused Local Mode​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#51-unused-local-mode","content":"This error will be thrown if you specify more than one local mode, by having multiple line comments of the form # pyre-strict or # pyre-unsafe in the header. Pyre will ask you to remove all but one local mode declaration if you have more than one because the mode needs to be unambiguous. Context: Pyre supports two modes of type checking, unsafe and strict. By default, every file runs in unsafe mode, but you can change this default to strict in your configuration file.In addition, you can set the type checking mode of a module to differ from the default for the project by adding a comment in the form # pyre-strict or # pyre-unsafe comment on its own line to the file header. ","version":"Next","tagName":"h3"},{"title":"52: Private Protocol Property​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#52-private-protocol-property","content":"Python Protocols provide a way to statically check &quot;duck typing&quot;, what many languages would refer to as interfaces. Because protocols specify only an interface, they should not include private fields and methods, which cannot not be accessed outside of the class where they are defined (including in subclasses). Pyre will complain about the following: from typing import Protocol class Duck(Protocol): def __quack(self) -&gt; str: ... class SomeDuck: def __quack(self) -&gt; str: return &quot;quack&quot;  To signal a non-public part of an interface, use a protected field or method (single leading underscore), which is accessible by classes implementing the interface: from typing import Protocol class Duck(Protocol): def _quack(self) -&gt; str: ... class SomeDuck: def _quack(self) -&gt; str: return &quot;quack&quot;  ","version":"Next","tagName":"h3"},{"title":"53: Missing Annotation For Captured Variables​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#53-missing-annotation-for-captured-variables","content":"Pyre makes no attempt at trying to infer the types across function boundaries. The statement holds for nested functions as well. From a nested function's perspective, a variable defined in an nesting function behaves similarly to a global variable. As with global variables, an explicit annotation is required if strict mode is turned on: def outer_function0() -&gt; int: x = foo() def inner_function() -&gt; int: return x # Due to the lack of explicit annotation, Pyre will treat this variable as having type `Any`. return inner_function() def outer_function1() -&gt; int: x: int = foo() def inner_function() -&gt; int: return x # This is ok: the type of `x` is known to be `int`. return inner_function() def outer_function2() -&gt; int: x = foo() def inner_function(x: int) -&gt; int: return x # This is also ok: even though the outer `x` is not annotated, the `x` parameter of the inner function is. return inner_function(x)  ","version":"Next","tagName":"h3"},{"title":"54: Invalid TypedDict Operation​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#54-invalid-typeddict-operation","content":"In accordance with PEP 598, code that tries to assign a value of the wrong type to a field of a TypedDict will not typecheck: from typing import TypedDict class MyDict(TypedDict): value: str d: MyDict = {&quot;value&quot;: &quot;hello&quot;} d[&quot;value&quot;] = 5 # Invalid TypedDict operation  To fix this you may need to change your field type to a Union, if variable types are actually needed for a field. ","version":"Next","tagName":"h3"},{"title":"55: TypedDict Initialization Error​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#55-typeddict-initialization-error","content":"Pyre will warn you when initializing a TypedDict with: Missing required fields from typing import TypedDict class Movie(TypedDict): name: str year: int movie: Movie = {&quot;name&quot;: &quot;The Matrix&quot;} $ pyre TypedDict initialization error [55]: Missing required field `year` for TypedDict `Movie`. Incorrect field type movie: Movie = {&quot;name&quot;: &quot;The Matrix&quot;, &quot;year&quot;: &quot;1999&quot;} $ pyre TypedDict initialization error [55]: Expected type `int` for `Movie` field `year` but got `str`. Undefined fields movie: Movie = {&quot;name&quot;: &quot;The Matrix&quot;, &quot;year&quot;: 1999, &quot;extra_field&quot;: &quot;hello&quot;} $ pyre TypedDict initialization error [55]: TypedDict `Movie` has no field `extra_field`.  ","version":"Next","tagName":"h3"},{"title":"56: Invalid Decoration​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#56-invalid-decoration","content":"This error code is a catch-all for a variety of problems that can arise in the course of resolving the type of a decorated function. In all of these cases, these decoration failures will lead to the function being registered with type Any to avoid any spurious downstream errors. &quot;Pyre was not able to infer the type of the decorator ...&quot;​ This should only happen when the decorator access itself is invalid, e.g. when you use a decorator which isn't declared in the stubs for a third-party library. &quot;Pyre was not able to infer the type of argument ...&quot;​ When using the &quot;decorator factory&quot; pattern, we need to resolve the type of both the decorator factory itself as well as the arguments passed to the decorator factory. This is because the types of these arguments can alter the behavior of the returned decorator via overloads or type variables. However, this resolution has to happen early in the environment-building pipeline, when we don't yet have all of the context we need in order to resolve the types of arbitrary expressions. We support resolving literals and simple globals as arguments, but using anything else will result in this error. To work around this, you can statically type your arguments to the decorator factory as separate globals, which can be validated later in the type-checking pipeline. from typing import TypeVar T = TypeVar(&quot;T&quot;) def decorator_factory(x: T) -&gt; Callable[[Callable[[int], str]], Callable[[str], T]]: ... # pyre-fixme[56]: Pyre was not able to infer the type of argument # `complex_expression()` to decorator factory `decorator_factory`. @decorator_factory(complex_expression()) def foo(x: int) -&gt; str: ... argument: float = complex_expression() @decorator_factory(argument) # Accepted! bar resolves to Callable[[str], float] def bar(x: int) -&gt; str: ...  &quot;Decorator factory `X` could not be called&quot;​ This corresponds to when the decorator factory access resolves to a type that is not callable (i.e. has no __call__ method). not_a_factory: int = 5 # pyre-fixme[56]: Decorator factory `not_a_factory` could not be called, because its # type `int` is not callable @not_a_factory(1) def bar() -&gt; None: pass  &quot;Decorator `X` could not be called&quot;​ Similarly, these errors correspond to when the entire decorator expression (potentially including arguments to a decorator factory), resolves to a non-callable type. def foo() -&gt; int: return 42 # pyre-fixme[56]: Decorator `foo()` could not be called, because its # type `int` is not callable @foo() def bar() -&gt; None: pass  &quot;While applying decorator factory ...&quot;​ These errors are emitted from attempting to pass the resolved factory arguments to the factory, as with any other function call. from typing import Callable def factory(x: str) -&gt; Callable[[object], object]: ... # pyre-fixme[56]: While applying decorator factory `factory`: # Expected `str` for 1st param but got `int`. @factory(1) def foo() -&gt; None: pass  &quot;While applying decorator ...&quot;​ Correspondingly, these errors are emitted from trying to pass the decorated function as an argument to the resolved decorator type. from typing import Callable def decorator(f: Callable[[int], str]) -&gt; int: ... # pyre-fixme[56]: While applying decorator `decorator`: # Expected `Callable[[int], str]` for 1st param but got `Callable[[str], int]`. @decorator def foo(x: str) -&gt; int: return 5  ","version":"Next","tagName":"h3"},{"title":"57: Incompatible Async Generator Return Type​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#57-incompatible-async-generator-return-type","content":"An async generator function is an async function that contains at least one yield statement. The Python runtime ensures that all async generator would return an async generator object. Therefore, the return type of async generator functions should always be typing.AsyncGenerator or one of its supertypes. from typing import AsyncGenerator async def f() -&gt; int: # Error yield 0 async def g() -&gt; AsyncGenerator[int, None]: # OK if False: yield 1  ","version":"Next","tagName":"h3"},{"title":"58: Unsupported Operand​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#58-unsupported-operand","content":"Pyre will warn if an infix operator is not supported for the right or left operands provided. In Python, an infix operator is converted to a method call on either of the operands - for example, a &lt; b is equivalent to a.__lt__(b). Therefore, this type error can also be considered sugar for an error that method a.__lt__ does not accept the type of b as an argument. For example, from typing import Optional def foo(x: Optional[int]) -&gt; bool: return x &lt; 0 # type error: Optional[int] is not a supported operand def bar(x: Optional[int]) -&gt; bool: if x: return x &lt; 0 # no type error return False  ","version":"Next","tagName":"h3"},{"title":"59: Duplicate Type Variables​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#59-duplicate-type-variables","content":"This occurs when the same type variable is provided more than once to a Generic or Protocol. A type variable needs to be bound to a single value. Thus, if one wants two independent type variables with perhaps the same bounds or same properties, they have to be different variables. from typing import TypeVar, Generic T0 = TypeVar(&quot;T0&quot;) T1 = TypeVar(&quot;T1&quot;) T2 = TypeVar(&quot;T2&quot;) class A(Generic[T0, T1, T0]): # Error pass class B(Generic[T0, T1, T2]): # OK pass  ","version":"Next","tagName":"h3"},{"title":"60: Unable to Concatenate Tuple​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#60-unable-to-concatenate-tuple","content":"&quot;Expected to unpack an iterable ...&quot;​ This can occur if during concatenation of a tuple one tries to unpack a non-iterable since non-iterables can't be unpacked. Either try to unpack an iterable, or concatenate without unpacking. def foo(x: int, not_iterable: int, iterable: list[int]) -&gt; None: y = (x, *not_iterable) # Error z = (x, not_iterable) # OK w = (x, *iterable) # OK  &quot;Concatenation not yet supported for multiple variadic tuples ...&quot;​ This can occur if during concatenation one tries to use multiple variadic tuples. This is due the limitations of the current type system and there is no workaround currently. One may use # pyre-ignore[60] to suppress. from typing import Tuple from pyre_extensions import TypeVarTuple Ts = TypeVarTuple(&quot;Ts&quot;) def foo(xs: Tuple[*Ts]) -&gt; None: y = (*xs, *xs) # Error  ","version":"Next","tagName":"h3"},{"title":"61: Uninitialized Local​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#61-uninitialized-local","content":"This indicates that there are code paths along which a local variable may not be initialized. Below are some common code patterns that may cause this error: Not initialized in all branches of condition​ def f(x: int) -&gt; None: z = None if x &gt; 5: y = 2 z = 2 print(y) # Error print(z) # OK  y is not defined when the if condition is not met. For instance, f(4) will result in a runtime error. Possible ways to address this: initialize y to a default value, outside the conditional or in the else branchrefactor so that initialization and access are in the same conditional Pyre static analysis does not reason about runtime values or potential side effects of interleaving calls, so for instance, in the example below we cannot guarantee that the two if statements will always be consistent and, hence, throw the same error: def f(x: int) -&gt; None: if x &gt; 5: y = 2 # ...some operations... if x &gt; 5: print(y) # Error  Initialized only inside a for loop​ def f(xs: List[int]) -&gt; None for x in xs: y = &quot;yes&quot; print(&quot;Last element is: &quot;, x) # Error print(&quot;Did we enter the loop?&quot;, y) # Error  Here, if one calls f([]), it will result in errors. One way to remediate is to initialize outside the loop. For instance, def f(xs: List[int]) -&gt; None: x = None y = &quot;no&quot; for x in xs: y = &quot;yes&quot; print(&quot;Last element is: &quot;, x) # OK print(&quot;Did we enter the loop?&quot;, y) # OK  Initialized in try block​ def f(divisor: int) -&gt; None: answer_good = None try: answer_bad = 5 / divisor answer_good = 5 / divisor answer_also_good = 5 / divisor print(f&quot;5 divided by {divisor} is {answer_also_good}&quot;) # OK except ZeroDivisionError: pass print(f&quot;5 divided by {divisor} is {answer_bad}&quot;) # Error print(f&quot;5 divided by {divisor} is {answer_good}&quot;) # OK  Here, f(0) leads to an error on access of answer_bad. Suggested approaches to address this: Initialize any variables needed after the try block to a default value before entering the try block.Keep the access to variables initialized inside the try block within the try block.Consider if pulling the initialization as-is before the try block is possible. It is generally considered a good practice to minimize the code inside a try block, and keep it to exception throwing code. This also helps with Pyre, as it does not reason about which operations might throw exceptions. def bad(divisor: int) -&gt; Optional[int]: try: dividend = 5 return dividend // divisor except ZeroDivisionError: print(f&quot;Cannot divide {dividend} by 0&quot;) # Error (according to Pyre) def good(divisor: int) -&gt; Optional[int]: dividend = 5 try: return dividend // divisor except ZeroDivisionError: print(f&quot;Cannot divide {dividend} by 0&quot;) # OK  ","version":"Next","tagName":"h3"},{"title":"62: Non-literal string​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#62-non-literal-string","content":"Pyre will error if you passs in a non-literal string into a function call that expects a LiteralString. def query_user(conn: Connection, user_id: str) -&gt; User: query = f&quot;SELECT * FROM data WHERE user_id = {user_id}&quot; conn.execute(query) # Error: Expected LiteralString, got str. ...  def query_user(conn: Connection, user_id: str) -&gt; User: query = &quot;SELECT * FROM data WHERE user_id = ?&quot; conn.execute(query, (user_id,)) # OK.  LiteralStrings are created either from an explicit string literal like &quot;foo&quot; or from combining multiple string literals or LiteralStrings. This is a security focused typing feature for safely calling powerful APIs. See PEP 675 for more details. ","version":"Next","tagName":"h3"},{"title":"63: Suppression Comment Without Error Code​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#63-suppression-comment-without-error-code","content":"When running Pyre in strict mode, suppression comments like pyre-ignore and pyre-fixme need to be associated with a specific error code or set of error codes. OK: def foo() -&gt; int: # pyre-ignore[7] return &quot;&quot;  Not OK: def foo() -&gt; int: # pyre-ignore return &quot;&quot;  For more details on how to write suppression comments, refer to the section on Suppression later in this doc. ","version":"Next","tagName":"h3"},{"title":"64: Inconsistent Method Resolution Order​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#64-inconsistent-method-resolution-order","content":"Python supports multiple inheritance via multiple base classes. In order to decide the order that methods from base classes are overridden, there needs to be a consistent order among the base classes of a particular class. When this order cannot be created, for example because there is a cycle, then Pyre raises this error. class A(B): # Error pass class B(A): # Error pass  For more details and examples for Python's Method Resolution Order (MRO), please refer to the official guide. ","version":"Next","tagName":"h3"},{"title":"65: Duplicate Parameter​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#65-duplicate-parameter","content":"Functions may not have multiple named parameters that share the same name. def add(a: int, a: int) -&gt; None: # Error pass  ","version":"Next","tagName":"h3"},{"title":"66: Invalid Exception Handler​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#66-invalid-exception-handler","content":"Exception types listed in an except clause must extend BaseException. try: pass except (int, bool): # Error pass  ","version":"Next","tagName":"h3"},{"title":"67: Invalid Exception Group Handler​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#67-invalid-exception-group-handler","content":"Exception types listed in an except* clause (Python 3.12 exception group handler) must extend BaseException and may not extend BaseExceptionGroup. try: pass except* ExceptionGroup as e: # Error pass  try: pass except* int as e: # Error pass  ","version":"Next","tagName":"h3"},{"title":"68: Invalid Type Guard​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#68-invalid-type-guard","content":"User defined type-guards are functions that return TypeIs[X] or TypeGuard[X]; at runtime these return a bool, but the static type indicates to the type checker that they narrow the type of the first positional argument, for example: from typing import TypeIs, reveal_type def is_int_or_str(val: object) -&gt; TypeIs[int | str]: ... def f(x: object): if is_int_or_str(x): reveal_type(x) # int | str  The difference between TypeGuard and TypeIs is that TypeGuard only narrows in the positive case and is covariant in its type parameter, whereas TypeIs also narrows in the negative case and is invariant in its type parameter; for example: # (extending the previous example) def is_int_or_str_typeguard(val: object) -&gt; TypeGuard[int | str]: ... def g(x: int | str | bytes): if is_int_or_str(x): reveal_type(x) # int | str else: reveal_type(x) # bytes if is_int_or_str_typeguard(x): reveal_type(x) # int | str else: reveal_type(x) # int | str | bytes (no narrowing here)  It is a type error if such a type guard function does not accept at least one positional argument; the type guard cannot actually be invoked correctly in this case. For example: from typing import TypeIs, TypeGuard # Error: the argument is keyword-only, this is not a valid type guard. def bad_type_guard(/, val: objec) -&gt; TypeGuard[float]: ... class CustomTypeGuard: # Error: this is a non-static method and `self` is bound, so it does not # accept a positional argument. def guard(self) -&gt; TypeIs[str]: ...  In addition, for TypeIs it is an error if the narrowed type (the type inside the TypeIs) is not assignable to the type of the first positional parameter. from typing import TypeIs # Error: `int` is not a subtype of `str` def inconsistent_type_is(x: str) -&gt; TypeIs[int]: ...  You can read more about type guards and narrowing in the specification: https://typing.readthedocs.io/en/latest/spec/narrowing.html. ","version":"Next","tagName":"h3"},{"title":"69: Invalid Positional-Only Parameter​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#69-invalid-positional-only-parameter","content":"Python has positional-only parameters which may not be passed by name. Positional-only parameters cannot appear after parameters that may be passed by name. Typically, all the parameters that proceed / in the parameter list are considered positional-only, but in functions without this syntax we treat parameters that are prefixed but not suffixed with __ as positional-only for backwards-compatibility purposes. Refer to https://typing.readthedocs.io/en/latest/spec/historical.html#positional-only-parameters for more details. In the following example, __y is a positional-only that follows the regular parameter x, which is an error. def foo(x: int, __y: int) -&gt; None: # Error pass  ","version":"Next","tagName":"h3"},{"title":"70: Assert Type​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#70-assert-type","content":"assert_type is a static assertion that has no effect at runtime. Pyre will emit an error if the inferred type for the first argument does not match the type provided as the second argument. x: int = 1 assert_type(x, str) # Error  ","version":"Next","tagName":"h3"},{"title":"71: Typed Dictionary Isinstance​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#71-typed-dictionary-isinstance","content":"Typed dictionaries are structurally typed. This means that it is invalid to use isinstance to check whether something is an instance of a typed dictionary. class Coord(TypedDict): x: int y: int isinstance({}, Coord) # Error  ","version":"Next","tagName":"h3"},{"title":"72: Tuple Delete​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#72-tuple-delete","content":"Tuples are immutable, so deleting elements is not allowed. x = (1, 2, 3) del x[0] # Error  ","version":"Next","tagName":"h3"},{"title":"73: Tuple Out of Bounds​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#73-tuple-out-of-bounds","content":"When a tuple with a concrete/known length is indexed with a literal, Pyre will emit an error if the index is out of bounds. x = (1, 2, 3) y: int = ... x[0] # OK x[-1] # OK x[5] # Error x[y] # OK  ","version":"Next","tagName":"h3"},{"title":"74: Named Tuple Default Fields​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#74-named-tuple-default-fields","content":"Since named tuple constructors are generated based on the order fields are declared in, fields without defaults may not follow fields with defaults in a named tuple declaration. # This is OK class MyTuple(NamedTuple): x: int y: int = 1 # This is not allowed class MyTuple2(NamedTuple): x: int = 1 y: int  ","version":"Next","tagName":"h3"},{"title":"Suppression​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#suppression","content":"It is not always possible to address all errors immediately – some code is too dynamic and should be refactored, other times it's just not the right time to deal with a type error. We do encourage people to keep their type check results clean at all times and provide mechanisms to suppress errors that cannot be immediately fixed. ","version":"Next","tagName":"h2"},{"title":"Suppressing Individual Errors​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#suppressing-individual-errors","content":"Pyre supports error suppression of individual errors with comments that can be placed on the line of the error or on the line preceding the error. # pyre-fixme indicates there is an issue in the code that will be revisited later.# pyre-ignore indicates there's an issue with the type checker or the code is too dynamic and we have decided to not fix this. If this is a Pyre bug, make sure you open an issue on our tracker. Both comment styles allow you to suppress individual error codes as well as adding additional context. def foo() -&gt; int: # pyre-fixme[7]: only suppresses return mismatches return &quot;&quot;  Pyre also supports # type: ignore comments for backwards-compatibility with MyPy. ","version":"Next","tagName":"h3"},{"title":"Suppressing Errors within Format Strings​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#suppressing-errors-within-format-strings","content":"If you want to suppress an error within an f-string, you can add a fixme comment on the line before the string. This will suppress all errors within the f-string matching that fixme: def print_profile(name: str, age: Optional[int]) -&gt; None: # pyre-fixme[58]: `-` is not supported for operand types `Optional[int]` and `int`. s = f&quot;&quot;&quot; Your personal details!! Name: {name} Age: {age - 3} &quot;&quot;&quot; print(s)  ","version":"Next","tagName":"h3"},{"title":"Suppressing All Errors​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#suppressing-all-errors","content":"You can use the Pyre upgrade tool to add inline error suppressions for all errors in your project. ","version":"Next","tagName":"h3"},{"title":"Suppressing Errors Across Files​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#suppressing-errors-across-files","content":"You can suppress all errors in entire sections of your code by adding the path to the ignore_all_errors section of your configuration. Furthermore Pyre supports suppressing all errors in an individual file if you add a # pyre-ignore-all-errors to your file. Like the other suppression comments, you can use square brackets to chose to only ignore one or more particular error types. For example, you can suppress all incompatible return type errors by adding: # pyre-ignore-all-errors[7] def foo(x: int) -&gt; str: return x # pyre will not error here  ","version":"Next","tagName":"h3"},{"title":"Debugging​","type":1,"pageTitle":"Type Errors","url":"/docs/errors/#debugging","content":"","version":"Next","tagName":"h2"}],"options":{"id":"default"}}